local_uri,alt_text
images/e6011ab5c271d61735bfecdeb4e27bdce7a061e6_Image_001.jpg,"Friends Graph represented using GSK. Each line below lists the name of a node, its number of edges, and nodes to which it is joined.

Amy	4	Oscar	Pat	Neal	Harry			
Bob	2	Dan	Charlie					
Charlie	1	Bob						
Dan	4	Bob	Fred	Kate	Neal			
Emma	1	Neal						
Fred	4	Dan	Kate	Ike	Neal			
George	3	Mark	Pat	Harry				
Harry	5	Amy	George	Jon	Pat	Neal		
Ike	4	Fred	Kate	Pat	Neal			
Jon	1	Harry						
Kate	5	Dan	Fred	Mark	Lou	Ike		
Lou	1	Kate						
Mark	2	George	Kate					
Neal	7	Amy	Dan	Fred	Ike	Pat	Emma	Harry
Oscar	1	Amy						
Pat	5	Amy	Neal	Harry	George	Ike"
images/ee93a76437d7ba475c58b043c050fd78b77e7370_Image_001.jpg,Cumulative distribution function (blue) and histogram (N = number of participants within bin) for match making ranking (MMR).
images/3b7898e31176cfe6b7e2b6309e2f18c63103baa9_Image_005.jpg,"This figure presents a collum chart with the average WPM for each method. QWERTY ist the fastest followed by MultiTap, NavTouch and BrailleTouch."
images/3b7898e31176cfe6b7e2b6309e2f18c63103baa9_Image_006.jpg,"This figure presents a collum chart with the MSD Error Rate for each method. MultiTap has the largest MSD Error Rate, followed by QWERTY, NavTouch and BrailleTouch. the method with thefastest followed by MultiTap, NavTouch and BrailleTouch."
images/3b7898e31176cfe6b7e2b6309e2f18c63103baa9_Image_007.jpg,"This figure presents a line chart with the average WPM for each method, for three age of onset groups (<=5, 6-20 and >=21). The early blind group was slower in every method. THe group with an age of onset between 6 and 20 is the fastest. These differeces in performance are more pronounced in QWERTY and MultiTap than with NavTouch and BrailleTouch."
images/3b7898e31176cfe6b7e2b6309e2f18c63103baa9_Image_008.jpg,"This figure presents a line chart with the average WPM for each method, for two pressure sensitivity groups (<=3.61 and 3.62-4.31). The difference in performance of the two groups is considerable for QWERTY and MultiTap, especially for MultiTap, with the users with better sensitivity being much faster."
images/3b7898e31176cfe6b7e2b6309e2f18c63103baa9_Image_009.jpg,"This figure presents a line chart with the average WPM for each method, for three spatial ability groups (<=4.75, 4.76-7.0 and >=7.01). The difference in performance of the group with the best spatial ability and the other two is big for QWERTY and MultiTap. Performance in NavTouch and BrailleTouch is similar among groups."
images/b0abced402bd11a7b43f42e4fd443c9150b4a9b0_Image_007.jpg,"This figure shows a U.S. map where counties are marked using black separator lines. The U.S. counties filled with red color are those with at least one edit from the women power editors in our sample in the no-bots dataset. A prominent ""No Female Edits Belt"" (in white color) is visible running from the Northern Mountain West down through the Great Plains, Midwest, and Appalachians (note: these counties may be edited by non-power-editors or unidentified female editors)."
images/5fe63a4c521dd10ca9ec9b4e7dc07f6194c564cc_Image_002.png,Figure 1a: A stenograph keyboard that shows its phonetic-based keys.  Figure 1b: A graph of a stenographer's typical Words Per Minute (WPM) limit and range.
images/5fe63a4c521dd10ca9ec9b4e7dc07f6194c564cc_Image_008.png,"Figure 5: A graph of the latencies for each transcript (professional, automatic and crowd). Professional and crowd captions have latencies under 5 seconds which allows students to keep up with the lecture."
images/85bf475fb8a40de8ace3cd67c4fa963daa890fcb_Image_014.jpg,An overview of the average Task Completion Time to assemble the Lego Duplo construction using the different error feedback modalities and the average number of errors that were made using the different error feedback modalities for both assembly errors and picking errors. The error bars depict the standard error.
images/85bf475fb8a40de8ace3cd67c4fa963daa890fcb_Image_015.jpg,An overview of the average Task Completion Time to assemble the Lego Duplo construction using the different error feedback modalities and the average number of errors that were made using the different error feedback modalities for both assembly errors and picking errors. The error bars depict the standard error.
images/29ce15f6520d7427cf1c0cce62e49fca0f40c19d_Image_001.jpg,Screenshot of the mechanical turk interface.  See caption for the information collected
images/29ce15f6520d7427cf1c0cce62e49fca0f40c19d_Image_003.jpg,"This image shows a donut chart of the six different categories in our dataset.  Rising trend is 36%, falling trend is 23%, stable trend is 33%, changing trend, big jump, and big fall are significantly lower"
images/29ce15f6520d7427cf1c0cce62e49fca0f40c19d_Image_004.jpg,"This figure contains two line graphs a and b.  The line on a goes sharply down, but then rises and falls, rises and falls again.  For b, the line is barely stable and changes a bit before rising at the end."
images/29ce15f6520d7427cf1c0cce62e49fca0f40c19d_Image_005.jpg,"This figure contains two line graphs a and b.  The line on a goes sharply down, but then rises and falls, rises and falls again.  For b, the line is barely stable and changes a bit before rising at the end."
images/29ce15f6520d7427cf1c0cce62e49fca0f40c19d_Image_006.jpg,"This figure contains two line graphs, a and b.  The a line graph represents the vision testing and training accuracy of the network over 80 epochs.  The training data rises consistently, but the testing accuracy maxes out at around 25 epochs.  In graph b, the line graph shows the training and testing accuracy of the bag of words model.  The training accuracy rises consistently, but the testing accuracy maxes out at round 45% at epoch 30 and slightly falls afterward."
images/29ce15f6520d7427cf1c0cce62e49fca0f40c19d_Image_007.jpg,"This figure contains two line graphs, a and b.  The a line graph represents the vision testing and training accuracy of the network over 80 epochs.  The training data rises consistently, but the testing accuracy maxes out at around 25 epochs.  In graph b, the line graph shows the training and testing accuracy of the bag of words model.  The training accuracy rises consistently, but the testing accuracy maxes out at round 45% at epoch 30 and slightly falls afterward."
images/29ce15f6520d7427cf1c0cce62e49fca0f40c19d_Image_008.jpg,"This line graph shows the training and testing accuracy of our multimodal model over 25 epochs.  The training accuracy consistently rises, but the testing accuracy peaks quickly at around 2 epochs and then falls due to the model overfitting to the training data."
images/29ce15f6520d7427cf1c0cce62e49fca0f40c19d_Image_009.jpg,This bar chart shows the accuracy of the compared methods.  The baseline is at 36%.  The BOW is at 45.2%.  The Human (no vote) is at 58.5%.  The CNN is at 69.8%.  The Human is at 70.9% and the multimodal model is at 74.0%
images/41b29f8c66e0281fa0544fae0a45764a58e83c3b_Image_004.jpg,The results of the user study. (a) The Task Completion Time in seconds that was needed for each navigation method. (b) The average amount of navigation errors. (c) The perceived cognitive workload measured using the RTLX score. All error bars depict the standard error. The values depicted in this Figure are mentioned in the text.
images/41b29f8c66e0281fa0544fae0a45764a58e83c3b_Image_005.jpg,The results of the user study. (a) The Task Completion Time in seconds that was needed for each navigation method. (b) The average amount of navigation errors. (c) The perceived cognitive workload measured using the RTLX score. All error bars depict the standard error. The values depicted in this Figure are mentioned in the text.
images/41b29f8c66e0281fa0544fae0a45764a58e83c3b_Image_006.jpg,The results of the user study. (a) The Task Completion Time in seconds that was needed for each navigation method. (b) The average amount of navigation errors. (c) The perceived cognitive workload measured using the RTLX score. All error bars depict the standard error. The values depicted in this Figure are mentioned in the text.
images/d39c93d0017363f1aaeb8e372cf8a124d33a8297_Image_005.jpg,"Two line graphs appear with Group A's findings stacked above Group B's findings. Each particpant that completed both the majority of game play and testing appear in their respective group's graph. For group A, that is P1, P2, and P5. For group B that is P7, P8, P11. Each particpant's score for each assessment is dispalyed in contionous line that run across the X axis that displays days of assessments  (1-3, 11-13, and days 24-26). The Y axis is the score on the MCR assessmet (0-14). The top graph has a phase line after day 3 to indicate that intervention began at this time for this group. The phase line is drawn down to graph below but jogs over to day 13 to indicate when treatment started for this group. Each participant's data is represetned by a uniqie shae and line style. Descriptive text of these data are provided in resutls section."
images/6443e3632848430cfac5aeb3ab94a46acf0bbf0c_Image_006.jpg,"Titel: Infographics ""Intra-active"" Dynamics - Beschreibung: The term ""activity"" is positioned in the middle of a triangular graph. The corners of the triangle are made out of the acronyms ""PPP"", ""OP"" and ""P"". The term ""activitiy"" and the acronyms are connected with double-ended arrows."
images/dd11d994cd3d819ddbd4c8b0f6bfcbb3690c9045_Image_005.jpg,"This figure shows results for player experience of persons using wheelchairs and able-bodied persons playing our game. Mean results are given for the dimensons competence, autonomy, relatedness, control and enjoyment on a five point Likert scale. While most values are above average, the biggest difference in scores can be found for relatedness."
images/2b270028ed9d0e8f2851f67988e822ab434cdb9d_Image_008.png,"Graph showing the Mean Selection Time for each Menu Size, Direction and Distance in the Moving condition. Within Menu Size, 5 item is the fastest, then 7 item then 10 item. The Up Direction is faster than the Down Direction and the 2N Distance is fastest than the 4N distance which is faster than the 6N distance."
images/2b270028ed9d0e8f2851f67988e822ab434cdb9d_Image_009.png,"Graph showing the mean selection time for for each Target Distance within each Direction. The graph shows, across directions, selection time increased as distance increased. The selection times for the Up Direction are generally faster than the Down Direction."
images/dd652c6a297c57c8c0c9cd5d91f2cba213d2eba8_Image_008.png,"This figure shows a stacked column graph. The columns are grouped by activity (left to right): Colors, Money, Numbers, and Shapes. Within each activity there is a column for each participant (who demonstrated any reaction while using this activity) which depicts the quantity of negative (black) and positive (gray) reactions he/she demonstrated while trying that activity.

Participants’ reactions during the Colors activity: For P1, 2 out of 2 were positive. For P2, 86 out of 95 were positive. For P3, 1 out of 1 were positive. For P4, 1 out of 1 were negative. For P5, 21 out of 25 were positive. For P6, 30 out of 30 were positive. P7 did not demonstrate any reactions. For P8, 22 out of 22 were positive. For P9, 31 out of 32 were positive.

Participants’ reactions during the Money activity: For P1, 5 out of 5 were positive. For P2, 39 out of 39 were positive. For P3, 14 out of 14 were positive. For P4, 2 out of 3 were positive. For P5, 6 out of 6 were positive. For P6, 1 out of 1 were positive. P7 did not demonstrate any reactions. For P8, 13 out of 13 were positive. For P9, 21 out of 21 were positive. P10 did not demonstrate any reactions.

Participants’ reactions during the Numbers activity: For P1, 8 out of 8 were positive. For P2, 64 out of 73 were positive. For P3, 2 out of 2 were positive. For P4, 10 out of 11 were positive. For P5, 21 out of 24 were positive. For P6, 19 out of 19 were positive. P7 did not demonstrate any reactions. For P8, 13 out of 13 were positive. For P9, 10 out of 10 were positive. P10 did not demonstrate any reactions.

Participants’ reactions during the Shapes activity: For P1, 5 out of 5 were positive. For P2, 58 out of 59 were positive. For P3, 6 out of 6 were positive. For P4, 10 out of 11 were positive. For P5, 7 out of 8 were positive. For P6, 10 out of 10 were positive. P7 did not demonstrate any reactions. For P8, 8 out of 8 were positive. For P9, 31 out of 31 were positive."
images/dd652c6a297c57c8c0c9cd5d91f2cba213d2eba8_Image_018.png,"This figure shows a stacked column graph. The columns are grouped by activity (left to right): Lowercase Letters, Uppercase Letters, and Money Addition. Within each activity there is a column for each participant (who demonstrated any reaction while using this activity) which depicts the quantity of negative (black) and positive (gray) reactions he/she demonstrated while trying that activity.

Participants’ reactions during the Lowercase Letters activity: For P1, 12 out of 12 were positive. For P2, 75 out of 76 were positive. For P3, 1 out of 1 were positive. For P4, 18 out of 18 were positive. For P5, 20 out of 20 were positive. For P6, 4 out of 4 were positive. For P7, 1 out of 1 were negative. For P8, 18 out of 18 were positive. For P9, 30 out of 31 were positive. For P10, 7 out of 7 were positive.

Participants’ reactions during the Uppercase Letters activity: For P1, 16 out of 16 were positive. For P2, 96 out of 99 were positive. For P3, 1 out of 1 were positive. For P4, 8 out of 9 were positive. For P5, 35 out of 36 were positive. For P6, 24 out of 24 were positive. P7 did not demonstrate any reactions. For P8, 13 out of 13 were positive. For P9, 37 out of 37 were positive.

Participants’ reactions during the Money Addition activity: For P1, 12 out of 12 were positive. For P2, 67 out of 82 were positive. For P3, 39 out of 55 were positive. For P4, 14 out of 14 were negative. For P5, 9 out of 9 were positive. For P6, 24 out of 24 were positive. P7 did not demonstrate any reactions. For P8, 16 out of 16 were positive. For P9, 39 out of 43 were positive."
images/825ae04b67cd58951cdb115978e9fba6a1d5f5d9_Image_002.jpg,"No-uncertainty visualization, showing a predicted arrival time bar at 9 minutes and the scheduled arrival time bar at 7 minutes."
images/825ae04b67cd58951cdb115978e9fba6a1d5f5d9_Image_005.jpg,Quantile dotplots shown on a timeline. Dark vertical bar indicates predicted arrival time; light vertical bar indicates scheduled arrival time.
images/825ae04b67cd58951cdb115978e9fba6a1d5f5d9_Image_007.jpg,"Probability density plot, showing the PDF as a lightly shaded interval, the predicted arrival time as a dark vertical bar, and the scheduled arrival time as a light vertical bar."
images/825ae04b67cd58951cdb115978e9fba6a1d5f5d9_Image_009.jpg,Complementary Cummulative Distribution Plot. Lightly shaded region indicates someone's chances of catching the bus if they arrive at the bus stop at a particular time. Dark vertical line indicates predicted arrival time; light vertical line indicates scheduled arrival time.
images/76cf5f3238904787043a4417b306e85c717e60b3_Image_012.jpg,"The figures show the time distribution of different keyboards and different languages. The entering time of VIPBoard is 1079.51 ms in English input and 1174.29 ms in Chinese input, the entering time of the traditional keyboard is 1298.95 ms in English input and 1359.74 ms in Chinese input."
images/39dcd4c585a6916a434dffd5cebfd70e97581dea_Image_013.gif,"Bar chart illustrating character recognition accuracy per participant: P1 - 94%, P2 - 65%, P3 - 92%, P4 - 100%, P5 - 100%, P6 - 69%, P7 - 94%, P8 - 96%, P9 - 65%, P10 - 67%, P11 -  54%"
images/39dcd4c585a6916a434dffd5cebfd70e97581dea_Image_016.gif,"Bar chart representing word recognition accuracy per condition. 4000ms condition - 93%, 2000ms condition - 89%, 1000ms condition - 64%, 500ms condition - 33%. Accuracy decreases with demand of condition. Clearly there are no statistically significant differences between the first and second conditions."
images/e44a1f6ef33c38a0aecb7dc5221055419b8f467a_Image_002.jpg,This image illustrates the visual appearance of the target features in each of the study's three tasks.
images/e44a1f6ef33c38a0aecb7dc5221055419b8f467a_Image_003.jpg,"This chart shows the average completion time (ms) across the three tasks, for each of the four conditions."
images/e44a1f6ef33c38a0aecb7dc5221055419b8f467a_Image_005.jpg,This chart illustrates the theoretical performance of progressive downloading across different LOD compression ratios and SPI settings.
images/e44a1f6ef33c38a0aecb7dc5221055419b8f467a_Image_006.jpg,This image is a screenshot of the visualization produced by the first case study participant.
images/a24780a906824f5e84777f8a1a4ebb7f65ff4f7e_Image_006.gif,This figure shows the participants’ mean responses to game experience statements S1 - S3 following each condition. The chart serves to provide a clear visual impression of the fact that the abstract version received the worst responses for each item. The means and standard deviations are listed in table 3.
images/a24780a906824f5e84777f8a1a4ebb7f65ff4f7e_Image_007.gif,This figure shows a bar chart featuring the mean responses to Borg's RPE scale before gameplay and after playing each version of the game. The values are detailed in the following paragraph.
images/2ea1e1b13f160dbdc939506d10205528da14adfb_Image_004.jpg,"Graphs of Response Times across situations, Response Times across Modalities and the Interaction between Situation and Modality"
images/0fe0270f4de60836fdb150646a6f7d730c8f564d_Image_005.jpg,Prevalence of Disease Determinants. A bar chart where each of the Scanning Errors (determinants) is shown with the number of apps out of 100 that were detected having that error. Values as follows in order the bars appear:    Item Description: 85 apps. Text contrast: 94 apps. Item Label: 94 apps. Item type label 20 apps. Clickable items: 57 apps. Touch Target: 95 apps. Image contrast: 85 apps. Editable Item Label: 10 apps. Link: 1 app.
images/0fe0270f4de60836fdb150646a6f7d730c8f564d_Image_006.jpg,Number of Determinants per App. A bar chart of the number of apps out of 100 that presented with a given number of determinants out of the nine screened for.    Number of apps that presented:  zero determinants: 0 apps. one determinant: 3 apps. two determinants: 2 apps. three determinants: 2 apps. four determinanats: 9 apps. five determinants: 36 apps. six determinants: 36 apps. seven determinants: 10 apps. eight determinants: 3 apps. all nine determinants: 0 apps.
images/13eccfcfd4ce807e14da418115a386b918870582_Image_005.jpg,"This is a bar chart of the mean time to complete the tasks.    With Keywords: Without Tool 3:57, with tool 3:32  Without Keywords: Without Tool 4:25, with tool 2:25  Conditions: Without Tool 5:01, with tool 2:24  All: Without Tool 4:28, with tool 2:47"
images/13eccfcfd4ce807e14da418115a386b918870582_Image_006.jpg,"This is a bar chart of the mean score for the tasks.    With Keywords: Without Tool 2, with tool 2.42  Without Keywords: Without Tool 1.57, with tool 1.57  Conditions: Without Tool 2, with tool 2.7  All: Without Tool 1.9, with tool 2.2"
images/13eccfcfd4ce807e14da418115a386b918870582_Image_007.jpg,"This is a bar chart of the mean response on the semantically anchored scales.    Easy: Without Tool 4.1, with tool 4.1  Frustration: Without Tool 4.3, with tool 5  Knew Location in the Code: Without Tool 4.1, with tool 5.6"
images/00de251fbb4aaeb4cae73a26f69b8a28e365c3a5_Image_002.jpg,"The chart shows the pre and post means of the three conditions for the autonomy, presence, tension and importance dimensions of the motivational measures with error bars indicating standard error."
images/00de251fbb4aaeb4cae73a26f69b8a28e365c3a5_Image_003.jpg,The chart shows bar plots for the mean difference in the FRT measure for all three conditions.
images/98474c14fa7ce6e06400788c51a7c0619abe26e5_Image_002.jpg,"This figure is a scatterplot showing the relationship between HIV Estimated Prevalence Rate Per 100,000 Population (CDC, 2011) on the x-axis and Percentage of Ads Containing Sexual Health-Related Language on the y-axis in 95 locations. The relationship is estimated linearly by the equation SHR language = 46.360 + 0.009 * prevalence rate, p = 0.009. Each location is represented by a circle, with the size of the circle representing its population relative to the other locations. Outliers with a low HIV prevalence rate and a high % of SHR language in ads include SF Bay Area and Boise, ID. Outliers with a high HIV prevalence rate and a low % of SHR language in ads include Wichita, KS and Jackson, MS. New York City is close to the linear trend, with a high HIV prevalence rate and a high % of SHR language in ads. In general, locations with a higher population tend to have a greater percentage of ads containing SHR language."
images/1d537d9ef32d2e12cd60ea1f551000d0671af8c9_Image_006.jpg,"Bargraph showing the number of likes, dislikes, and net score (likes minus dislikes) for each agent. Mikey had the highest net score, followed by Ava, Zee, and then Jake."
images/0907dfb73fbc31f4f0035aa7f391bbeab2c55bd4_Image_007.jpg,Box plot of ASL Instructor Score Improvement from Round 1 to Round 1.  Comparison of the VIDEO condition and the NOTES + POPUP condition.  VIDEO median 0.05 quartiles 0 and 0.5. NOTES + POPUP median 0.5 quartiles 1.5 and 0.
images/8209b931c94fea5d107e6ef2461b64e00fd52249_Image_005.jpg,"Figure 3: How people communicate in ASL a) digitally, b) when taking notes, and c) when using an ASL writing system. This figure presents three bar charts (a, b, and c). The y-axis is % Participants, ranging from 0-90. The x-axis is a) Digital Communication Format, b) ASL Note Format, and c) Known Writing Systems. Each bar chart provides separate bars for DHH (light blue) and Hearing (dark blue) populations.    a) Digital ASL Communication Formats, sorted by DHH popularity (most popular first): Animated emoji, English gloss, Live video chat, Recorded videos, English descriptions, Non-animated emoji, Other, N/A.  b) ASL Note Formats, sorted by DHH popularity (most popular first): English gloss, English translation, ASL writing system, ASL video recording, English descriptions, Drawings of signs, Other, N/A.  c)Known ASL Writing Systems, sorted by DHH popularity (most popular first): English gloss, SignWriting, HamNoSys, Stokoe notation, si5s, Other, None."
images/8209b931c94fea5d107e6ef2461b64e00fd52249_Image_006.jpg,"Figure 4: Materials participants reported wanting to read in ASL text. This figure presents a bar chart, with separate bars for DHH (light blue) and hearing (dark blue) populations. Y-axis is % participants, ranging from 0-70. X-axis is Material Desired in ASL Text. sorted by DHH popularity (most popular first): Website content, Printed content, Email, Texts/SMS, Video captions, Other, None."
images/8209b931c94fea5d107e6ef2461b64e00fd52249_Image_007.jpg,"Figure 6: Identification Accuracy, the percent who identified signs from stationary vs. animated characters, without training. This figure presents a bar chart, with separate bars for stationary (light blue) and animated (dark blue) characters. Y-axis is Identification Accuracy, ranging from 0-80. X-axis is ASL Sign, including four signs: WHERE, UNDERSTAND, MAYBE, and MOTIVATION."
images/8209b931c94fea5d107e6ef2461b64e00fd52249_Image_008.jpg,"Figure 5: Barriers to using ASL character systems reported by participants. This figure presents a bar chart, with separate bars for DHH (light blue) and hearing (dark blue) populations. Y-axis is % participants, ranging from 0-55. X-axis is Barrier to Adoption, sorted by DHH popularity (most popular first): Few printed material, Few online material, Hard to learn, Prefer English, Do not resemble SL, Dislike of reading, Other, None. Barriers with asterisks are potentially addressed by introducing animation to character systems. Barriers that have asterisks at the top of their bars: Hard to learn, and Do not resemble ASL."
images/feaab02b3d3545acf1964aaacc3ae4f29f889bda_Image_012.gif,The ROC curves for mean keystroke distances for gesturing on the compact keyboard.
images/e8f307fe9618a608b5503003fd1490908dd2077e_Image_013.jpg,Three line chart graphs showing recognition accuracy rates for stroke-gestures articulated by participants with and without motor impairments
images/b535ecced835fbcfffaa15a78abfa49f44709daa_Image_011.jpg,"The localization error in meters per participant across three routes. All data is the following in a csv format.  participant,lower whisker,25th percentile,median,75th percentile,upper whisker,% of outliers,extremes,number of samples  P1,0.04,1.02,1.52,2.24,4.07,6.1%,48,787  P2,0.03,0.96,1.39,2.51,4.835,8.8%,66,751  P3,0.08,0.91,1.435,2.09,3.86,0.3%,2,644  P4,0.06,0.905,1.43,2.05,3.7675,2.6%,16,620  P5,0.03,0.95,1.42,2.03,3.65,2.2%,20,915  P6,0.02,0.76,1.15,1.59,2.835,6.4%,34,530  P7,0.03,0.81,1.29,1.93,3.61,1.0%,8,813  P8,0.12,1,1.53,2.305,4.2625,11.8%,115,971  P9,0.16,0.99,1.34,1.88,3.215,4.4%,36,810  P10,0.03,0.86,1.55,2.28,4.41,0.4%,3,800"
images/b535ecced835fbcfffaa15a78abfa49f44709daa_Image_012.jpg,"Fig7.  The distribution of localization accuracy in meters. All the data is the following in a csv format.  Error in meters,Total,Success,Fail  0-0.5,16,15,1  0.5-1.0,87,79,8  1.0-1.5,61,56,5  1.5-2.0,55,46,9  2.0-2.5,18,14,4  2.5-3.0,12,8,4  3.0-3.5,3,2,1  3.5-4.0,1,0,1  5.5-6.0,1,1,0"
images/25e5f2ff3df3d731bbdbcd8485a45fe3658efd7f_Image_011.jpg,"Topographic distribution of correct trials (top) and incorrect trials (bottom) in the ‘far’ layout at the intervals: 50ms before key press (left), key press (middle), and 50ms after key press (right)."
images/25e5f2ff3df3d731bbdbcd8485a45fe3658efd7f_Image_017.jpg,"Average signals of the far layout at F3. The left vertical line is the averaged hand lift-off moments, the right vertical line is the button touched moments"
images/2efeaa97efaaca7c70ca7b4294dc12294b509aca_Image_016.jpg,"Figure 6  This figure shows two line graphs. The top graph shows the average binned offset along the x-axes of the smartphone screen and the location of clusters, three in total. The bottom graph shows the average binned offset along the y-axes of the smartphone screen and the location of the clusters, three in total."
images/f11a212f60cef1b9319ab3a3502beb104415a6ef_Image_007.jpg,"A bar diagram showing the factors navigation technique, gender and display size. The y axis ranges from 0 to 1000. The bar for the spatial navigation technique is about two thirds the size of the touch techiques . The bar of the male participants is about 4/5 the size of the female participants. The bar of the tablet is about the same hight of the male participants and similarly the bar of the phone is about the same hight as the bar of the female participants."
images/f11a212f60cef1b9319ab3a3502beb104415a6ef_Image_008.jpg,Bar chart showing the diffrent compeltion time deppening on the visibility of the target. All numbers are in the text. In all cases the bars for visible tasks are much smaller than those for invisble.
images/f11a212f60cef1b9319ab3a3502beb104415a6ef_Image_009.jpg,A bar chart showing the average number of actions required for spatail conditon sperated by on and off screen targets as wel as for the phone and for the iPad. Likewise for the touch condition.
images/f11a212f60cef1b9319ab3a3502beb104415a6ef_Image_010.jpg,"The results of the questionaire shown as a bar chart. All bar look quiete similar except for ease of use, efficency to use, user experience and zooming."
images/e7635f15dd6753f7f0c3538b85f36d38da503ba5_Image_011.gif,The participants needed to hear fewer corrections on average for each trial of the poses. Warrior Two Pose was only attempted once by all of the participants.
images/38e81f92a74dcdb62b7f35243f91e3d96a615b82_Image_003.jpg,"Y-axis is types of tasks. From top: survey control, survey mini, transcription control, transcription mini, and text detection. X-axis is time in seconds."
images/38e81f92a74dcdb62b7f35243f91e3d96a615b82_Image_008.jpg,A comparison of time spent on control transcription and ATQ-based transcription. Y-axis represents the types of interface. From top: control and ATQ. X-axis represents time in (s)
images/5fbe768879ccd88f675d4783a05a9f26a1ef49ab_Image_010.png,"Top image shows a blue wavy line labeled with ``Gaze signal''.       Middle image shows a rectangle labeled with ``Aid shown?''.       The rectangle is subdivided into three rectangles, the middle rectangle       is labeled with ``aid-shown'' and the remaining labeled as ``no-aid''.       Bottom image shows a set of sliding rectangles in blue and red. The       red rectangles intersect with a one rectangle size area before ``aid-shown''."
images/5fbe768879ccd88f675d4783a05a9f26a1ef49ab_Image_011.jpg,A line plot showing the progression of training at each epoch. The     accuracy increases until 237 then plateaus.
images/5fbe768879ccd88f675d4783a05a9f26a1ef49ab_Image_015.jpg,"A bar chart with 5 columns: ``no aid'', ``perm. arrow'', ``perm. map'',     ``adaptive arrow'' and adaptive map. The values range from 1 to 5 and are     labeled with Rating."
images/bb96dc3ce7c2196446c72e6d8c151abe578ee216_Image_019.jpg,"Gender Distribution    There was 1 woman with all 5 Abby facets, there were 5 women with 4 Abby facets, 2 women with 3 Abby facets, 1 woman with 2 Abby facets, 1 woman with 1 Abby facet, and 1 woman with 0 Abby facets. 1 man with 5 Tim facets, 3 men with 4 Tim facets, 3 men with 3 Tim facets, and 2 men with 2 Tim facets."
images/1a91496ad6d8adf41f12b157343321732872c0c1_Image_007.jpg,"Figure 5. Kinematics of tool movement (subject 01, trial 01) during a typical horizontal movement between circles. The blue curve is the tooltip position in pixels along the horizontal line between the circles, and the red curve is the velocity of tooltip."
images/1a91496ad6d8adf41f12b157343321732872c0c1_Image_009.jpg,"Figure 6:  Example of tooltip movement (blue) and pupil size (black) over time for a complete trial (subject 01, trial 01). The blue curve is the tooltip position in pixels along the horizontal line between the circles. The dash and solid vertical lines represent the moments of tooltip-start and tooltip-reach."
images/1a91496ad6d8adf41f12b157343321732872c0c1_Image_012.gif,"Figure 9. Mean pupil diameter changes for 808 valid moves of 69 trials from 12 subjects. Data were aligned over a 7 second window 3 seconds before the tooltip-start. The baseline is defined as the mean diameter of the pupil over the first second of the window, and the solid black curve is the mean pupil diameter change from the baseline over time. The black vertical dashed line is tooltip-start where all the data are aligned and the vertical solid black line is the average tool-reach time. The error bars for 1 std. dev. are drawn every 400ms."
images/1a91496ad6d8adf41f12b157343321732872c0c1_Image_013.gif,"Figure 10. Mean pupil diameter changes against different IDs; data are aligned over a 7-second window around tooltip-start.  The vertical dash black line is the tooltip-start and other three solid color vertical lines represent the tooltip-reach moments of three IDs respectively. The three colors of bars at the bottom indicate significant differences in pupil dilation between Easy, Middle and Hard ID with black representing Easy vs. Hard, pink representing Easy vs. Middle, and green representing Middle vs. Hard. The error bars for 1 std. dev. are drawn every 400ms."
images/1a91496ad6d8adf41f12b157343321732872c0c1_Image_014.jpg,Figure 11. Box-whisker plot for Mean duration from tooltip-reach to the moment where the pupil peaked in size for three difficulty IDs.
images/00be9ed47bb08d4af373474345c79729d7514e2b_Image_006.jpg,left: mean time vs. angle middle: mean pointing error vs. angle right: mean pointing error vs. focus
images/00be9ed47bb08d4af373474345c79729d7514e2b_Image_007.jpg,left: arm fatigue and neck fatigue vs. direction middle: arm fatigue and neck fatigue vs. angle group right: arm fatigue and neck fatigue vs. point of focus
images/f7406bd6a43969a5471287344cb565bee972b376_Image_003.gif,"number of apps is along the y-axis, proportion of labeled image-based buttons with duplicate labels is the x-axis.    proportion range: number of apps;  0-0.1: 2961 apps;  0.1-0.2: 42 apps;  0.2-0.3: 34 apps;  0.3-0.4: 60 apps;  0.4-05: 44 apps;  0.5-0.6: 14 apps;  0.6-0.7: 20 apps;  0.7-0.8: 25 apps;  0.8-0.9: 24 apps;  0.9-1: 174 apps."
images/a9acd1907c8be605fb24753d4209d44ca82d4b26_Image_005.jpg,Heatmaps of positioning data from a lesson of T2 (L) and T5 (R) for illustrating their reported examples.
images/4cecd70a9e46a761774a54ed11d613b33721b95d_Image_007.gif,"A box plot displaying the Median Intensity across each condition, with units in decibels (dB). First results are presented for the 9 participants who spoke in all three conditions, with median value of 48.882 for Markup, 41.828 for No ASR, and 50.541 for ASR.  There were significant differences between Markup and No ASR, as well as ASR and No ASR.  Next, results are shown for all 12 participants, with median value of 49.253 for Markup and 49.578 for ASR.  There was no significant difference between these two conditions."
images/4cecd70a9e46a761774a54ed11d613b33721b95d_Image_008.gif,"A box plot displaying the Mean Harmonicity across each condition, with units in decibels (dB). First results are presented for the 9 participants who spoke in all three conditions, with median value of 4.826 for Markup, 2.555 for No ASR, and 4.083 for ASR.  There was a significant difference between Markup and No ASR.  Next, results are shown for all 12 participants, with median value of 4.848 for Markup and 4.372 for ASR.  There was no significant difference between these two conditions."
images/4cecd70a9e46a761774a54ed11d613b33721b95d_Image_009.gif,"A box plot displaying the F1 Mean across each condition, with units in Hertz. First results are presented for the 9 participants who spoke in all three conditions, with median value of 948.497 for Markup, 1152.505 for No ASR, and 905.744 for ASR.  There were significant differences between Markup and No ASR, as well as ASR and No ASR.  Next, results are shown for all 12 participants, with median value of 959.743 for Markup and 909.571 for ASR.  There was no significant difference between these two conditions."
images/4cecd70a9e46a761774a54ed11d613b33721b95d_Image_010.gif,"A box plot displaying the F2 Mean across each condition, with units in Hertz. First results are presented for the 9 participants who spoke in all three conditions, with median value of 2510.066 for Markup, 2707.750 for No ASR, and 2577.583 for ASR.  There were significant differences between Markup and No ASR, as well as ASR and No ASR.  Next, results are shown for all 12 participants, with median value of 2524.027 for Markup and 2594.337 for ASR.  There was no significant difference between these two conditions."
images/4cecd70a9e46a761774a54ed11d613b33721b95d_Image_011.gif,"A box plot displaying the Speech Rate across each condition, with units in words per minute. First results are presented for the 9 participants who spoke in all three conditions, with median value of 209.828 for Markup, 150.846 for No ASR, and 169.242 for ASR.  There was a significant difference between Markup and No ASR.   Next, results are shown for all 12 participants, with median value of 203.418 for Markup and 171.534 for ASR.  There was no significant difference between these two conditions."
images/2d955bfeb3b7b43d5d1f45161b068a705190fde9_Image_005.jpg,A bar graph with all possible finger tap patterns on the x-axis and percentages on the y-axis.
images/2d955bfeb3b7b43d5d1f45161b068a705190fde9_Image_006.jpg,A boxplot showing the password method and order (first or second in the session) on the x-axis and time (in seconds) on the y-axis. The boxes marking the range of PIN times are far higher than those for PassChord times.
images/5fde0fa5fe2968ce9d50b52e7cd2b3aa9fc0ab65_Image_009.png,"The graph shows that our system, Sprites peorformed 3x times better in task completion rate."
images/6a69750f5fba6953fc582e1c17c7313ac0cfddce_Image_017.png,Fig7: Two images of line graphs stacked vertically. The first shows a positive correlation between size of an object that is electrospun with its infill density. The second shows how scaling and object can produce an desired expected size based on an infill percentage
images/fcdecb55ba0d72332570b2cea55e38208728e699_Image_010.jpg,Recognition rates for static graphical elements when indicating the perceived shape on a printed reference sheet.
images/6adc7c33566402e7aec97e9b7039ba4921fcf8d4_Image_006.jpg,Boxplots showing average participant trial completion times by grid size and selection method.
images/6adc7c33566402e7aec97e9b7039ba4921fcf8d4_Image_007.jpg,Box plots showing average participant error rates by grid size and selection method.
images/6adc7c33566402e7aec97e9b7039ba4921fcf8d4_Image_009.jpg,"A series of box plots showing how the average time taken by participants to select the correct item changed as the blocks progressed. In the first 6 blocks, the median swoops downward from ~4000ms to ~1500ms, then stays around this level for the remaining blocks."
images/6adc7c33566402e7aec97e9b7039ba4921fcf8d4_Image_010.jpg,"Dot plot showing how the average percentage use of one-step selection changed over the study blocks. Shows a steady progression toward higher use of one-step selection, culminating in nearly 100% use in the final six blocks."
images/6adc7c33566402e7aec97e9b7039ba4921fcf8d4_Image_012.jpg,"Box plots showing the error-free trial completion times for the testing stage of Study 3. WristTap and TwoTap are close to one another, with medians around 900-1000ms / selection. Swipe-and-Tap has a median that is higher, closer to 2500ms, and a larger spread."
images/6adc7c33566402e7aec97e9b7039ba4921fcf8d4_Image_013.jpg,"Three segmented bars, showing the median time taken for the component actions of the three selection techniques.

WristTap - two-finger tap (900ms)

TwoTap - tap category (637ms); tap item (344ms)

Swipe-and-Tap - swipe to open menu (685ms); tap category (482ms); select item in vertical list (1209ms)"
images/becd79d567f86115aa509b992dd1a09a765043cb_Image_009.jpg,"Figure 7 shows tabular chart of statistics for participant responses in study. It describes questions and responses. The questions are ""What is your rating for single/multiple view"", ""Did it help"", ""is it easy to use"", etc. It shows significant difference between SVP/MVP and C-MVP."
images/94586032948e2c2ba39f17b94679efb4435237c9_Image_009.jpg,"On the top-left, there is the mean response times chart for MOT task. Mean response time for control and standing conditinions are  5.59 s, and 5.41 s, respectively. On the  top-right, there is the mean response times chart for VS task. Meadn response time for control, standing, and walking conditions are 1.52 s, 1.50 s, 1.54 s, respectively.  On the bottom-left, there is the accuracy chart for MOT task. Mean accuracies for control, standing and walking conditions are %89.4, %87.9, and %78.3, respectively. The relationship between control vs. walking and standing vs. walking are marked with *.   On the bottom-right there is the mean chart of accuracy for VS task. Mean accuracies for control, standing, and walking conditions are %86.4, %87.6, and %86.7, respectively"
images/386a15fd85c162b8e4ebb6023acdce9df2bd43ee_Image_009.jpg,Bar graph of the JND latency thresholds gathered from each participant during the large box dragging task.
images/386a15fd85c162b8e4ebb6023acdce9df2bd43ee_Image_010.jpg,Bar graph of the JND latency thresholds gathered from each participant during the small box dragging task.
images/386a15fd85c162b8e4ebb6023acdce9df2bd43ee_Image_011.jpg,Bar graph of the JND latency thresholds gathered from each participant during the scribbling task.
images/854f7ee708fdb78943c7b67dcf8f3b786d94b9b0_Image_021.png,"This figure has two bar charts at the top and bottom. The bar chart at the top describes the proportion of participants who use a certain technology never, once a month, several times a month, once a week, several times a week, once a day, and several times a day as follows.  Experience of using a mobile device Never: 0.0% Once a month: 0.0% Several times a month: 0.0% Once a week: 0.0% Several times a week: 0.0% Once a day: 11.11% Several times a day: 88.89%  Experience of taking pictures using a mobile phone Never: 44.44% Once a month: 22.22% Several times a month: 0.0% Once a week: 0.0% Several times a week: 22.22% Once a day: 0.0% Several times a day: 11.11%  Experience of sharing your own photos or videos with others Never: 66.67% Once a month: 0.0% Several times a month: 22.22% Once a week: 0.0% Several times a week: 11.11% Once a day: 0.0% Several times a day: 0.0%  Experience of using apps (for any purpose) on a mobile phone Never: 0.0% Once a month: 0.0% Several times a month: 0.0% Once a week: 0.0% Several times a week: 0.0% Once a day: 22.22% Several times a day: 77.78%  Experience of using apps for object recognition (for example, Aipoly, TapTapSee) on a mobile phone Never: 44.44% Once a month: 0.0% Several times a month: 0.0% Once a week: 11.11% Several times a week: 11.11% Once a day: 0.0% Several times a day: 33.33%  Experience of using Braille labels to distinguish objects Never: 22.22% Once a month: 0.0% Several times a month: 11.11% Once a week: 0.0% Several times a week: 22.22% Once a day: 0.0% Several times a day: 44.44%  The bar chart at the bottom describes the proportion of participants who strongly disagree, disagree, neither agree nor disagree (neutral), agree, strongly agree with a statement about technology as follows.  Statement: I enjoy taking a photo on a mobile phone. Strongly disagree: 0.0% Disagree: 44.44% Neutral: 11.11% Agree: 22.22% Strongly agree: 22.22%  Statement: I think it is important to keep up with the latest trends in te"
images/854f7ee708fdb78943c7b67dcf8f3b786d94b9b0_Image_025.jpg,"This figure shows two bar charts on the left and the right, respectively.  The left bar chart shows the average accuracy of each participant's model in the vanilla test and the right bar chart shows the average of each participant's model in the wild test.  The average accuracy of the models in the vanilla test P1: 49.86% (min: 44.60%, max: 54.00%, std: 3.16) P2: 62.88% (min: 57.20%, max: 68.00%, std: 3.47) P3: 70.46% (min: 66.20%, max: 76.40%, std: 3.06) P4: 61.78% (min: 57.20%, max: 66.60%, std: 3.57) P5: 53.38% (min: 47.80%, max: 57.60%, std: 2.84) P6: 74.56% (min: 72.60%, max: 77.00%, std: 1.46) P7: 84.14% (min: 80.20%, max: 89.40%, std: 3.32) P8: 55.12% (min: 52.60%, max: 59.80%, std: 2.39) P9: 55.28% (min: 50.00%, max: 59.80%, std: 3.17) S1: 82.30% (min: 79.20%, max: 86.20%, std: 2.38) S2: 94.58% (min: 92.60%, max: 96.00%, std: 1.16)  The average accuracy of the models in the wild test P1: 28.56% (min: 24.40%, max: 33.80%, std: 3.00) P2: 34.44% (min: 29.20%, max: 38.60%, std: 3.08) P3: N/A P4: 54.32% (min: 48.00%, max: 58.00%, std: 3.37) P5: 40.72% (min: 36.40%, max: 45.60%, std: 3.51) P6: 55.82% (min: 52.20%, max: 61.00%, std: 2.22) P7: 58.08% (min: 52.00%, max: 66.00%, std: 4.14) P8: 23.00% (min: 20.00%, max: 26.80%, std: 2.35) P9: 43.28% (min: 39.80%, max: 48.80%, std: 2.97) S1: 76.68% (min: 69.80%, max: 84.00%, std: 4.74) S2: 86.18% (min: 83.20%, max: 89.00%, std: 1.83)"
images/854f7ee708fdb78943c7b67dcf8f3b786d94b9b0_Image_026.jpg,"This figure has two line graphs. A line graph on the left describes the average proportion of photos that included the full, part of, and no object.   Train Full: average=0.68, variance=0.05 Partial: average=0.29, variance=0.05 No: average=0.02, variance=0.001 Vanilla test Full: average=0.77, variance=0.03 Partial: average=0.20, variance=0.02 No: average=0.02, variance=0.002 Wild test Full: average=0.62, variance=0.10 Partial: average=0.30, variance=0.05 No: average=0.08, variance=0.01  The other line graph on the right describes the average proportion of photos that included the full, part of, and no hand.  Train Full: average=0.53, variance=0.14 Partial: average=0.13, variance=0.01 No: average=0.34, variance=0.14 Vanilla test Full: average=0.58, variance=0.18 Partial: average=0.11, variance=0.01 No: average=0.31, variance=0.19 Wild test Full: average=0.66, variance=0.12 Partial: average=0.19, variance=0.01 No: average=0.16, variance=0.08"
images/854f7ee708fdb78943c7b67dcf8f3b786d94b9b0_Image_030.jpg,"This figure consists of four box plots that are located from left to right.  The first boxplot shows word error rate per feedback cluster in the train session. The second boxplot shows the ratio of including hands in train photos per feedback cluster. The third boxplot shows the ratio of fully including an object in train photos per feedback cluster. The fourth boxplot shows the photography time per feedback cluster in the train session.  Word error rate per feedback cluster in train C1: 0.65 (min: 0.27, max: 0.96, std: 0.15) C2: 0.27 (min: 0.07, max: 0.64, std: 0.13) C3: 0.22 (min: 0.04, max: 0.52, std: 0.14)  Ratio of including hands in traing photos per feedback cluster. C1: 0.64 (min: 0, max: 1, std: 0.379, median: 0.84) C2: 0.55 (min: 0, max: 1, std: 0.447, median: 0.68) C3: 0.88 (min: 0, max: 1, std: 0.3, median: 1.0)  Ratio of including entire object in train photos per feedback cluster. C1: 0.96 (min: 0.93, max: 1.00, std: 0.02) C2: 0.995 (min: 0.960, max: 1.00, std: 0.008) C3: 0.974 (min: 0.933, max: 1.00, std: 0.023)  Photography time per feedback cluster in train C1: 227.94 seconds (min: 106.57 seconds, max: 867.25 seconds, std: 140.32) C2: 220.28 seconds (min: 40.81, max: 1039.57, std: 194.55) C3: 129.90 seconds (min: 76.74, max: 346.58, std: 65.63)"
images/854f7ee708fdb78943c7b67dcf8f3b786d94b9b0_Image_031.jpg,"This figure consists of four box plots that are located from left to right.  The first boxplot shows word error rate per feedback cluster in the train session. The second boxplot shows the ratio of including hands in train photos per feedback cluster. The third boxplot shows the ratio of fully including an object in train photos per feedback cluster. The fourth boxplot shows the photography time per feedback cluster in the train session.  Word error rate per feedback cluster in train C1: 0.65 (min: 0.27, max: 0.96, std: 0.15) C2: 0.27 (min: 0.07, max: 0.64, std: 0.13) C3: 0.22 (min: 0.04, max: 0.52, std: 0.14)  Ratio of including hands in traing photos per feedback cluster. C1: 0.64 (min: 0, max: 1, std: 0.379, median: 0.84) C2: 0.55 (min: 0, max: 1, std: 0.447, median: 0.68) C3: 0.88 (min: 0, max: 1, std: 0.3, median: 1.0)  Ratio of including entire object in train photos per feedback cluster. C1: 0.96 (min: 0.93, max: 1.00, std: 0.02) C2: 0.995 (min: 0.960, max: 1.00, std: 0.008) C3: 0.974 (min: 0.933, max: 1.00, std: 0.023)  Photography time per feedback cluster in train C1: 227.94 seconds (min: 106.57 seconds, max: 867.25 seconds, std: 140.32) C2: 220.28 seconds (min: 40.81, max: 1039.57, std: 194.55) C3: 129.90 seconds (min: 76.74, max: 346.58, std: 65.63)"
images/854f7ee708fdb78943c7b67dcf8f3b786d94b9b0_Image_032.jpg,"This figure consists of four box plots that are located from left to right.  The first boxplot shows word error rate per feedback cluster in the train session. The second boxplot shows the ratio of including hands in train photos per feedback cluster. The third boxplot shows the ratio of fully including an object in train photos per feedback cluster. The fourth boxplot shows the photography time per feedback cluster in the train session.  Word error rate per feedback cluster in train C1: 0.65 (min: 0.27, max: 0.96, std: 0.15) C2: 0.27 (min: 0.07, max: 0.64, std: 0.13) C3: 0.22 (min: 0.04, max: 0.52, std: 0.14)  Ratio of including hands in traing photos per feedback cluster. C1: 0.64 (min: 0, max: 1, std: 0.379, median: 0.84) C2: 0.55 (min: 0, max: 1, std: 0.447, median: 0.68) C3: 0.88 (min: 0, max: 1, std: 0.3, median: 1.0)  Ratio of including entire object in train photos per feedback cluster. C1: 0.96 (min: 0.93, max: 1.00, std: 0.02) C2: 0.995 (min: 0.960, max: 1.00, std: 0.008) C3: 0.974 (min: 0.933, max: 1.00, std: 0.023)  Photography time per feedback cluster in train C1: 227.94 seconds (min: 106.57 seconds, max: 867.25 seconds, std: 140.32) C2: 220.28 seconds (min: 40.81, max: 1039.57, std: 194.55) C3: 129.90 seconds (min: 76.74, max: 346.58, std: 65.63)"
images/854f7ee708fdb78943c7b67dcf8f3b786d94b9b0_Image_033.jpg,"This figure consists of four box plots that are located from left to right.  The first boxplot shows word error rate per feedback cluster in the train session. The second boxplot shows the ratio of including hands in train photos per feedback cluster. The third boxplot shows the ratio of fully including an object in train photos per feedback cluster. The fourth boxplot shows the photography time per feedback cluster in the train session.  Word error rate per feedback cluster in train C1: 0.65 (min: 0.27, max: 0.96, std: 0.15) C2: 0.27 (min: 0.07, max: 0.64, std: 0.13) C3: 0.22 (min: 0.04, max: 0.52, std: 0.14)  Ratio of including hands in traing photos per feedback cluster. C1: 0.64 (min: 0, max: 1, std: 0.379, median: 0.84) C2: 0.55 (min: 0, max: 1, std: 0.447, median: 0.68) C3: 0.88 (min: 0, max: 1, std: 0.3, median: 1.0)  Ratio of including entire object in train photos per feedback cluster. C1: 0.96 (min: 0.93, max: 1.00, std: 0.02) C2: 0.995 (min: 0.960, max: 1.00, std: 0.008) C3: 0.974 (min: 0.933, max: 1.00, std: 0.023)  Photography time per feedback cluster in train C1: 227.94 seconds (min: 106.57 seconds, max: 867.25 seconds, std: 140.32) C2: 220.28 seconds (min: 40.81, max: 1039.57, std: 194.55) C3: 129.90 seconds (min: 76.74, max: 346.58, std: 65.63)"
images/415c0ef55b1c603af7ed537f4aede720d80f34bd_Image_007.jpg,Two graphs. The graph on the left shows the text entry speeds for each technique over all eight sessions with learning curves fit to the speed data. The graph on the right shows corrected error rates for each technique over all sessions.
images/f504e35bd95dd13e5692c126fb272244dd765d39_Image_004.jpg,The figure shows that communities with higher overlap with mature communities are more likely to survive than communities with lower overlap with mature communities.
images/f504e35bd95dd13e5692c126fb272244dd765d39_Image_005.jpg,The figure shows that communities which have more core members participating in other communities are less likely to survive than communities which have fewer core members participating in other communities.
images/f8361de968dc956b7a2e1f19b3f8ccfc4ba18b0d_Image_001.jpg,"A graph showing the average completion times per gesture. Body-based gestures average around 2500 milliseconds while wheelchair-based gestures take less time for moving forward and backward with an average of about 2000 milliseconds, and turning gestures taking longer with about 3400 milliseconds."
images/a579f1acfcc6eb51605078e79f1478fbfb2fedf3_Image_009.jpg,Heat maps of gaze points on the tablet while typing in Eyes-on mode and Peripheral mode.
images/3b592c4f68ad1c9cdb32fe825aae0c090c09f937_Image_009.jpg,"The image shows a table of the positional errors per condition (2x2): For (near,high) = 13.8 mm (SD 3.54 mm), for (near,low) = 28.9 mm (SD 6.85 mm), for (far,high) = 44.7 mm (SD 15.1 mm), for (far,low) = 46.5 mm (SD 5.98 mm)."
images/108a29b3e76f0b2f375ddabb46b44b436bdee7b3_Image_002.png,"This is a scatter plot of the Fitbit data for 6 participants with gender (color of point-box), totoal number of days the firbit worn in the x axis, and average steps per day in the y-axis. Data is as follows 1. Female, 4 days, apprx 9000 steps per day 2. Male, 5 days, a little less than 9000 steps a day 3. Male, 6 days, 2500 steps a day 4. Female, 7 days, 7500 steps a day 5. Male, 14 days, a littl emore than 6000 steps a day 6. Female, 16 days, a littl emore than 8000 steps a day"
images/c769c84174b7a6b2f1083aa5bcf5ef45e8e527f4_Image_005.jpg,"Graph shows that while the ensemble of face detectors works best, the alt and alt2 frontal face detectors perform similarly when there are at least 45 training samples for each class."
images/c769c84174b7a6b2f1083aa5bcf5ef45e8e527f4_Image_006.jpg,Graph shows that performance is similar and there is a slow degradation in performance measured via F1 score as the sampling rate decreases (e.g. when there are more intermediate frames between those used for face detection) for both the Ensemble and Alt 2 face detectors. The performance is relatively table when frames are sampled at least every 20-25 frames for the 30 frame per second video.
images/c769c84174b7a6b2f1083aa5bcf5ef45e8e527f4_Image_008.jpg,The graph shows that the F1 score hovers around 71% once at least 10 frames are selected from a 60 second video segment while it takes more frames to achieve a lower performance (65%) when analyzing 30 second video segments.
images/b661e1e4bcc4e6d51f6cf0e30be641ed44a72889_Image_009.jpg,Task times for the four feedback conditions  (+/- standard deviation of the mean).
images/ec53d5cef0968ba3a7edd0a55e60f634ba8b792c_Image_007.jpg,Fifteen charts arranged in a 3 by 5 matrix showing growth curves for each of the 15 referents considered in this paper.
images/bcb3a46274165a64c4b951ae95fa118493593ddc_Image_006.jpg,Bar graph which demonstrates the increase level of knowledge gained by students after the 3D printing class sessions.
images/d1d8b26974a672a00ac297c4910d279cb8f13a7c_Image_007.jpg,"This line graph shows the trends for musical, non-musical and combined mean scores for all participants over the eight therapy sessions."
images/0d29f0ef7a18cfc6aae35381f163807c198c6ef6_Image_004.png,"Three-part figure describing experimental setup and task. The top part shows an illustration of the experimental setup: on the left side, a participant sits at a desk with a keyboard in front of them. Their head rests on a chin rest and the participant is looking through a transparent mirror, above which the eye tracker is mounted. On the right side is a projection screen that the participant looks at, showing a gray background with a black circle. The middle part of the figure displays a 3 by 3 grid of potential starting locations (white crosses on black circles), with the grid centered on the middle of a noisy gray background image. Around the bottom-left starting location, dotted semicircles are drawn that indicate potential target positions during the experiment at 5 and 10 degrees distance from the starting location. The bottom part of the figure illustrates a time line: in each trial, a fixation cross was shown for 500-1250 ms, then the target was visible for 2000 ms, followed by a variable inter-stimulus interval of 1250-2000 ms."
images/b073ce4197a929f926f4aa0601af3a2325f7568a_Image_006.jpg,"Summary:  Depicts all the metrics in the route reconstruction task for both VirtualLeap and VirtualWalk. Most results are similar between the two modalities, except the completion time, that is longer for Virtual Leap. Virtual Leap also shows more NumberElementErrors and FormElementErrors, but it is not statistically significant.    Data:     Completion Time    Virtual Leap Virtual Walk  min 238 178  q1 381 273  q2 445 370  q3 780 478  max 906 820     NumberElementsError  FormElementsError  PlacementErrors  POIsInBlockError  POISsOrderingError    Virtual Leap Virtual Walk Virtual Leap Virtual Walk Virtual Leap Virtual Walk Virtual Leap Virtual Walk Virtual Leap Virtual Walk  min 0 0 0 0 0 1 0 0 0 0  q1 0 0 0 0 3 2 0 0 0 0  q2 0 0 0 0 3 3 2 1 1 1  q3 1 0 2 0 4 4 2 1 2 2  max 2 2 5 2 4 5 4 2 4 4     POIsDistanceError  POIsOnSideError    Virtual Leap Virtual Walk Virtual Leap Virtual Walk  min 0.030555556 0.016666667 0 0  q1 0.088888889 0.064583333 0 0  q2 0.116666667 0.111111111 0.2 0.2  q3 0.169444444 0.216666667 0.2 0.4  max 0.326666667 0.275833333 0.67 0.75"
images/b073ce4197a929f926f4aa0601af3a2325f7568a_Image_007.jpg,"Summary:  It depicts all metriccs for the real-world exposure task for both Virtual Leap and Virtual Walk. Results are very similar between approaches, for all metrics.    Data:     Route Errors  Missing POIs    Virtual Leap Virtual Walk Virtual Leap Virtual Walk  min 0 0 0 0  q1 0 0 0.75 1.5  q2 0 0 4 3  q3 0.75 1 5 3.5  max 3 2 5 7     Route Accuracy  POI Accuracy  Referred POIs Accuracy    Virtual Leap Virtual Walk Virtual Leap Virtual Walk Virtual Leap Virtual Walk  min 0.65 0.55 0.3125 0.09375 0.833333333 0.5625  q1 0.7875 0.75 0.3125 0.34375 0.833333333 0.7  q2 0.9 0.8 0.4375 0.59375 0.854166667 0.833333333  q3 0.9375 0.975 0.796875 0.703125 0.89375 0.915178571  max 1 1 0.9375 0.9375 0.9375 0.95     Time (Real)  Time (Virtual)    Virtual Leap Virtual Walk Virtual Leap Virtual Walk  min 130 131 270 158  q1 163 153.5 315.75 406  q2 197.5 260 416 477  q3 268.75 352 485.5 482  max 334 397 499 507"
images/fc76954a4eca8adbdbec961d479c22e6d0d1a1cb_Image_009.png,"The bar graph consists of the math scores from 0 to 10 on the y axis with participants on the x axis. For each participant, her pre and post test math score and post test math) is displayed. The solid blue bar is the pre test score and the lined blue bar is the post test math score. For P1 the pre test score is 9.5 and post test is 8, for P2, both pre and post scrores are 5, for P3 pre test score is 4.5 and post test is 6, for P4 pre test score is 8.5 and post is 7, for P5 and P6 pre test score is 6 and post 7, for P7 both pre test and post are 7, for P8 both pre and post test are 6, for P9 pre test is 6 and post 6.5, for P10 pre test is 3 and post is 8, for P11 pre test is 4.5 and post is 7.5, for P12 pre test is 3 and post is 6 , for P13 pre is 3 and post 5, for P14 pre is 8 and post is 7.5, for P15 pre is 8 and post is 6.5, for P16 pre is 5 and post is 6.5, for P17 pre is 8 and post is 9 and for P18, pre is 7.5 and post is 8."
images/7ce152841cc96d0d4c20e8a67c43692e1b742ddb_Image_010.jpg,"A bar graph showing the feature importance by category. Germane was the most important category followed by Intrinsic, Participant's Characteristics, and Extraneous."
images/7ce152841cc96d0d4c20e8a67c43692e1b742ddb_Image_012.png,This graph displays the three most important features overall and for each model. Both transparency and height of the blocks represent the feature importance value.
images/4aa65bbc0da30f1f761722f5db7d3bffd49ea29b_Image_001.jpg,Line charts showing the transition in the number of completed or returned HITs (above) and active monthly users (bottom).
images/4aa65bbc0da30f1f761722f5db7d3bffd49ea29b_Image_002.jpg,A histogram of the number of HIT performed by workers. More than 90% of workers completed less than 3000 HITs making the distribution long tail.
images/4aa65bbc0da30f1f761722f5db7d3bffd49ea29b_Image_004.jpg,A line chart showing the change in the number of clusters formed as the paramter D (interval between HITs) changes. The change in the number of clusters diminishes after D=1min.
images/4aa65bbc0da30f1f761722f5db7d3bffd49ea29b_Image_005.jpg,Three kernel density estimation plots showing the distributions of per-HIT and per-cluster hourly wages. The blue and green lines indicate median and mean.
images/4aa65bbc0da30f1f761722f5db7d3bffd49ea29b_Image_006.jpg,Three kernel density plots showing the distributions of per-worker hourly wages based on the interval-based and cluster-based methods.
images/4aa65bbc0da30f1f761722f5db7d3bffd49ea29b_Image_007.jpg,A scatter plot showing a relationship between HIT reward and hourly wage. A black dashed line represents the model that is fit to the data using an ordinary least square regression.
images/4aa65bbc0da30f1f761722f5db7d3bffd49ea29b_Image_011.jpg,Points above the dashed line represent requesters who are paying above the minimum wage.
images/4aa65bbc0da30f1f761722f5db7d3bffd49ea29b_Image_012.jpg,Relatively high and less varying payment indicates that requesters who post high reward HITs treat workers fairly.
images/4aa65bbc0da30f1f761722f5db7d3bffd49ea29b_Image_014.jpg,"(1) High paying ""video evalution"" HITs push the hourly wage distribution up. (2) The CC distribution is skewed toward left by low hourly wages of ""transcribe data"" and ""transcribe image"" tasks."
images/ab98b531389db9db660a3538f68e45c19895d7d4_Image_002.jpg,"This image shows two visualizations: a timeseries visualization showing when pointing errors occured, and a piechart visualization showing which websites had the most pointing errors."
images/d07cc441fe600f1b4f6590cfa82fcb979f23fe4d_Image_006.gif,"Mean number of times help was required, with standard deviations for each interface configuration"
images/d07cc441fe600f1b4f6590cfa82fcb979f23fe4d_Image_009.gif,"Mean rank for each interface configuration (4 = most preferred, 1 = least preferred)"
images/1d8ad5af9bbcbf4266aa6d7c049084a4e6584373_Image_001.jpg,"(a) Age distribution: 18 respondents were under 20, 70 between 20 to 25, 186 between 26 to 30, 137 between 31 to 35, 113 over 36, and 3 unkown. (b) Highest level of education: 16 respondents had high school degree, 150 had college degree, 269 had bachelor degree, and 92 had master or above. (c) Location distribution: Respondents were from most provinces of China, and a lot are from tier 1 cities. (d) Experience using live streaming: 52 had used less than 3 months, 106 had used 4 to 6 months, 140 had used 7 to 12 months, 169 had used 1 to 2 years, and 60 had used more than 2 years."
images/2ad9fb4a36bd91f26ad2b8d95fef54bf6a016e5c_Image_004.png,Graph with the number cumulative number of unique apps used per week. Where P4 is shown to be 40 unique apps used ahead of all the other participants by the end of the eight week.
images/2ad9fb4a36bd91f26ad2b8d95fef54bf6a016e5c_Image_005.png,Graph with the cumulative interaction time during the eight weeks. Where we see partipant 5 as the one with the lowest amount throught every week. P4 was the one with the highest interaction time.
images/471f9168db0fcb72d394222491966b97c098b1cd_Image_014.jpg,"A bar graph of participants' preferences of the markup styles. The x axis is the 12 markup styles: no_change, bold_c, bold_u, color_c, color_u, del_u, it_u, r_gray, r_size, size_u, ul_u, and ul_gray_u. The y axis is numeric, ranging from 0 to 1. The prominent feature is it_u being the most preferred with 0.5 and del_u having zero preference. Other styles ranged from 0.1 to 0.25 as their preference."
images/471f9168db0fcb72d394222491966b97c098b1cd_Image_016.jpg,"A vertical bar graph of participants' preferences of the markup styles. The x axis is the 4 markup styles: No Change, Yellow, Italics, and Underline. The y axis is numeric, ranging from 0 to 0.8. The prominent feature is No Change being the most preferred with 0.65. Other styles ranged from 0.3 to 0.45 as their preference with Italics being ahead of Yellow and Underline."
images/471f9168db0fcb72d394222491966b97c098b1cd_Image_017.jpg,"A vertical bar graph of participants' perspective of the markup styles being distracting. The x axis is the 4 markup styles: No Change, Yellow, Italics, and Underline. The y axis is numeric, ranging from 0 to 0.8. The prominent feature is No Change being the least distracting with 0.4. Other styles ranged from 0.5 to 0.7 as their preference with Italics being less distracting than Yellow and Underline."
images/471f9168db0fcb72d394222491966b97c098b1cd_Image_018.jpg,"A horizontal stacked bar graph of participants' Likert responses to the helpful question. The x axis is numeric, ranging from 0 to 100%. The y axis is the 4 markup styles: Yellow, Underline, No Change, and Italics. All markup styles had similar percentages of their scales which ranged from Strongly Disagree, Disagree, Neither agree nor disagree, Agree, and Strongly Agree. Yellow had 13.1%, 15%, 27.1%, 32.7%, and 12.1% for the scales. Underline had 15.9%, 19.6%, 19.6%, 33.6%, and 11.2%. No Change had 7.5%, 14%, 25.2%, 39.3%, and 14%. Italics had 9.3%, 18.7%, 26.2%, 31.8%, and 14%."
images/471f9168db0fcb72d394222491966b97c098b1cd_Image_019.jpg,"A horizontal stacked bar graph of participants' ranks of the markup styles. The x axis is numeric, ranging from 0 to 100%. The y axis is the 4 markup styles: Yellow, Underline, No Change, and Italics. The most prominent feature is No Change with the highest ranking. The ranks are Ranked #1, Ranked #2, Ranked #3, and Ranked #4. Yellow had 18.7%, 11.2%, 13.1%, and 57% for the ranks. Underline had 2.8%, 27.1%, 47.7%, and 22.4%. No Change had 66.4%, 12.1%, 8.4%, and 13.1%. Italics had 12.1%, 49.5%, 30.8%, and 7.5%."
images/db1abe8f1d2842a94c1e7c8c4f22acf305f4c4cb_Image_004.jpg,"Graph of how many participants solved the puzzle: 100% with causal order, 63% with non-causal order."
images/db1abe8f1d2842a94c1e7c8c4f22acf305f4c4cb_Image_005.jpg,"Graph of solution times: mean of 6.35 minutes with causal order, mean of 10.63 minutes with non-causal order."
images/db1abe8f1d2842a94c1e7c8c4f22acf305f4c4cb_Image_009.jpg,"Mean solution times of the Experiment 3 interfaces measured in number of clicks. 98.72 with continuous, 88.88 with follow and 113.87 with discontinuous."
images/79f77995d06aa29b5a37e5fc3a4d5e7548abf248_Image_005.jpg,Data table visualized as stacked ranks:  Rank 1 Rank 2 Rank 3 embedded11 6 10 menu 7 14 14 auto 7 11 10
images/79f77995d06aa29b5a37e5fc3a4d5e7548abf248_Image_008.jpg,Stacked rank results chart for the following data: Rank 1 E 33 Rank 2 E 4 Rank 3 E 5 Rank 1 A 6 Rank 2 A 18 Rank 3 A 7 Rank 1 M 15 Rank 2 M 14 Rank 3 M 6
images/e5aa37a7a87b1f3ea9afab6791e02fe2aa8872ab_Image_006.jpg,"Two grouped bar charts displaying % of Accounted Variance (Adjusted squared R):
Comprehension Model 1: Demographic at 25.6%
Comprehension Model 2: Demographic and Technology at 38.2%
Significance code between the comprehension models: **
Subjective Model 1: Demographic at 15.3%
Subjective Model 2: Demographic and Technology at 33.5%
Significance code between the subjective models: ***"
images/e5aa37a7a87b1f3ea9afab6791e02fe2aa8872ab_Image_007.gif,"Two graphs: Comprehension and Subjective. 
Comprehension
y-axis: % of squared R and x-axis: ten bar charts with confidence intervals. The values for each of the bars are given as (percentage, lower, upper):
SchoolType: 0.4756, 0.1884, 0.6030
GameGroup: 0.1011, 0.0252, 0.2820
Gender: 0.0312, 0.0071, 0.1350
Describe: 0.0608, 0.0083, 0.2200
WhenBecome: 0.0394, 0.0043, 0.1790
HomeASL: 0.0520, 0.0054, 0.2090
InternetSearch: 0.1240, 0.0196, 0.2930
PositiveAttitudes: 0.0536, 0.0064, 0.1530
ASLChat: 0.0502, 0.0083, 0.1940
SeenBefore: 0.0121, 0.0047, 0.1100
Subjective
y-axis: % of squared R and x-axis: six bar charts with confidence intervals. The values for each of the bars are given as (percentage, lower, upper):
SchoolType: 0.1149, 0.0245, 0.3400
WhenLearn: 0.0260, 0.0073, 0.1680
HomeASL: 0.2561, 0.0430, 0.5210
ComputerComplex: 0.0478, 0.0031, 0.2330
MediaSharingSubscale: 0.3158, 0.0595, 0.5490
AnimationAttitude: 0.2394, 0.0270, 0.4690"
images/13edf7dd51106ede13ea81ad69cd311aff29b05e_Image_005.jpg,"A 3D convex hull of points plotted in a 3D Cartesian space, where the axes represent clarity, speed, and Qwerty similarity and range from 0 to 1. The convex hull faces almost perfectly away from the origin at a 45 degree diagonal fashion. The hull is relatively symmetric, and the points near the middle of the whole appear to have coordinates of roughly (0.7, 0.7, 0.7)."
images/8bba1845a85370618cd5c400ec8be42208554549_Image_002.jpg,"Figure 2 - Histogram showing the distribution of word error rate of transcriptions generated by individual transcribers. Clips at intelligibility level 50 tended to have low word error rate, those at intelligibility level 30 tended to have high word error rate, and those at intelligibility level 40 had more evenly distributed word error rate.    Figure 3 - Bar graph showing average word error rates at the three intelligibility levels (30, 40, 50), for both automated and individual crowd worker approaches. Word error rate increased as clip intelligibility decreased. Individual transcribers outperformed the automated approach at each intelligibility level."
images/8bba1845a85370618cd5c400ec8be42208554549_Image_003.jpg,"Figure 2 - Histogram showing the distribution of word error rate of transcriptions generated by individual transcribers. Clips at intelligibility level 50 tended to have low word error rate, those at intelligibility level 30 tended to have high word error rate, and those at intelligibility level 40 had more evenly distributed word error rate.    Figure 3 - Bar graph showing average word error rates at the three intelligibility levels (30, 40, 50), for both automated and individual crowd worker approaches. Word error rate increased as clip intelligibility decreased. Individual transcribers outperformed the automated approach at each intelligibility level."
images/8bba1845a85370618cd5c400ec8be42208554549_Image_004.jpg,"Figure 4 - Scatter plot plotting the word error rate of one randomly sampled crowd worker transcription on the X axis, and the average word error rate of the rest of the transcriptions they submitted on the Y axis. There was a positive correlation between the two groups across the collected data."
images/8bba1845a85370618cd5c400ec8be42208554549_Image_008.jpg,"Figure 5 - Three line graphs showing word error rate of worker transcriptions in a 10-step iterative workflow, with step number on the X axis and word error rate on the Y axis. The first graph (intel 30) shows iteration fails to improve word error rate The second graph (intel 40) shows iteration produces transcriptions with significantly lower word error rate after 10 steps. The third graph (intel 50) shows iteration is able to produce transcriptions with average word error rate below 0.1, significantly outperforming automated and individual human approaches."
images/8bba1845a85370618cd5c400ec8be42208554549_Image_009.jpg,"Figure 6 - Line graph with iteration step on the X axis and cosine similarity on the Y axis, with one line for each of three intelligibility levels (30, 40, 50). Worker transcriptions tended to converge resulting in overall increasing cosine similarity with each iteration step.    Figure 7 - Line graph showing word error rate of worker transcriptions in a 10-step iterative workflow for the Alexa commands dataset. ASR transcription word error rate is constant across all 10 steps (at about 0.84) and average individual transcription word error rate is constant across all 10 steps (at about 0.4). Both are represented by horizontal lines. The iterative approach produced significantly lower word error rates than both other approaches, with a downwards trending line as the number of iteration steps increased."
images/8bba1845a85370618cd5c400ec8be42208554549_Image_010.jpg,"Figure 6 - Line graph with iteration step on the X axis and cosine similarity on the Y axis, with one line for each of three intelligibility levels (30, 40, 50). Worker transcriptions tended to converge resulting in overall increasing cosine similarity with each iteration step.    Figure 7 - Line graph showing word error rate of worker transcriptions in a 10-step iterative workflow for the Alexa commands dataset. ASR transcription word error rate is constant across all 10 steps (at about 0.84) and average individual transcription word error rate is constant across all 10 steps (at about 0.4). Both are represented by horizontal lines. The iterative approach produced significantly lower word error rates than both other approaches, with a downwards trending line as the number of iteration steps increased."
images/a92be5bddb46da574738c6452582c9a5939958c3_Image_003.jpg,Figure 3. Each panel shows the random walk through the interface space via the Metropolis algorithm with a different value for scalar k with T (arbitrarily) at 10. Each data point represents the WPM for an interface arrangement with a higher efficiency than the “current” arrangement.
images/c7cbe32734918f335533efd49f9c46e69e2e14b4_Image_003.jpg,"four boxplot charts showing how the tap xoffset, yoffset, duration and movement characteristics differed between participants"
images/c7cbe32734918f335533efd49f9c46e69e2e14b4_Image_004.jpg,"individual line graphs for each participant, tracing the variances of their daily average tap xoffset characteristics"
images/c7cbe32734918f335533efd49f9c46e69e2e14b4_Image_005.jpg,"bar graph showing the three gesture recognisers accuracies; baseline 85%, user specific 79.7% and session specific 95.1%"
images/c7cbe32734918f335533efd49f9c46e69e2e14b4_Image_006.jpg,"bar graph showing the effect of the subject used to train the models, user specific group 59%, individual, 82.6%; session specific group 97%, individual 93.6% recognition accuracy"
images/12bc05ca02519f15117f08e93d961138a805cc0d_Image_001.gif,Figure 1. QS Video posts per year. Our dataset is colored in orange with vertical stripes.
images/dc3ec04644d37f6d54893db29992e15f9a7f38a8_Image_008.jpg,"The figure shows a curvilinear relationship between the topic overlap of a given community with other communities and the activity level of this community. Low topic overlap and high topic overlap results in low activity level, while moderate topic overlap results in highest activity level."
images/90f8a200755d05d7f41af45fb4883e62a1ca831d_Image_007.jpg,"Line graph of VoiceOver speed (x-axis) vs. Words per Minute (y-axis), with two segmented curves: one for rhyme test questions, and one for transcription and yes/no questions. The exact values, in CSV format, are:  VoiceOver speed, Words per Minute - Rhyme test questions, Words per minute - Transcription and yes/no questions  14, 101, 97  29, 139, 132  43, 233, 208  57, 357, 311  71, 501, 402  86, 651, 462  100, 766, 506"
images/90f8a200755d05d7f41af45fb4883e62a1ca831d_Image_010.jpg,"Line plot of Age (x-axis) vs. Listening Rate (y-axis) with two segmented curves: one for sighted participants, and one for visually impaired participants. The exact values, in CSV format, are:  Age (years), Listening Rate - sighted, Listening Rate - visually impaired  0-15, 49.86 (std err 7.04), 72.16 (std err 5.25)  15-30, 56.15 (std err 1.46), 70.97 (std err 3.36)  30-45, 59.04 (std err 2.39), 66.78 (std err 3.68)  45-60, 48.97 (std err 3.08), 38.51 (std err 4.70)  60-75, 55.19 (std err 3.38), 29.02 (std err 5.30)"
images/90f8a200755d05d7f41af45fb4883e62a1ca831d_Image_011.jpg,"Scatterplot of Age (years) vs. Screen Reader Adoption Age (years). Each dot represents one of our 123 visually impaired participants. Dots are colored by Listening Rate on a grayscale, with white being 0 and black being 100. Dots appear clustered along a line with slope just under 1. Darker dots are clustered at the bottom-left (low age and low screen reader adoption age), and become lighter moving along the line to the upper-right (high age and high screen reader adoption age). The upper-left  (low age and high adoption age) and lower-right areas (high age and low adoption age) are empty."
images/de6562e7c3736b7e0c94f62f26ea1f77d44e4eff_Image_087.jpg,"This figure has two graphs that show the average accuracy depending on the background environment of objects: vanilla and wild.  The graph for the vanilla environment is shown on left and the graph for the wild environment is shown on right.  In the vanilla environment, the model achieves 0.754 (std: 0.086), 0.747 (std: 0.102), and 0.704 (std: 0.028) on the HO, CO, and O method with the B data, respectively, and 0.937 (std: 0.011), 0.933 (std: 0.037), and 0.863 (std: 0.028) on the HO, CO, and O method with the S data, respectively.  In the wild environment, the model achieves 0.542 (std: 0.047), 0.667 (std: 0.040), and 0.532 (std: 0.065) on the HO, CO, and O method with the B data, respectively, and 0.796 (std: 0.095), 0.905 (std: 0.053), and 0.853 (std: 0.046) on the HO, CO, and O method with the S data, respectively."
images/de6562e7c3736b7e0c94f62f26ea1f77d44e4eff_Image_088.jpg,"The figure consists of three graphs that show the average accuracy depending on the sample size during training, referred to as k-shot where k is the number of images used for training --- three sample sizes (20, 5, 1).  When using 20 images per object for training, the model achieves 0.618 (std: 0.114), 0.705 (std: 0.075), and 0.608 (std: 0.098) on the HO, CO, and O methods with the B data, respectively, and 0.855 (std: 0.087), 0.888 (std: 0.064), and 0.859 (std: 0.039) on the HO, CO, and O methods with the S data, respectively.  When using 5 images per object for training, the model achieves 0.539 (std: 0.099), 0.595 (std: 0.112), and 0.550 (std: 0.098) on the HO, CO, and O methods with the B data, respectively, and 0.788 (std: 0.098), 0.818 (std: 0.058), and 0.811 (std: 0.052) on the HO, CO, and O methods with the S data, respectively.  When using 1 image per object for training, the model achieves 0.400 (std: 0.068), 0.450 (std: 0.090), and 0.424 (std: 0.053) on the HO, CO, and O methods with the B data, respectively, and 0.587 (std: 0.056), 0.614 (std: 0.094), and 0.611 (std: 0.056) on the HO, CO, and O methods with the S data, respectively."
images/35941a4414b58e76d1f92b495c3c8d90a2593315_Image_002.jpg,The Group Spinner interface showing the radar chart for a group of students for the current and previous sessions. It also shows the indicators for the selected group so the teacher can update the graph based on the indicator values.
images/35941a4414b58e76d1f92b495c3c8d90a2593315_Image_004.gif,"An empty radar chart with 10 axis: Outcome, Collaboration, Organization process, Classroom dynamics, Confidence, Behaviour, Motivation, Language, Skillfullness, and Thinking skills."
images/35941a4414b58e76d1f92b495c3c8d90a2593315_Image_007.jpg,The radar chart from T1 shows plots from 6 previous sessions as well as the yet unmodified plot for the 7th session. It shows how the teachers' focus may change from session to session.
images/a1dd85f22c7e9b2a4d3f403ca105c839b5303095_Image_003.jpg,"A bar graph titled Figure 2: H1-a for Noticed Errors (Boolean). The figure is split into three facets (subgraphs), from left to right: WRAT-L, WRAT-M, and WRAT-H. The vertical axis ranges from 0 to 1, with ticks at increments of 0.1. On the horizontal axis are the labels for the WER accuracy levels in the study: Desktop, Cloud, and Human. In the WRAT-L facet, all pairwise comparisons are not significant, and the means are approximately: 0.55 for Desktop, 0.45 for Cloud, and 0.4 for Human. In the WRAT-M facet, only the Desktop-Human pairwise comparison was significant with two stars, and the means are approximately: 0.7 for Desktop, 0.65 for Cloud, and 0.55 for Human. In the WRAT-H facet, all pairwise comparisons are not significant, and the means are approximately: 0.95 for Desktop, 0.9 for Cloud, and 0.85 for Human."
images/a1dd85f22c7e9b2a4d3f403ca105c839b5303095_Image_004.jpg,"A stacked bar graph titled Figure 4: H1-c for ASR Did a Good Job (Likert). The figure is split into three facets (subgraphs), from left to right: WRAT-L, WRAT-M, and WRAT-H. The vertical axis ranges from 0% to 100%, with ticks at 10% increments. On the horizontal axis are the labels for the WER accuracy levels in the study: Desktop, Cloud, and Human. The bar graph displays the percentage of answers for each choice: Strongly Disagree, Disagree, Neither agree nor disagree, Agree, Strongly Agree. In the WRAT-L facet, all pairwise comparison lines are not significant and the overall percentages are: 15% Strongly Disagree, 15% Disagree, 25% Neither agree nor disagree, 25% Agree, 10% Strongly Agree. In the WRAT-M facet, the Desktop-Cloud pairwise comparison was significant with two stars, the Desktop-Human pairwise comparison was significant with three stars, and the overall percentages are: 15% Strongly Disagree, 15% Disagree, 15% Neither agree nor disagree, 15% Agree, 25% Strongly Agree. In the WRAT-H facet, both Desktop-Cloud and Desktop-Human had significant pairwise comparisons with three stars, and the overall percentages are: 25% Strongly Disagree, 20% Disagree, 10% Neither agree nor disagree, 10% Agree, 20% Strongly Agree."
images/a1dd85f22c7e9b2a4d3f403ca105c839b5303095_Image_005.jpg,"A bar graph titled Figure 6: H1-e for Evaluation of Accuracy (Numeric). The figure is split into three facets (subgraphs), from left to right: WRAT-L, WRAT-M, and WRAT-H. The vertical axis ranges from 0 to 100, with ticks at increments of 10. On the horizontal axis are the labels for the WER accuracy levels in the study: Desktop, Cloud, and Human. In the WRAT-L facet, all pairwise comparisons are not significant, and the means are approximately: 55 for Desktop, 60 for Cloud, and 65 for Human. In the WRAT-M facet, the Desktop-Cloud and Desktop-Human pairwise comparison was significant with three stars, the Cloud-Human pairwise comparison had one star, and the means are approximately: 55 for Desktop, 65 for Cloud, and 70 for Human. In the WRAT-H facet, the Desktop-Cloud and Desktop-Human pairwise comparisons were significant at three stars, and the means are approximately: 50 for Desktop, 65 for Cloud, and 75 for Human."
images/a1dd85f22c7e9b2a4d3f403ca105c839b5303095_Image_006.jpg,"A boxplot titled Figure 12: H2-d for Accuracy of Evaluation (Ordinal Scale). The vertical axis has ticks representing the answer choices: Zero, Low, Medium, High, Perfect. On the horizontal axis are the labels for the WRAT accuracy levels in the study: WRAT-L, WRAT-M, and WRAT-H. Only the WRAT-M/WRAT-H pairwise comparison was significant with one star. Please refer the subsection on the current page for the median and modes for the WRAT levels."
images/a1dd85f22c7e9b2a4d3f403ca105c839b5303095_Image_007.jpg,"A boxplot titled Figure 10: H2-b for Errors Prevented Understanding (Likert). The vertical axis has ticks representing the answer choices: Strongly Disagree, Disagree, Neither agree nor disagree, Agree, Strongly Agree. On the horizontal axis are the labels for the WRAT accuracy levels in the study: WRAT-L, WRAT-M, and WRAT-H. All of the pairwise comparisons were not significant. Please refer the subsection on the previous page for the median and modes for the WRAT levels."
images/a1dd85f22c7e9b2a4d3f403ca105c839b5303095_Image_008.jpg,"A boxplot titled Figure 11: H2-c for ASR Did a Good Job (Likert). The vertical axis has ticks representing the answer choices: Strongly Disagree, Disagree, Neither agree nor disagree, Agree, Strongly Agree. On the horizontal axis are the labels for the WRAT accuracy levels in the study: WRAT-L, WRAT-M, and WRAT-H. Both WRAT-M/WRAT-H and WRAT-L/WRAT-H pairwise comparisons were significant with two stars. Please refer the subsection on the previous page for the median and modes for the WRAT levels."
images/a1dd85f22c7e9b2a4d3f403ca105c839b5303095_Image_009.jpg,"A bar graph titled Figure 13: H2-e for Evaluation of Accuracy (Numeric). The vertical axis ranges from 0 to 100, with ticks at increments of 10. On the horizontal axis are the labels for the WRAT accuracy levels in the study: WRAT-L, WRAT-M, and WRAT-H. All of the pairwise comparisons were not significant. Please refer the subsection on the current page for the means and standard errors for the WRAT levels."
images/a1dd85f22c7e9b2a4d3f403ca105c839b5303095_Image_010.jpg,"A bar graph titled Figure 14: H2-f for Comprehension Quiz Success (Mult. Choice). The vertical axis ranges from 0% to 100%, with ticks at increments of 10%. On the horizontal axis are the labels for the WRAT accuracy levels in the study: WRAT-L, WRAT-M, and WRAT-H. All of the pairwise comparisons were significant at three stars. Please refer the subsection on the current page for the means and standard errors for the WRAT levels."
images/505187170911c92ea3c8b2f2eeb0fe0a1fb26738_Image_006.png,"Retention scores in a bar chart. For both user groups, differences between conditons are small and non-significant."
images/505187170911c92ea3c8b2f2eeb0fe0a1fb26738_Image_007.png,"Transfer scores in a bar chart. For both user groups, differences between conditons are small and non-significant."
images/505187170911c92ea3c8b2f2eeb0fe0a1fb26738_Image_008.png,"Bar chart with average time on each visual sources for DHH participants: slides, ASL, and instructor. Differences between control and SlidePacer conditions are significant for all visual sources."
images/505187170911c92ea3c8b2f2eeb0fe0a1fb26738_Image_009.png,Bar chart with perceived pace. SlidePacer has an effect on perceived pace from approapriate to slightly slow.
images/505187170911c92ea3c8b2f2eeb0fe0a1fb26738_Image_010.png,"Bar chart with average time on each visual sources for hearing participants: slides, ASL, and instructor. Differences between control and SlidePacer conditions are significant for all visual sources."
images/505187170911c92ea3c8b2f2eeb0fe0a1fb26738_Image_011.png,Bar chart with perceived dificulty for both user groups and conditions. There are no significant differences beetween control and SlidePacer conditions.
images/09f444597b50aebe550b5efd1368a55953d8ddd1_Image_005.jpg,"The bar chart shows the average selection error (y-axis, in percent) for all feedback conditions, and contains 10 vertical bars, one for each condition. The x-axis groups bars by the feedback designs, from left: Geiger, Pitch, Constant and Control. There are three coloured bars in the Geiger, Pitch and Constant, one for each of the Wrist, Object and Both locations. The Control Design only has a single bar (for Object). The values, from left to right, are as follows: Geiger-Wrist = 17.6%, Geiger-Object = 12%, Geiger-Both = 6.5%; Pitch-Wrist = 13%, Pitch-Object = 9.2%, Pitch-Both = 15.7%; Constant-Wrist = 25%, Constant-Object = 25.9%, Constant-Both = 21.3%; Control-Object = 36.1%."
images/09f444597b50aebe550b5efd1368a55953d8ddd1_Image_006.jpg,"The bar chart shows the average selection time (y-axis, in milliseconds) for all feedback conditions, and contains 10 vertical bars, one for each condition. The x-axis groups bars by the feedback designs, from left: Geiger, Pitch, Constant and Control. There are three coloured bars in the Geiger, Pitch and Constant, one for each of the Wrist, Object and Both locations. The Control Design only has a single bar (for Object). The values, from left to right, are as follows: Geiger-Wrist = 4881ms, Geiger-Object = 4686ms, Geiger-Both = 4020ms; Pitch-Wrist = 3938ms, Pitch-Object = 3107ms, Pitch-Both = 4268ms; Constant-Wrist = 3195%, Constant-Object = 3568ms, Constant-Both = 3972ms; Control-Object = 2666ms."
images/09f444597b50aebe550b5efd1368a55953d8ddd1_Image_007.jpg,"The bar chart shows the average selection error (y-axis, in percent) for all feedback conditions in Study 2, and contains 10 vertical bars, one for each condition. The x-axis groups bars by the feedback designs, from left: Geiger, Pitch, Constant and Control. There are three coloured bars in the Geiger, Pitch and Constant, one for each of the Wrist, Object and Both locations. The Control Design only has a single bar (for Object). The values, from left to right, are as follows: Geiger-Wrist = 35.4%, Geiger-Object = 22.9%, Geiger-Both = 14.6%; Pitch-Wrist = 35.4%, Pitch-Object = 27.1%, Pitch-Both = 45.8%; Constant-Wrist = 37.5%, Constant-Object = 20.8%, Constant-Both = 33.3%; Control-Object = 54.2%."
images/9c3dff78167c8fa4d89107bcf0921c6f46ddb569_Image_008.jpg,The results of a qualtiative analysis of participants’ rationales for rating clips. Blue bars extending to the right of the central axis indicate attributes cited as positive. Red bars extending to the left of the central axis indicate attributes cited as negative.
images/5e2b43efb44af88bae17ed1e7932d3df1506dfb6_Image_005.jpg,"This table contains one row for each of the nine prompts showing the statistical analysis results of question responses for those prompts in the online questionnaire data. There are two parts: one analyzing responses in part Q1 and one analyzing responses in part Q2. For part Q1, Fisher tests found significant differences between participant's responses for the three conditions for 7 prompts (prompts 2, 3, 4, 5, 6, 8, and 9). Prompt 7 was not included in Q1. For Q2, Friedman tests found significant differences between the three conditions for prompts 2, 4, 6, 7, 8, and 9."
images/9e93e21f6e300a80b870a31ed6c33e8c6ec2d81e_Image_006.jpg,"Bar chart of ratings by gesture category, for blind and sighted participants.  Values on a scale from 1 to 7: Tap gestures: Rated 6.1 by blind participants, 6.3 by sighted participants Flick gestures: Rated 6.5 by blind participants, 6.3 by sighted participants Multi-touch gestures: Rated 5.7  by blind participants, 4.3 by sighted participants Shape gestures: Rated 4.9 by blind participants, 5.7  by sighted participants Symbol gestures: Rated 5.4 by blind participants, 5.7 by sighted participants"
images/020621edc59be97e9a2d086b5133a48f6c62cc9c_Image_002.jpg,Graph showing Audio Only vs. Audio + Video at 95% confidence interval. Y axis is difference in words correct. X axis indicates the 7 conditions. Mean difference and 95% confidence intervals around the differences of words correct out of 102 vs. audio only.  The only interval that crosses zero belongs to condition 3 and is not significantly different from 0.
images/020621edc59be97e9a2d086b5133a48f6c62cc9c_Image_003.jpg,"Graph showing differences in words correct for 7.5 vs. 15 vs. 30 fps at 95% confidence level.  The X axis indicates frame rates 30-15, 15-7.5, and 30-7.5).  The Y axis indicates differences in words correct. Mean difference and 95% confidence intervals around the differences of words correct out of 102 across frame rates with no AV delay. One interval that crosses zero (dotted line) is not significantly different from 0. Overall, increasing the frame rate from 7.5 fps to 15 fps or from 7.5 fps to 30 fps results in significant improvements in words correct. The difference between 15 fps and 30 fps is not significant."
images/408a505662902bbaf20ef32ac6deaf7a78e52650_Image_012.jpg,Trend of the AdoptRate of Auto-switch in Experiment 2. The error bars in the graph indicate standard deviation.
images/408a505662902bbaf20ef32ac6deaf7a78e52650_Image_021.jpg,Frequency of the participants' attempts to delete the visual feedback characters throughout Experiment 3. The error bars in the graph indicate standard deviation.
images/408a505662902bbaf20ef32ac6deaf7a78e52650_Image_022.jpg,Trend of the AdoptRate of Smart-toggle in Experiment 4. The error bars in the graph indicate standard deviation.
images/408a505662902bbaf20ef32ac6deaf7a78e52650_Image_023.jpg,The proportions of the mode errors corrected manually or by Smart-toggle for different mode error lengths (in the number of keystrokes) in Experiment 4.
images/c7b00311313d5ed6e7fbbf72a31dab397c0016b2_Image_004.png,"Mean Ratings of Like, Need, and Easy to Use between over-the-bed table and Prototypes E, F, G"
images/f1c65f5ae00874891111e9750eba23ad03421f5e_Image_004.jpg,Boxplot view of the block completion times. The median times for no and full conditions are clearly longer than the median times for out and both conditions.
images/28e2c1a3d6158c3fcb765cec4094e46ef5847a77_Image_002.jpg,"Figure 1: Three bar charts presenting the percentage of participants who are interested in knowing about particular sounds (a) at home, (b) at work, and (c) while mobile. Each chart contains pairs of bars: one representing deaf participants, and the other hard-of-hearing participants.  (a) A bar chart of the percentage of participants interested in particular sounds at home. The sounds, sorted in decreasing order of deaf participants are: appliances running, emergency alarms, appliance alerts, intruders, knocking on door, doorbell, sounds outside of the house, wake-up alarms, people knocking things over, dog barking, phone ringing, baby crying, people shouting, people laughing, children fighting, children playing, and other. The percent of deaf participants who selected each sound decreases consistently from about 70% to about 10%. Hard-of-hearing participants followed a similar trend, but about 15% more selected knocking on door, wake-up alarms, and phone ringing than deaf participants. (b) A bar chart of the percentage of participants interested in particular sounds at work. The sounds, sorted in decreasing order of deaf participants are: emergency alarms, presence of co-workers, co-workers calling attention, surrounding conversations, knocking on door, announcements, co-worker activity, gun shots, phone ringing, other, and faxes. Deaf percentages decreased from around 50% to 10%. Hard-of-hearing participants followed a similar trend, with about 20% more interest in co-workers calling attention, surrounding conversations, announcements, and phone ringing. (c) A bar chart of the percentage of participants interested in particular sounds while mobile. The sounds, sorted in decreasing order of deaf participants are: sirens, bikes or people behind, if you are in the way, honking, announcements, vehicles driving by, sounds in nature, dogs barking, airplanes or helicopters, and other. Deaf percentages decrease from about 70% to 5%."
images/28e2c1a3d6158c3fcb765cec4094e46ef5847a77_Image_004.jpg,"Figure 2: Three bar charts of missed sounds (a) at home, (b) at work, and (c) while mobile. Each chart displays the percentage of participants who reported missing sounds never, once/month, once/week, once/day, and more than once/day. There are one bar for deaf participants, and one for hard-of-hearing participants in each condition. (a) At home, about 30% of deaf participants never missed sounds and 50% missed sounds more than once per day. About 25% of hard-of-hearing participants missed sounds once/week, and about 50% more than once per day. Other responses were all under about 12%. (b) At work, the bar chart takes a U-shape for both deaf and hard-of-hearing participants. About 35% of deaf participants never missed sounds, and about 40% missed sounds more than once per day, with all other answers under 15%. Hard-of-hearing participants followed a similar curve. (c) While mobile, the bar chart takes a U-shape for both deaf and hard-of-hearing participants. About 35% of deaf participants never missed sounds, and about 50% missed more than once per day. The other responses were under about 10%. Hard-of-hearing participants followed a similar trend, but less extreme."
images/28e2c1a3d6158c3fcb765cec4094e46ef5847a77_Image_005.jpg,"Figure 3: Desired information for app notifications. Pairs of bars represent deaf and hard-of-hearing (HH) participants. The following types of information are included: identity, location, volume, length, pitch, urgency, and confidence. Possible participant responses were: absolutely essential, very important, moderately important, of little importance, and not important at all. A stacked bar chart shows user responses for each type of information. Most participants responded that identity, location, urgency, and confidence were at least moderately important, while fewer participants gave volume, length, and pitch the same importance. Deaf and hard-of-hearing responses were very similar."
images/9bd21b56644843a04823a05de227853db6ee5f07_Image_006.jpg,"In this graph, all frequency bandwidth decrease in activity across the time sample. Frequencies in order of highest to lowest activity is delta, alpha, beta, theta, ad gamma."
images/86fffe172d05cd3222cd16401caa561950c71d7b_Image_034.png,Three plots of precision versus recall in the filtering process. All three show curve that indicate recall does not drop until precision is at or near 100 percent.
images/4715303bdb871e57cbb597b7e936a6ef4aa2f71a_Image_005.png,"Box plot results show the frequency with which humans could identify the correct image from a given description, both for BrowseWithMe generated descriptions and Alt text."
images/fd420c53c56d844ccd48efd6a261907b2bc53de9_Image_008.jpg,A line chart showing the average accuracies of the different modes for the Bar Chart task. The first session is the lowest and then the lines tend to increase. The fifth session has a large drop in accuracy for the silent and verbal modes. The Silent and Verbal lines tend to be similar and the Finger Pointing line is higher in the last three sessions. There is a single point for the Braille modes in session six which is between Silent and Verbal Modes and below Finger Pointing.
images/fd420c53c56d844ccd48efd6a261907b2bc53de9_Image_009.jpg,"A line chart showing the average time it took participants on all tasks. The y-axis of the chart is time in seconds (ranges from 0 to 60), the x-axis of the chart is session number (ranges from 1 to 6). There is a line for the three modes: Silent, Verbal and Finger Pointing. They all appear to be going down, but there is a big spike in the Verbal mode line at session 4. In general, the Finger Pointing mode is the highest (takes the most time), the Silent mode is next and the Verbal takes the least amount of time, although in the fourth and sixth sessions, the Verbal line is above the Silent one. There is a dot corresponding to the Braille mode at Session 6, it is between the Verbal and Silent modes."
images/7bb3ebe039b18f33e7d0df5549c84ebe1e8f093f_Image_003.jpg,Figure 3. Task durations across values. Error bars denote 95% confidence intervals.
images/7bb3ebe039b18f33e7d0df5549c84ebe1e8f093f_Image_004.jpg,Figure 4. Interaction count (drags) across values. Error bars denote 95% confidence intervals.
images/7bb3ebe039b18f33e7d0df5549c84ebe1e8f093f_Image_005.jpg,Figure 6. Scatter plot and regressions of our model. Grey indi- cates the display; green areas show 95% prediction intervals.
images/7bb3ebe039b18f33e7d0df5549c84ebe1e8f093f_Image_008.jpg,Figure 8. Task durations across values. Error bars denote 95% confidence intervals.
images/7bb3ebe039b18f33e7d0df5549c84ebe1e8f093f_Image_009.jpg,Figure 7. Relationship between values in original input space (top) and corrected input space (bottom).
images/7bb3ebe039b18f33e7d0df5549c84ebe1e8f093f_Image_010.jpg,Figure 10. Aggregation of drag movement across positive (top) and negative (bottom) values. The shaded areas show the pro- portion of interactions in different parts of the motor space.
images/7bb3ebe039b18f33e7d0df5549c84ebe1e8f093f_Image_011.jpg,Figure 9. Interaction count (drags) across values. Error bars denote 95% confidence intervals.
images/49cb31597722ec0acbf46eec54128ef8947dab02_Image_008.jpg,"Graph of Model 6 priors showing two lines with a negative slope. The slope is the same, with the black line having an intercept of about +2 compared to the red line. Choice set size is the independent variable and satisfaction is the dependent variable."
images/49cb31597722ec0acbf46eec54128ef8947dab02_Image_010.jpg,"Graph of Model 7 priors showing two lines with a negative slope. The slope is different for the two lines: black, which lies above red, has a very slight negative slope (a change of about -.5 satisfaction). The red line slope is steeper (a change of about -4 satisfaction). Choice set size is the independent variable and satisfaction is the dependent variable."
images/49cb31597722ec0acbf46eec54128ef8947dab02_Image_014.jpg,"Graph of M1 posteriors showing a flat line. Choice set size is the independent variable and satisfaction is the dependent variable. It is identical to Table 3, Model 1"
images/49cb31597722ec0acbf46eec54128ef8947dab02_Image_015.jpg,"Graph of M6 posteriors showing two nearly flat lines. A slight negative slope is just visible. The slope is the same, with the black line having an intercept of about +1 compared to the red line. Choice set size is the independent variable and satisfaction is the dependent variable."
images/49cb31597722ec0acbf46eec54128ef8947dab02_Image_016.jpg,"Graph of Model 7 posteriors showing two nearly flat lines. The slope is different for the two lines. Black, which lies above red, has a very slight positive slope. The red line has a slight negative slope. The slopes are barely visible. Choice set size is the independent variable and satisfaction is the dependent variable."
images/1110852f906fe08d42814a051e4e8c15f0b930b5_Image_002.jpg,"Plot of how mean discrimination ellipsoid volume (dependent) varies across eight different lighting ratios (independent). As lighting ratio increases (i.e., the room gets brighter or the screen gets darker), ellipsoid volume increases (i.e., participant color differentiation abilities decrease)."
images/1110852f906fe08d42814a051e4e8c15f0b930b5_Image_005.jpg,"Histogram plot of mean discrimination volumes (bin size = 250) for our participants. Rises sharply from 0-250 (over 500 participants) to a peak at 500-750 (over 3000 participants). Histogram then falls off with a very long tail. Minimum volume is 21.68, 25th quartile is at volume 804.62, 50th quartile (median) is at volume 1558.38, 75th quartile is at volume 3223.60, maximum volume is 1058397.75. Histogram is cut off above volumes of 12000."
images/1110852f906fe08d42814a051e4e8c15f0b930b5_Image_007.jpg,"Plots of lower and upper estimates of the number of unique differentiable colors (independent) versus discrimination ellipsoid volume (dependent). Plots start very high (above 20000 unique colors), fall quickly as ellipsoid volume increases, and then level out into a long-tail. At volume=1000, upper estimate is about 10000 colors and the lower estimate is about 5000 colors; at volume=2000, upper=5000 and lower=2000; at volume 4000, upper=3000 and lower=1000."
images/1110852f906fe08d42814a051e4e8c15f0b930b5_Image_012.jpg,"Plot of mean proportion of image pixels differentiable (independent) for 0% - 100% of the population (dependent) for websites and infographics. Increasing from 0% of the population, both plots start at 100% differentiable and gradually fall to 80% differentiable at 75% of the population. Plots begin to diverge here as they both fall off more quickly until a discontinuity plateau is reached at 88% of the population (websites = 60% differentiable, infographics = 50% differentiable). Plateau gradually declines to 99% of population (websites = 55% differentiable, infographics = 45% differentiable), and then both plots fall to 0% differentiable for 100% of the population."
images/4e36e8637a6e0892eb2d6cda79537a5e0b189968_Image_004.jpg,"This graph depicts a series of boxplots for the distrubution of the average number of concurrent touches per trial for each participant. Key takeaway: each participant, except P4, averages more than 1 concurrent touch. The highest average is P10 with an average of about five and a half concurrent touches. Many of the participants average between 2 to 4 concurrent touches."
images/48fc79059aecbe211fe15aaca6c96d2dff7650fc_Image_012.jpg,"A graph showing precision-recall curves for overall labeling performance, and performance for each of the four types of labels. Curb ramp performance is best, with performance for missing ramps, obstructions, and surface problems all being somewhat worse."
images/48fc79059aecbe211fe15aaca6c96d2dff7650fc_Image_015.jpg,"A graph showing improvements in the models' precision and recall as more training data is added. The x-axis uses a log scale ranging from approximately 500 crops in the training set, to approximately two hundred thousand crops in the training set. Both overall precision and overall recall increase from approximately 60 percent to approximately 80 percent."
images/2a6f6d7a0996d638a88f5842f4d31574354ece8f_Image_004.jpg,"This figure is a graph of the battery power characteristics of the sensors. On the x-axis is time in days and on the y-axis is battery voltage in volts. There are three curves, all trending downward from approximately 4.2 volts. The ultra low standby curve slowly trends downwards over fifty to sixty days. The day-to-day curve trends down quicker over a two week period. Finally, the intensive use curve trends down even quicker still in three to four days."
images/2a6f6d7a0996d638a88f5842f4d31574354ece8f_Image_007.jpg,"This figure shows a graph of the sensor data from the three sensors. On the x-axis is time in seconds and on the y-axis is either acceleration (in metres per second squared) or rotation rate (in radians per second). All six channels of accelerometer and gyroscope data are shown. The data from the foot sensors is more periodic than the waist sensor, which appears noisier."
images/2a6f6d7a0996d638a88f5842f4d31574354ece8f_Image_008.jpg,"This figure shows a graph of a segment of the sensor data from both the left and right sensors on the shoes. On the x-axis is time in seconds and on the y-axis is acceleration in metres per second squared. For every stride there is a large peak followed by a trough, which represents the toe-off and heel-strike events of the step respectively. These peaks and trough pairs alternate between the left and right strides."
images/88d0f2d52847de405a413a43638329de94b8911c_Image_004.png,"A bar chart entitle time spent playing games. The vertical axis reads hours played and the horizontal axis reads p1- p8. P1, P2, P6, and P8 spent around an hour total playing VBReader (VBR) and VBWriter (VBW). P3, P4,  abd P7 spent close to 4 hours playing both games. P5 spent about an hour playing VBR and VBW and 4 hours playing VBH."
images/88d0f2d52847de405a413a43638329de94b8911c_Image_005.jpg,Line graphs showing gameplay patterns (time to enter a letter and accuracy) for VBWriter and VBReader.
images/710f0efc81ddd7ccbfc427995a7e2ed53da72046_Image_008.gif,bar chart showing average completion times for finding active devices:  card = 13.5 seconds  cash = 8 seconds  receipt 8.9 seconds
images/84e867b0e07ef33492478682a68899d99ea211d8_Image_020.jpg,"This figure is a line graph with frame index number on the horizontal axis and number of edge lines on the vertical axis. It shows both the original and filtered result. In the filtered result, the peaks are prominent and easier to identify."
images/84e867b0e07ef33492478682a68899d99ea211d8_Image_021.jpg,"This figure is a line graph with frame index number on the horizontal axis and foot position in pixels on the vertical axis. It is split into two panels, the top half shows the absolute distance of left and right feet, with an expected step function like curve. The lower panel has the first order difference of the absolute difference, and shows the expected left and right foot oscillations."
images/4f6800463ceb4c8f24cd8f4b7af90469528d3d89_Image_004.jpg,"Figure 4. Average task completion time of each task in the study. P4 did not complete app switching on the control condition, and P5 did not complete the holistic task."
images/a81adf83dbac7a957b1da4451562d85a705a780f_Image_104.jpg,"Two density plots for the two measures, adjusted number of pumps and percent change."
images/d5466ed3ad919365cc5752b7ca9693b2a8dfc167_Image_004.gif,"Figure 4. The distributions of the time performance across groups on rotation questions 10, 13 and 15."
images/d5466ed3ad919365cc5752b7ca9693b2a8dfc167_Image_005.gif,"Figure 5. The distributions of the time performance across groups on translation questions 10, 13 and 15."
images/abfd76ebf841802ffc6c26cb28e9106211a658f3_Image_002.png,"A horizontal red bar represents the passage of time. A shaded area in the middle represents the recording window. A blue dotted line is drawn through the middle of the shaded area and labeled ""Anchor Event."" The shaded portion to the left of the blue line is labeled ""Antecedent Recording"" and the shared portion to the righ tof the blue line is labeled ""Ensuing Recording."""
images/008f51c5a995cf3d19bdcf2c7bb01648774daafb_Image_008.jpg,"For each measure, we present 3 stacked graphs with the number of people who rated each scheme."
images/db59784588a97b0a1147fab50c76a495253232ff_Image_004.png,"Line graph showing histogram of differences between personalized and adjustable simulation  results for protan and deutan simulations. Differences measured in CIE Luv units) Both lines rise sharply from 0 and drop sharply at 20 units, with a long tail to around 65 units."
images/2f54a34d2bf141d33c7c10a8d4c044eebcbe3d0e_Image_004.gif,"Graph displaying the Root Mean Squared Error (RMSE) values for the two regression models: Differential Rate and Pause Insertion.   For Differential Rate, ""ASL-SPEED"" is 0.64, and ""2008 Model"" is 0.84.  For Pause Duration, ""ASL-SPEED"" is 5.31, and ""2008 Model"" is 6.23.  In both cases, the ASL-SPEED has a lower value, which indicates a better result."
images/7ad140271d649d31a0cd72fe4b56fb7febf56b69_Image_061.png,"Line charts showing there is an interaction effect of method and nation. The y axis is the total entry time, and x axis is the method. the two lines crossed with each other"
images/7ad140271d649d31a0cd72fe4b56fb7febf56b69_Image_062.png,"Two Barcharts. Y axis are total entry time and emoji entry time, x axis is the method, including ios keyboard and voicemoji. The results are described in section 6.2"
images/8d4702b2f7ebb13d75d2def7ada05968f9cc5fc8_Image_007.png,"Bar chart showing the amount of times each task was observed, broken down by app category."
images/c5134f7f6bc86cf2654aded683ff0902efc7cf57_Image_007.jpg,"Three spectrum plots of a 2Hz-2kHz swept-frequency signal, recorded signal from an accelerometer affixed to the speaker diaphragm, and from Vibrosight++."
images/4147ba46985a1fa81abcf649811afaf1353fdc6a_Image_014.jpg,Shows that users rated MultiClench sensations between 4-7 on a scale from very uncomfortable to very comfortable. And between 1-4 on a scale of not annoying at all to very annoying.
images/4147ba46985a1fa81abcf649811afaf1353fdc6a_Image_015.jpg,"Bar graph depicting 75%, 45%, 80% accuracy for hold, continuous, staggered respectively for 30s. And 85%, 65%, 90% accuracy for hold, continuous, staggered, respectively for 60s."
images/d52e19ab3da615b4bb58dd79508465894ad14264_Image_001.jpg,"A Confusion Matrix indicating the classification accuracy for each letter. None are perfectly classified. D, K, W, C are correctly classified 90% of the time. B, E, I, L, X, Y, O, P are correctly classified 80% of the time. A, F, M, N, R, G are classified 70% of the time. S, V are correctly classified 60% of the time. T is correctly classified 40% of the time. U is correctly classified 30% of the time. H and Q are correctly classified 20% of the time."
images/f007aa8f60e02b4b917f2e161733b5d2b21c56b8_Image_006.jpg,Recognition accuracy continues to improve with data from additional sessions. Collecting data in different conditions is more valuable than collecting larger volumes of data in similar conditions.
images/ea1eca1816100eddedc30c9e55a4ae0ee83fce02_Image_024.jpg,"A plot of the stiffness of traps that approach each other horizontally versus vertically. The plots (top) show that the stiffness varies considerably in the vertical case, whereas horizontally merged traps have relatively stable stiffness along the way. The bottom part shows the pressure fields during the motion until they are merged (rightmost)."
images/166d91ef569340148a9d77fe64330e4599239c2f_Image_007.png,"The left image is a heatmap of smartwatch bezel with 24 segments. The segments on the left and left top corner of this heatmap are dark red and the segments on the right, right button, and button of the display are dark green. The other image shows a spider graph with 24 data points presenting 24 segments. This graph is another representation of the heatmap but with exact screen visibility numbers."
images/166d91ef569340148a9d77fe64330e4599239c2f_Image_010.png,The image shows a smartwatch display with a line graph and the user interacting with the smartwatch bezel. There is a line starting from the touch point on the smartwatch bezel to the other side of the bezel. The intersection of this line and the data point on the graph shows the value of the data point.
images/166d91ef569340148a9d77fe64330e4599239c2f_Image_013.png,"Figure 8 shows the result of the second experiment. The median response time for Shift is approximately 4000, for FBG 2600 and for PBG 2200 milliseconds.  The other bar chart shows the response time divided by interaction techniques and mobility conditions.  Shift-walking and shift standing are very close and they are the worst. PBG-walking and PBG standing are very close and they have the best performance"
images/166d91ef569340148a9d77fe64330e4599239c2f_Image_014.jpg,Figure 9 left shows a spider graph with three interaction techniques. This spider graph shows the average response time for each one of 24 segments on the screen. For almost all of the segments PBG is faster than FBG and Shift.
images/81169d7c531a54953765b7d5ea8e0b58a481941e_Image_002.jpg,"Figure 1: ""Four charts that show an example of the four velocities captured in a template."""
images/b32fa6180fb20a8e4752df8bd5aff50ac24ad12f_Image_013.png,"Plot of the playback speed results. As the playback speed (Y axis) increased, the response speed (X axis) decreases less than linearly."
images/b32fa6180fb20a8e4752df8bd5aff50ac24ad12f_Image_014.png,Plot of the number of clips completed (Y axis) over time (X axis). The curve formed is logarithmic.
images/b32fa6180fb20a8e4752df8bd5aff50ac24ad12f_Image_015.png,"Graph comparing all of the different aggregation approaches tested, measured after each aggregation scheme was applied. Scanning with adjustment for ``early birds'' strictly outperforms other methods."
images/b32fa6180fb20a8e4752df8bd5aff50ac24ad12f_Image_017.png,"Plot of the F1 score (X axis) and count variance (Y axis). As count variance increases, so does the F1 score, with a clear correlation."
images/c21909d31d496412a868903b917cbb8b964b57d0_Image_012.png,"Figure 4: ""Task completion times for each Visualisation Modality. On average, the oscilloscope required the least task completion time compared to the other modalities. The error bars depict the standard error. Brackets indicate significant differences."""
images/c21909d31d496412a868903b917cbb8b964b57d0_Image_013.jpg,"Figure 5: ""Raw NASA-TLX scores for each modality. The user positioned tablet elicited the least workload compared to the other modalities. The error bars depict the standard error. Brackets indicate significant differences"""
images/be49605108a4c7b2cc78a9cf112a749a38a7b8fd_Image_010.gif,"A bar graph comparing the motion of the head and controller at 25, 50 and 75 degrees. The controller in all cases moves significantly more than the HMD"
images/be49605108a4c7b2cc78a9cf112a749a38a7b8fd_Image_011.png,"A scatter plot making comet like images for each cardinal direction tracked. There's one dot for each trial. The nucleus of the comet is where the controller was pointing when the user clicked, the tail is where the HMD was looking when the user clicked"
images/be49605108a4c7b2cc78a9cf112a749a38a7b8fd_Image_012.jpg,"A line graph showing 3 velocity curves for 25, 50 and 75 degrees. This graph shows the velocities for the controller angle. In the first 200 milliseconds, there is almost no spread between the 3 curves"
images/be49605108a4c7b2cc78a9cf112a749a38a7b8fd_Image_013.jpg,"A line graph showing 4 curves, one each for HMD position, HMD angle, Controller position, and Controller Angle. HMD curves are a tiny bit apart showing a lower value up until about 60%. After this the Controller angle drops below the other curves. The Controller position does as well, but not as significantly."
images/be49605108a4c7b2cc78a9cf112a749a38a7b8fd_Image_014.jpg,"A line graph showing the accuracy of the four stated conditions. the prediction curves are better for each subsequent curve, going from worst to best: KTM, KTM-7, HC-KTM-1, HC-KTM-7"
images/dfa09494b50030571735aafbe5c114cd9ba80eba_Image_003.png,"A line chart showing mean acquisition time across touch types and trial interfaces, showing magnification is the slowest touch type, and then targets list and then conventional tapping."
images/dfa09494b50030571735aafbe5c114cd9ba80eba_Image_004.png,"A bar chart showing mean error rates across touch types and interfaces, it shows lower rates for list based area touch, especially on small and dense targets. Error bars show moderate stand deviation."
images/dfa09494b50030571735aafbe5c114cd9ba80eba_Image_005.png,"A bar chat showing perceived usefulness, perceived ease of use and user acceptance, it shows that magnification is less preferred. Overall rates are positive. Error bars show moderate stand deviation."
images/88b5f0341afb94f658ade33d8cef8a30bde358b4_Image_007.jpg,"A horizontal bar graph which lists tasks on the Y-axis and percent success from 0.0%-100.0% on the X-axis. The list of tasks, with percentages, are as follows: 1) Identify objects on the pre-made slide; 91.7%. 2) Identify rectangle color; 25.0%. 3) Identify rectangle width; 58.3%. 4) Determine rectangle's and oval's positions on the slide; 50.0%. 5) Determine rectangle's and oval's positions in relation to each other; 36.4%. 6) Determine the size of the rectangle relative to the oval; 54.5%. 7) Determine the arrow's position on the slide; 45.5%. 8) Determine the direction the arrow is pointing; 0.0%. 9) Determine the text box's position on the slide; 45.5%. 10) Identify the text in the text box; 90.9%. 11) Determine the text box's position relative to the other objects; 36.4%"
images/88b5f0341afb94f658ade33d8cef8a30bde358b4_Image_010.jpg,"Box chart of durations for tasks 1-11. Time in minutes on the Y-axis, and task numbers on the X-axis. There is a higher variance in duration for task 4 than for the rest of the tasks, and it ranges from 0.25 to just over 4 minutes, with the majority between 1 and 2.5 minutes. Tasks 8 and 10 have noticeably short durations, close to zero, with little variance. 1, 2, and 11 range between 0 and 0.5 minutes. 3, 5, and 7 range between 0.25 and 1.25 minutes, and 6 and 9 reach nearly 1.5 minutes.    Box chart of durations for tasks 2-23. Half of the tasks (12, 13, 14, 15, 16, and 17) have an extremely high variance. The boxes for 12, 16, and 17 range from around 1.25 minutes to 5 minutes. 13 has whiskers from 1 to 5, and the box is between 2 and 4. 14 has whiskers from 0 to 5 (the entire Y axis) and a box between 1.25 and 4.5. 15 is lower, the box ranging between 0.5 and 3 minutes. Tasks 19, and 21 have noticeably short durations, between nearly zero and 0.25 minutes, with little variance. 18, 20, 22, and 23 have boxes which span 1.5 minutes; 18 ranges from almost 0 up to 1.25, 22 ranges from 1.5 to 3 with a whisker extending below 0.5. 22 and 23 are nearly identical, ranging from about 0.75 to 2.5 minutes."
images/88b5f0341afb94f658ade33d8cef8a30bde358b4_Image_011.jpg,"Box chart of durations for tasks 1-11. Time in minutes on the Y-axis, and task numbers on the X-axis. There is a higher variance in duration for task 4 than for the rest of the tasks, and it ranges from 0.25 to just over 4 minutes, with the majority between 1 and 2.5 minutes. Tasks 8 and 10 have noticeably short durations, close to zero, with little variance. 1, 2, and 11 range between 0 and 0.5 minutes. 3, 5, and 7 range between 0.25 and 1.25 minutes, and 6 and 9 reach nearly 1.5 minutes.    Box chart of durations for tasks 2-23. Half of the tasks (12, 13, 14, 15, 16, and 17) have an extremely high variance. The boxes for 12, 16, and 17 range from around 1.25 minutes to 5 minutes. 13 has whiskers from 1 to 5, and the box is between 2 and 4. 14 has whiskers from 0 to 5 (the entire Y axis) and a box between 1.25 and 4.5. 15 is lower, the box ranging between 0.5 and 3 minutes. Tasks 19, and 21 have noticeably short durations, between nearly zero and 0.25 minutes, with little variance. 18, 20, 22, and 23 have boxes which span 1.5 minutes; 18 ranges from almost 0 up to 1.25, 22 ranges from 1.5 to 3 with a whisker extending below 0.5. 22 and 23 are nearly identical, ranging from about 0.75 to 2.5 minutes."
images/cff33e0d43ebb391db3d08a0b4cf6c7e9c04dec0_Image_003.jpg,Transitions times seperated based on position of the object and on transition type. The graphs shows that transitions times are higher for the 2D to 3D transition regardless of object position.
images/1d4484c14344e5bf197b49e1f17fe696d2d4a79d_Image_007.jpg,Figure shows the progression of reward of our method and the SVM-baseline over percentage of training samples for the four conditions of the data collection study.
images/1d4484c14344e5bf197b49e1f17fe696d2d4a79d_Image_009.jpg,"Shows mean and 95%-confidence interval of the metrics tested in the user study. The results of task execution time are as follows: SA, MV: 38.2 sec, lower CI: 33.5 sec, upper CI: 42.9 sec; CO, MV: 39.6 sec, lower CI: 34.9 sec, upper CI: 44.3 sec; SL, MV: 38.6 sec, lower CI: 33.8 sec, upper CI: 43.3 sec; RL, MV: 34.9 sec, lower CI: 30.2 sec, upper CI: 39.6 sec. The results of perceived support are SA, MV: 4.3, lower CI: 3.7, upper CI: 4.9; CO, MV: 3.7, lower CI: 3.1, upper CI: 4.3; SL, MV: 3.8, lower CI: 3.2, upper CI: 4.4; RL, MV: 4.7, lower CI: 4.1, upper CI: 5.3. The results of perceived disruption are SA, MV: 2.9, lower CI: 2.3, upper CI: 3.4; CO, MV: 3.8, lower CI: 3.2, upper CI: 4.3; SL, MV: 4.0, lower CI: 3.4, upper CI: 4.5; RL, MV: 3.8, lower CI: 3.2, upper CI: 4.3. The fraction of labels shown in each condition are SA 100%, CO 4%, SL 9%, and RL 13%. Results for precision are SA, MV: 0.04, lower CI: 0.01, upper CI: 0.06; CO, MV: 0.4, lower CI: 0.38, upper CI: 0.43; SL, MV: 0.27, lower CI: 0.24, upper CI: 0.29; RL, MV: 0.2, lower CI: 0.18, upper CI: 0.23. Results for recall are SA, MV: 0.93, lower CI: 0.90, upper CI: 0.97; CO, MV: 0.04, lower CI: 0.01, upper CI: 0.08; SL, MV: 0.05, lower CI: 0.01, upper CI: 0.08; RL, MV: 0.27, lower CI: 0.23, upper CI: 0.30. Results for F1-score are SA, MV: 0.071, lower CI: 0.063, upper CI: 0.078; CO, MV: 0.075, lower CI: 0.068, upper CI: 0.083; SL, MV: 0.079, lower CI: 0.072, upper CI: 0.087; RL, MV: 0.085, lower CI: 0.078, upper CI: 0.093."
images/cbd7e92b327dc9e54024aaf0a1ff39a45dc20623_Image_003.png,Figure 2: Average worker ratings of all 10 trial sentences as dif- ferent canonical rules are applied. Different rules have differ- ent effects although generally the trend is to increase simplicity as expected.
images/cbd7e92b327dc9e54024aaf0a1ff39a45dc20623_Image_005.png,"Figure 3: Average worker ratings (with standard deviation shown) of our 10 trial sentences, divided into two groups: high- change sentences (6) and low-change sentences (4) as different canonical rules are applied. A clear effect is observed when applying each rule in settings where there is a larger difference in the resulting sentence, suggesting workers are able to accurately pick up on successful rule-base simplicity changes."
images/373b3ed1b4ea52cc733b8296301221e3fb00ef42_Image_013.jpg,Figure 5c. DreamCatcher view of a single person with sleep and mood data for a week.
images/373b3ed1b4ea52cc733b8296301221e3fb00ef42_Image_016.jpg,"Figure 7. Heatmap of interactions for each family. Rows represent the type of interaction (from top to bottom): audio reflection, mood reporting, and views. Each column represents a family, from right to left, Fam 1 represents Family F1 to Fam 10 representing Family10. The x-axis in each family column represents family members and the y-axis represents the day of the study. Dark green bars represent the days on which children interacted, light green represents days children did not interact, dark red represents days parents interacted, and light red represents days parents did not interact."
images/373b3ed1b4ea52cc733b8296301221e3fb00ef42_Image_017.jpg,"Figure 8. Heatmap of sleep data captured. Dark green represents days children interacted, light green represents days children did not interact, dark red represents days parents interacted, light orange represents days parents did not interact."
images/80183519a1e9c67b6996bea274cd5e6c251e6683_Image_009.jpg,"Prior and posterior distributions for the likelihood ratio of H0 and H+, and corresponding Bayes Factors, based on performance improvement on the transfer test and learnt vocabulary after one week compared to performance before the study. Relative likelihoods are illustrated by the pie-chart. Created with JASP"
images/80183519a1e9c67b6996bea274cd5e6c251e6683_Image_010.jpg,"Prior and posterior distributions for the likelihood ratio of H0 and H+, and corresponding Bayes Factors, based on performance improvement on the transfer test and learnt vocabulary after one week compared to performance before the study. Relative likelihoods are illustrated by the pie-chart. Created with JASP"
images/80183519a1e9c67b6996bea274cd5e6c251e6683_Image_011.jpg,"Box plots of SUS Scores, indicating the median, upper and lower quartiles, minimum and maximum values, and outliers. The median of Snapshot is higher than for AR and the interquartile range is larger, but AR has two low outliers and Snapshot only 1."
images/e2dfca4f3f079b1ed31d59a68ecce08cbe52c05a_Image_011.jpg,The radar chart from T1 shows plots from 6 previous sessions as well as the yet unmodified plot for the 7th session. It shows how the teachers' focus may change from session to session.
images/9708dc7e9242fc8d235a0bf4712479c2a5dc8f59_Image_013.jpg,"Three charts, one for each of the three days of the conference. Each chart shows time (x-axis) and part number (y-axis), and indicates the start through end time for each part with a line. Labels on the charts indicate when individual rings were completed, and show two periods on Day 2 where no building occurred, labeled ""Replacing modules"" and ""Repairing structure""."
images/9708dc7e9242fc8d235a0bf4712479c2a5dc8f59_Image_015.gif,"Charts showing results for the question ""Please rate how challenging or straightforward you found each of the following steps in the build process"", for each of Registration, Collecting sticks, Loading sticks into the robot, String winding, Unloading the completed part, Locating the correct position and orientation for the part on the pavilion, and Attaching the part to the pavilion."
images/a15cd58325eb7334786ba0de65f961f66965fd44_Image_031.jpg,"Figure 6: A bar graph comparing Presentation A11y and the Default Interface. The y axis is out of 7 points. The comparisons are on the subjects of self-perceived accessibility, helpfulness as reminding for mentioning visuals, and causing distraction. Self-perceived accessibility: Presentation A11y scored 5.06, while Default Interface scored 4.00. Helpfulness as reminding for mentioning visuals: Presentation A11y scored 5.56, while Default Interface scored 2.94. Causing distraction: Presentation A11y scored 2.56, while Default Interface scored 2.06."
images/1b2d659346931daf853e0640d874557a86b4eb2a_Image_016.png,"Bar charts of word per minute, character error rate, word error rate, in-word IKI and between-word IKI of Gboard and Phraseflow. The statistics are reported in section 6.4"
images/1b2d659346931daf853e0640d874557a86b4eb2a_Image_017.png,Boxplot of SUS and TLX score on Gboard and PhraseFlow. Scores are reported in section 6.4
images/1b2d659346931daf853e0640d874557a86b4eb2a_Image_019.png,"Perceived speed bar chart of phraseflow in day 2,4,and 6 of the deployment study. Results are reported in section 7.4"
images/1b2d659346931daf853e0640d874557a86b4eb2a_Image_020.png,"Perceived accuracy bar chart of phraseflow in day 2,4,and 6 of the deployment study. Results are reported in section 7.4"
images/de99d2e06c5b8761ecc3fbccb094ec234c4144c4_Image_004.jpg,"This image shows the distribution of our participants on our dominance and prosocial scales. Few people score low in both domains and we see that most participants are relatively high in dominance motivation, most participants score high on both scales."
images/7abb628d0f9c326e2a4939c70eec4544ea9b4960_Image_010.jpg,Figure 9: Average measurements per strategy and layout: (a) Time completion task and (b) RULA scores during the task. Significant difference between retargeting strategies for each layout are represented by ‘*’.
images/7abb628d0f9c326e2a4939c70eec4544ea9b4960_Image_011.jpg,"Figure 8: Box plots for the results of our questionnaires. Horizontal red bars represent medians, and boxes represent the interquartile ranges (IQRs). Whiskers stretch to the data points that are within the median ± 1.5 IQR."
images/fb69af5da46713641b0bf69ba57ff1c3c9e124b2_Image_012.jpg,Bar plot of Accuracy and F1 for detecting post-semester depression. Baseline accuracy was 59.4%. Bluetooth accuracy was 69.3% and F1 was 0.64. Calls accuracy was 68.5% and F1 was 0.59. Campus Map accuracy was 68.2% and F1 was 0.66. Location accuracy was 69.5% and F1 was 0.62. Phone Usage accuracy was 70.3% and F1 was 0.75. Sleep accuracy was 69.2% and F1 was 0.66. Steps accuracy was 63.6% and F1 was 0.53. All-7 accuracy was 82.3% and F1 was 0.78. Best set accuracy was 85.7% and F1 was 0.82.
images/fb69af5da46713641b0bf69ba57ff1c3c9e124b2_Image_013.jpg,Bar plot of Accuracy and F1 for detecting change in depression. Baseline accuracy was 65.9%. Bluetooth accuracy was 65.8% and F1 was 0.55. Calls accuracy was 64.8% and F1 was 0.50. Campus Map accuracy was 79.1% and F1 was 0.80. Location accuracy was 74.3% and F1 was 0.73. Phone Usage accuracy was 73.9% and F1 was 0.68. Sleep accuracy was 73.8% and F1 was 0.66. Steps accuracy was 68.2% and F1 was 0.56. All-7 accuracy was 75.9% and F1 was 0.67. Best set accuracy was 85.4% and F1 was 0.80.
images/fbd915aa1143821e150396f6e9ac20f2134c400d_Image_022.gif,"Fig.3.b  Two heatmaps of the top weekend rules selected by metrics. The color is mapped to the percentage of the students who have this behavior rule in that day. The left is for non-depression group and the right is for depression group. For each heatmap, the x-axis is the time of the study, and every rule is lined up on the y-axis. The color pattern in the middle term (in the middle of the x-axis) is different from other time."
images/fbd915aa1143821e150396f6e9ac20f2134c400d_Image_023.gif,"Fig.4.ab  Two heatmaps of two rules, respectively. For each heatmaps, the x-asix is the time of the study, and the y-axis only have two points: depression group and non-depression group. The color is mapped to the percentage of the students who have this behavior rule in that day.  The left figure is for weekday night rule No.5, which is common in both groups but more in non-depression group. Non-depression group have an average of 11.35 percentage of students having this rules during the study. And depression group only have 8.50 percentages.   The right figure is for weekday night rule No.9, which is unique in non-depression group. Non-depression group have an average of 10.14 percentage. And depression group only have 7.93 percentages.     Fig.4.cd  The left figure is for weekend morning rule No.3, which is common in both groups but more in depression group. Depression group have an average of 12.25 percentage. And non-depression group only have 9.22 percentages.   The right figure is for weekend night rule No.19, which is unique in depression group. Depression group have an average of 10.27 percentage. And non-depression group only have 7.84 percentages."
images/fbd915aa1143821e150396f6e9ac20f2134c400d_Image_024.gif,"Fig.4.ab  Two heatmaps of two rules, respectively. For each heatmaps, the x-asix is the time of the study, and the y-axis only have two points: depression group and non-depression group. The color is mapped to the percentage of the students who have this behavior rule in that day.  The left figure is for weekday night rule No.5, which is common in both groups but more in non-depression group. Non-depression group have an average of 11.35 percentage of students having this rules during the study. And depression group only have 8.50 percentages.   The right figure is for weekday night rule No.9, which is unique in non-depression group. Non-depression group have an average of 10.14 percentage. And depression group only have 7.93 percentages.     Fig.4.cd  The left figure is for weekend morning rule No.3, which is common in both groups but more in depression group. Depression group have an average of 12.25 percentage. And non-depression group only have 9.22 percentages.   The right figure is for weekend night rule No.19, which is unique in depression group. Depression group have an average of 10.27 percentage. And non-depression group only have 7.84 percentages."
images/fbd915aa1143821e150396f6e9ac20f2134c400d_Image_025.gif,"Fig.4.ab  Two heatmaps of two rules, respectively. For each heatmaps, the x-asix is the time of the study, and the y-axis only have two points: depression group and non-depression group. The color is mapped to the percentage of the students who have this behavior rule in that day.  The left figure is for weekday night rule No.5, which is common in both groups but more in non-depression group. Non-depression group have an average of 11.35 percentage of students having this rules during the study. And depression group only have 8.50 percentages.   The right figure is for weekday night rule No.9, which is unique in non-depression group. Non-depression group have an average of 10.14 percentage. And depression group only have 7.93 percentages.     Fig.4.cd  The left figure is for weekend morning rule No.3, which is common in both groups but more in depression group. Depression group have an average of 12.25 percentage. And non-depression group only have 9.22 percentages.   The right figure is for weekend night rule No.19, which is unique in depression group. Depression group have an average of 10.27 percentage. And non-depression group only have 7.84 percentages."
images/fbd915aa1143821e150396f6e9ac20f2134c400d_Image_026.gif,"Fig.4.ab  Two heatmaps of two rules, respectively. For each heatmaps, the x-asix is the time of the study, and the y-axis only have two points: depression group and non-depression group. The color is mapped to the percentage of the students who have this behavior rule in that day.  The left figure is for weekday night rule No.5, which is common in both groups but more in non-depression group. Non-depression group have an average of 11.35 percentage of students having this rules during the study. And depression group only have 8.50 percentages.   The right figure is for weekday night rule No.9, which is unique in non-depression group. Non-depression group have an average of 10.14 percentage. And depression group only have 7.93 percentages.     Fig.4.cd  The left figure is for weekend morning rule No.3, which is common in both groups but more in depression group. Depression group have an average of 12.25 percentage. And non-depression group only have 9.22 percentages.   The right figure is for weekend night rule No.19, which is unique in depression group. Depression group have an average of 10.27 percentage. And non-depression group only have 7.84 percentages."
images/fbd915aa1143821e150396f6e9ac20f2134c400d_Image_027.gif,"Fig.4.ef  The left figure is for weekend morning rule No.10,  and the right is for weekend morning rule No.11. They have the same X but different Y.  Weekend morning rule No.10 is unique in non-depression group. Non-depression group have an average of 11.18 percentage. And depression group only have 5.50 percentages.   Weekend morning rule No.11 is unique in depression group. Depression group have an average of 16.58 percentage. And non-depression group only have 9.80 percentages."
images/fbd915aa1143821e150396f6e9ac20f2134c400d_Image_028.gif,"Fig.4.ef  The left figure is for weekend morning rule No.10,  and the right is for weekend morning rule No.11. They have the same X but different Y.  Weekend morning rule No.10 is unique in non-depression group. Non-depression group have an average of 11.18 percentage. And depression group only have 5.50 percentages.   Weekend morning rule No.11 is unique in depression group. Depression group have an average of 16.58 percentage. And non-depression group only have 9.80 percentages."
images/8f18fdea66d3c9439b3ecd0deb656be5f4d2dbcf_Image_001.jpg,"Figure 1 is a chart illustrating participants' ratings of the usefulness of the information they verbally shared while working. The chart has 6 mini bar charts. On the left are 3 mini bar charts for the concurrent think-aloud condition, and on the right are 3 mini bar charts for the retrospective think-aloud condition. For each condition, there is a mini bar chart per domain (i.e., coding, models, and slides). First we describe the concurrent think-aloud ratings: For concurrent think-aloud for the coding domain, there are 3 bars, from left: a bar of height 0 for ""not useful"", a pink bar of height 3 (i.e., 3 participants out of 4) for ""moderately useful"", and a blue bar of height 1 for ""very useful"". For concurrent think-aloud for the models domain, there are 3 bars, from left: a bar of height 0 for ""not useful"", a pink bar of height 4 for ""moderately useful"", and a bar of height 0 for ""very useful"". For concurrent think-aloud for the slides domain, there are 3 bars, from left: a bar of height 0 for ""not useful"", a pink bar of height 2 for ""moderately useful"", and a blue bar of height 2 for ""very useful"". Next we describe the retrospective think-aloud ratings: For retrospective think-aloud for the coding domain, there are 3 bars, from left: a bar of height 0 for ""not useful"", a pink bar of height 3 for ""moderately useful"", and a blue bar of height 1 for ""very useful"". For retrospective think-aloud for the models domain, there are 3 bars, from left: a bar of height 0 for ""not useful"", a pink bar of height 4 for ""moderately useful"", and a bar of height 0 for ""very useful"". For retrospective think-aloud for the slides domain, there are 3 bars, from left: a bar of height 0 for ""not useful"", a pink bar of height 1 for ""moderately useful"", and a blue bar of height 3 for ""very useful"". Note that these categories are aggregations of the participant ratings from the 7-point Likert scale results (between 1-Not Useful, and 7-Extremely Useful). Ratings (1, 2) have been aggregated into ""not useful"", ratings (3, 4, 5) have been aggregated into ""moderately useful"", and ratings (6, 7) have been aggregated into ""very useful""."
images/8f18fdea66d3c9439b3ecd0deb656be5f4d2dbcf_Image_002.jpg,"Figure 2 is a chart illustrating participants' ratings of their confidence in capturing all the important information while speaking while working. The chart has 6 mini bar charts. On the left are 3 mini bar charts for the concurrent think-aloud condition, and on the right are 3 mini bar charts for the retrospective think-aloud condition. For each condition, there is a mini bar chart per domain (i.e., coding, models, and slides). First we describe the concurrent think-aloud ratings: For concurrent think-aloud for the coding domain, there are 3 bars, from left: an orange bar of height 1 (i.e., 1 participant out of 4) for ""not confident"", a bar of height 0 for ""neutral"", and a green bar of height 3 for ""confident"". For concurrent think-aloud for the models domain, there are 3 bars, from left: an orange bar of height 2 for ""not confident"", a yellow bar of height 2 for ""neutral"", and a bar of height 0 for ""confident"". For concurrent think-aloud for the slides domain, there are 3 bars, from left: an orange bar of height 1 for ""not confident"", a bar of height 0 for ""neutral"", and a green bar of height 3 for ""confident"". For retrospective think-aloud for the coding domain, there are 3 bars, from left: an orange bar of height 2 for ""not confident"", a bar of height 0 for ""neutral"", and a green bar of height 2 for ""confident"". For retrospective think-aloud for the models domain, there are 3 bars, from left: a bar of height 0 for ""not confident"", a yellow bar of height 1 for ""neutral"", and a green bar of height 3 for ""confident"". For retrospective think-aloud for the slides domain, there are 3 bars, from left: a bar of height 0 for ""not confident"", a yellow bar of height 1 for ""neutral"", and a green bar of height 3 for ""confident"". Note that these categories are aggregations of the participant ratings from the 7-point Likert scale results (between 1-Very Not Confident, and 7-Very Confident). Ratings (1, 2, 3) have been aggregated into ""Not Confident"", rating (4) is ""Neutral"", and ratings (5, 6, 7) have been aggregated into ""Confident""."
images/8f18fdea66d3c9439b3ecd0deb656be5f4d2dbcf_Image_018.jpg,"Figure 8 is a chart illustrating participants' ratings of how much effort it took to document knowledge for think-aloud and traditional documentation techniques. The chart has 2 mini bar charts. On the left is the bar chart for the think-aloud condition. It has 3 bars, from left: a red bar of height 3 (i.e., 3 participants out of 12) for the category of ""high effort"", a yellow bar of height 3 for ""medium effort"", and a green bar of height 6 for ""low effort"". On the right is the bar chart for the traditional documentation condition. It has 3 bars, from left: a red bar of height 4 for the ""high effort"", a yellow bar of height 2 for ""medium effort"", and a green bar of height 6 for ""low effort"". Note that these categories are aggregations of the participant ratings from the 7-point Likert scale results (between 1-Very Low Effort, and 7-Very High Effort). Ratings (1, 2, 3) have been aggregated into ""low effort"", rating (4) is ""medium effort"", and ratings (5, 6, 7) have been aggregated into ""high effort""."
images/21e4fe87b1a374e69791fac357242a0ff64e93f3_Image_014.jpg,"Figure 5 presents four line charts of the results of Experiment 1. Blue hollow circles represent Young’s modulus E, orange hollow rectangles mean shear modulus G, and green hollow triangle indicate tensile strength. From left to right, it shows the distribution of E and G with different infill densities, the distribution of E and G with infill patterns, the distribution of tensile strength with different printing orientations, and the distribution of E and G with different printing orientations."
images/21e4fe87b1a374e69791fac357242a0ff64e93f3_Image_016.jpg,"Figure 6 presents four line charts of the results of Experiment 2 (tensile tests). Blue hollow circles represent the experimental results and orange hollow rectangles indicate theoretical predictions. From left to right, it shows the difference between experimental results and theoretical predictions in terms of varied spring wire thickness, spring diameter, number of coil turn, and spring length."
images/21e4fe87b1a374e69791fac357242a0ff64e93f3_Image_018.jpg,"Figure 7 presents four line charts of the results of Experiment 3 (torsion tests). Blue hollow circles represent the experimental results and orange hollow rectangles indicate theoretical predictions. From left to right, it shows the difference between experimental results and theoretical predictions in terms of varied spring wire thickness, spring diameter, number of coil turn, and spring length."
images/1c039ecfbef9bc19146b87920a0561570ff72732_Image_009.jpg,"A bar graph of the comprehension scores is shown. It shows a plot of the baseline and tool scores. The tools improve the performance in both cases, but the difference between the highlighting tool and the baseline is larger than the different between the pausing tool and the baseline."
images/992b6d5ea3b2da2d7b98a48b86e011b067a7c679_Image_003.jpg,Graph detailing the action spectrum for the light wavelength determined to be most effective for treating Seasonal Affective Disorder-related symptoms.
images/fa83fb659bbf9efb4b4a56e6a933c155c87c201e_Image_013.png,scatter plot and correlation line between social support and depression for people who have reported discrimination and those who have not
images/fa83fb659bbf9efb4b4a56e6a933c155c87c201e_Image_015.png,bar chart for level of significance from the day before to two days after the discrimination events
images/6ec41b668075f3053375de627be63b5661867880_Image_003.jpg,"Figure 2 illustrates the four representative types of selection errors of hierarchical pie menu interface using eye gaze input.     Figure 2 b, c, and ,d illustrates each of three types of errors which affected by size of pie menu. Those figures show how the size affect each errors.     Figure 2 f illustrates the content bound rule which consider balancing the overshoot errors and the incorrect selection errors."
images/6ec41b668075f3053375de627be63b5661867880_Image_005.jpg,"Figure 4 illustrates the results of experiment 1. Information Trasfer Rate tend to increase as enlarging the size of pie menu in experienced trials, but, in novice trials, it is tend to decrease as enlarging the size of pie.     Completion time tend to increase as enlarging the size of pie menu in novice trials, but, in experienced trials, the size of pie did not affect the completion time.     Error rate tend to decreas as enlarging the size of pie in both novice and experienced trials. However, in novice tirals of 4x4x4 layout and 8x8 layout, the largest pie generated more errors than the smaller sized pies. It is because of the misread errors caused by poor visual acuity of the peripheral regions of the display."
images/6ec41b668075f3053375de627be63b5661867880_Image_006.jpg,"Figure 5 shows the total number of errors per different size of pies. Major error types are the overshoot errors and the incorrect selection errors.    In novice trials,   76 overshoot errros, 26 incorrect selection errors, 30 False Activation errors, 4 misread errors, and 5 blinking errors occur in small size pie condition.    49 overshoot errros, 17 incorrect selection errors, 16 False Activation errors, 14 misread errors, and 2 blinking errors occur in medium size pie condition.    31 overshoot errros, 37 incorrect selection errors, 11 False Activation errors, 35 misread errors, and 7 blinking errors occur in large size pie condition.    In experienced trials,   62 overshoot errros, 30 incorrect selection errors, 21 False Activation errors, 2 misread errors, and 3 blinking errors occur in small size pie condition.    37 overshoot errros, 19 incorrect selection errors, 7 False Activation errors, 1 misread errors, and 3 blinking errors occur in medium size pie condition.    20 overshoot errros, 18 incorrect selection errors, 5 False Activation errors, 0 misread errors, and 2 blinking errors occur in large size pie condition."
images/6ec41b668075f3053375de627be63b5661867880_Image_010.jpg,"Figure 9 illustrates the results of experiment 2.     Information Trasfer Rates were equivalent across the different depth and the granularity in novice trials. In experienced trials, those are also equivalent across the different granularities with 3 depth hierarchy. however, the information transfer rate tend to increase as increasing the granularity with 2 depth hierachy.     Completion time tend to increase as increasing both the granularity and the depth in both novice and experienced trials.    Error rate tend to increase as increasing both the granularity and the depth in both novice and experienced trials. Figure 9 c show that the overshoot errors not much occur while using StickyPie."
images/a5b078260bddc6569886accc4e1a6e0199f11d2b_Image_003.jpg,"Results for the player experience questionnaire showing above-average experience on all subscales, and showing that the average experience for older adults and caregivers revealed no significant differences."
images/243a694be1b17c4018272ecce46685ad24b079a6_Image_007.jpg,A bar graph comparing the model performance of the four models across the there sound categories. Values given in text.
images/28636cf804c2520de41a7a7ff4392d173ba98a7b_Image_006.png,A bar graph showing the timing results for the NMI group from the categorical input experiment.
images/71219f2574c484c41e730c3ab758af92ac942400_Image_005.jpg,"A histogram of unique popular GIFs we saw in our Twitter sample. The most popular GIF on the left exceeds 1000 uses, and the graph quickly tapers off after around 200 GIFs. After that, most are below 50 uses. The graph is displayed in a logarithmic scale, yet still tapers off quickly."
images/56f28fa646fe7fc259ec368577db46f0acc317a5_Image_008.png,"A stacked bar graph with each participant placed on the x-axis and the number of sound classes on the y-axis. P9 and P4 each recorded between 25-30 sound classes; eight participants each recorded between 15-20; and P10 and P11 recorded between 10-15. 103 classes were indoor mechanical sounds, 59 were presence of people or pets, 30 were non-urgent alerts, 22 were outdoor background, 11 were urgent alerts, and 18 were other sounds."
images/b5cff6a8e605b87e828405a2bb7cbdd0275470d0_Image_004.jpg,"Example plot showcasing the waveforms for facing and not facing, the FFT with HLBR features and the cross correlation between the wave forms."
images/b5cff6a8e605b87e828405a2bb7cbdd0275470d0_Image_033.jpg,Effect of distance is seen here in the LDA plots. As the distance increases the difference between the two components decreases.
images/fdc69738f68745f1b11b269d30f9482fb428480b_Image_008.jpg,"Three column charts are shown horizontally. The first chart is labelled ""Complexity of Haptic w/ Visual"" and has shows decreasing utility moving right from Simple, to Tacton, to none.    The second chart is labelled Sound characteristics and shows decreasing utility moving right, from Identity, to Direction, to Loudness.     The last chart, labelled filtering options, shows decreasing utility moving from Identity to Direction to Loudness."
images/fdc69738f68745f1b11b269d30f9482fb428480b_Image_009.jpg,"Three column charts are shown horizontally. The first chart is labelled ""Complexity of Haptic w/ Visual"" and has shows decreasing utility moving right from Simple, to Tacton, to none.    The second chart is labelled Sound characteristics and shows decreasing utility moving right, from Identity, to Direction, to Loudness.     The last chart, labelled filtering options, shows decreasing utility moving from Identity to Direction to Loudness."
images/2fafd8b528727f4966cff89a1d5aaa0ec37231b7_Image_008.jpg,"""A table showing the average results of our experiment for each of the tested displays. On the MS table the average detection time was 50ms without the light sensor and 190ms with the light sensor. The position error was 1.5mm and the angle error was -0.78 degree. In 2.2% of all trials on the MS table only one marker was detected. On the PPI table, the average detection time was 65ms without the light sensor and 176ms with the light sensor. The position error was 2.1mm and the angle error was -1.84 degree. In 2.5% of all the trials on the PPI table only one marker was detected. On the iPad the average detection time was 55 without the light sensor and 167ms with the light sensor. The position error was 2.5mm and the angle error was -1.94 degree. In 3.5% of all the trials on the iPad only one marker was detected."""
images/148da4b210ceaa6d9699fd242a97d0739e460e12_Image_008.gif,"Timelines for each participant, showing that their use of the TInkercad mode increases over the study session."
images/148da4b210ceaa6d9699fd242a97d0739e460e12_Image_009.gif,"Bar chart showing subjective ratings of the unlockable features on usefulness, fun, and how annoying or disruptive they were perceived to be."
images/148da4b210ceaa6d9699fd242a97d0739e460e12_Image_010.gif,Bar charts showing that the control and experimental conditions were rated about the same in both fun and cognitive load.
images/148da4b210ceaa6d9699fd242a97d0739e460e12_Image_011.gif,Bar charts comparing the time to complete the three transfer tasks in the control and experimental conditions.
images/7824023f283bc0823a431cf16ae25786ae3a598c_Image_007.jpg,"Figure 5: ""Participant responses to the workload of different grip postures.  Graphs are centered around the neutral response, with the proportion  of positive and negative responses on the right and left side, respectively."""
images/f6adebe7eecae77ae926fe3b68c655318c15a8ef_Image_006.png,"Figure 3: Three images with blocks of barplots that show differences between conditions. The first image contrasts the PXI measures showing consistently higher average scores for the NPQ condition. The second image shows scores almost identical bars for Disclosure Failure WC, higher scores for Questionnaire on Disclosure Life WC, and higher scores for NPQ on QuestionsAnswered. The third image shows that Questionnaire had higher scores on objective intimacy while scores on perceived intimacy were substantially higher for NPQ."
images/f6adebe7eecae77ae926fe3b68c655318c15a8ef_Image_007.png,"Figure 3: Three images with blocks of barplots that show differences between conditions. The first image contrasts the PXI measures showing consistently higher average scores for the NPQ condition. The second image shows scores almost identical bars for Disclosure Failure WC, higher scores for Questionnaire on Disclosure Life WC, and higher scores for NPQ on QuestionsAnswered. The third image shows that Questionnaire had higher scores on objective intimacy while scores on perceived intimacy were substantially higher for NPQ."
images/f6adebe7eecae77ae926fe3b68c655318c15a8ef_Image_008.png,"Figure 3: Three images with blocks of barplots that show differences between conditions. The first image contrasts the PXI measures showing consistently higher average scores for the NPQ condition. The second image shows scores almost identical bars for Disclosure Failure WC, higher scores for Questionnaire on Disclosure Life WC, and higher scores for NPQ on QuestionsAnswered. The third image shows that Questionnaire had higher scores on objective intimacy while scores on perceived intimacy were substantially higher for NPQ."
images/a38749fbb390ae3939225efb60a72157cfe7c396_Image_008.jpg,"Scatterplots showing the relationship between age and mean trial time for each of the four tasks.  For pointing, a fit line for participants with motor impairments goes from about 1 second at the younger end to about 1.2 seconds at the older end, and a fit line for participants without motor impairments goes from about 0.7 seconds at the younger end to about 1 second at the older end.  For dragging, a fit line for participants with motor impairments goes from about 1 second at the younger end to almost 2 seconds at the older end, and a fit line for participants without motor impairments goes from under 1 second at the younger end to about 1.5 at the older end.  For crossing, a fit line for participants with motor impairments goes from about 1 second at the younger end to about 1.2 seconds at the older end, and a fit line for participants without motor impairments goes from about 0.7 seconds at the younger end to about 1.2 seconds at the older end.  For steering, a fit line for participants with motor impairments goes from just under 2 seconds at the younger end to just over 2 seconds at the older end, and a fit line for participants without motor impairments goes from under 1.5 seconds at the younger end to about 2 seconds at the older end."
images/a38749fbb390ae3939225efb60a72157cfe7c396_Image_009.jpg,"Scatterplots showing the relationship between age and error rate for each of the four tasks.  For pointing, a fit line for participants with motor impairments goes from about 4% to about 2.5% from the younger to older ends, and a fit line for participants without motor impairments goes from about 2.5% to about 2% from the younger to older ends.  For dragging, a fit line for participants with motor impairments goes from about 2.5% to about 2% from the younger to older ends, and a fit line for participants without motor impairments goes from about 1.5% to about 1% from the younger to older ends.  For crossing, a fit line for participants with motor impairments goes from about 10% to about 6% from the younger to older ends, and a fit line for participants without motor impairments goes from about 8.5% to about 2% from the younger to older ends.  For steering, a fit line for participants with motor impairments goes from about 15% to about 15% from the younger to older ends, and a fit line for participants without motor impairments goes from about 8% to about 10% from the younger to older ends."
images/a38749fbb390ae3939225efb60a72157cfe7c396_Image_010.jpg,"Two scatterplots showing age and mean trial time relationship for the 32 fastest and 32 slowest participants. The fastest participants are mostly in the 18-40 range, with 3 people older than that, and include 7 participants who had reported motor impairments. The slowest participants are more dispersed in age, from just over 25 to almost 70, and include 5 participants without motor impairments."
images/a2c4f7c19d32134841d8fe6f90ee44a8fefe7b09_Image_008.jpg,"The first subfigure shows bar charts of Latitude levels wrist, forearm, and elbow combined with awareness schemes known and unknown.       The height of the bar chart represents the throughput result of each combination:       wrist x known: 3.047, wrist x unknown: 2.697, forearm x known: 3.020, forearm x unknown: 2.584, elbow x known: 2.822, elbow x unknown: 2.265.       Gray lines indicate significant pairs between wrist x known vs. elbow x known, wrist x unknown vs. forearm x unknown, wrist x unknown vs. elbow x unknown, forearm x known vs. elbow x known, and forearm x unknown vs. elbow x unknown.      The second subfigure shows bar charts of Height levels close, medium, and far combined with awareness schemes known and unknown.       The height of the bar chart represents the throughput result of each combination:       close x known: 3.059, close x unknown: 2.660, medium x known: 3.014, medium x unknown: 2.565, far x known: 2.815, far x unknown: 2.321.      Gray lines indicate significant pairs between close x known vs. far x known, close x unknown vs. medium x unknown, close x unknown vs. far x unknown, medium x known vs. far x known, and medium x unknown vs. far x unknown."
images/a2c4f7c19d32134841d8fe6f90ee44a8fefe7b09_Image_016.jpg,"The bar chart shows the throughput result of each combination of longitude levels (0-7) and latitude levels (0-2).       The values are (ordered in wrist, forearm, and elbow):       (N) 2.873, 2.827, 2.644;       (NW) 2.677, 2.673, 2.503;       (W) 2.765, 2.649, 2.386;       (SW) 2.880, 2.766, 2.373;      (S) 2.921, 2.790, 2.422;      (SE) 2.965, 2.809, 2.561;      (E) 2.951, 2.936, 2.704;      (NE) 2.943, 2.964, 2.752.      Gray lines indicate significant pairs between W x Wrist vs. W x Elbow, W x Forearm vs. W x Elbow, SW x Wrist vs. SW x Elbow, SW x Forearm vs. SW x Elbow, S x Wrist vs. S x Elbow, S x Forearm vs. S x Elbow, and SE x Wrist vs. SE x Elbow."
images/a2c4f7c19d32134841d8fe6f90ee44a8fefe7b09_Image_017.jpg,"The four subfigures present the main effects of the four independent variables.      The TP results are:      Subfigure a (Awareness Scheme): Known (2.963), Unknown (2.515), with significant difference;      Subfigure b (Longitude): N (2.782), NW (2.618), W (2.600), SW (2.673), S (2.711), SE (2.778), E (2.864), and NE (2.886), with significant differences between: N vs. NW, NW vs. E, NW vs. NE, W vs. E, W vs. NE, SW vs. E, SW vs. NE, and S vs. E;      Subfigure c (Latitude): Wrist (2.872), Forearm (2.802), and Elbow (2.543), with significant differences between all pairwise comparisons;      Subfigure d (Height): Close (2.859), Medium (2.790), and Far (2.568), with significant differences between all pairwise comparisons."
images/538460460d734a137cf6f6a87d57cf86c1a69a52_Image_003.jpg,"24 Likert-scale prompts and the distribution of students' responses from 'Strongly Disagree' to 'Strongly Agree'. 80 percent of students identified that they do not share videos during lecture, despite almost 70 percent who have access to webcams. 78 percent of students strongly favored the chat feature."
images/fc1256c7375baa5b98f5b69ae584f2e4f0fbffe7_Image_008.jpg,3D distribution of endpoints for each character. The top view and the left view show that the endpoints roughly follow a QWERTY layout.
images/fc1256c7375baa5b98f5b69ae584f2e4f0fbffe7_Image_009.jpg,3D distribution of endpoints for each character. The top view and the left view show that the endpoints roughly follow a QWERTY layout.
images/fc1256c7375baa5b98f5b69ae584f2e4f0fbffe7_Image_010.jpg,3D distribution of endpoints for each character. The top view and the left view show that the endpoints roughly follow a QWERTY layout.
images/fc1256c7375baa5b98f5b69ae584f2e4f0fbffe7_Image_011.jpg,3D distribution of endpoints for each character. The top view and the left view show that the endpoints roughly follow a QWERTY layout.
images/3f0f4f61812103e1ecdbd1a2ec01b4d923c147c9_Image_008.png,Description: image of a chart that has automatic adapation and no notification selected
images/574211ab6e038ddee2e964502fb0b8a07930805a_Image_008.jpg,"Figure 5:  A scatterplot of points overlaid over a color space.  Clockwise from the top left, the colors are blue, purple, red, yellow, green.  In this plot, most of the points are scattered relatively evenly over the top two-thirds of the space, though the bottom third is sparse.  A denser than average line of points shows up along the top border of the image."
images/3243dde72340fe11b84bf83a9cc4e54a8eb6402d_Image_003.png,"Figure 1 describes our data collection intervals among the computing students whose degree required to take the HCI intervention course. An identical survey was administered three times: at beginning of the HCI course (Pre-survey), at the end of the HCI course (Post-survey), and 18-24 months after the HCI course (Senior-survey)."
images/ce4b730f4eaddd98be36ce4ba95548a95a6d69fb_Image_006.jpg,Figure 4: Error bar of user ratings on how samples in different datasets state ideological stereotypes.
images/ce4b730f4eaddd98be36ce4ba95548a95a6d69fb_Image_011.jpg,Figure 6: Error bar of user ratings on how samples state ideological stereotypes.
images/428c50a13844b247cc6bff879d3bd34128ea3273_Image_003.jpg,"The figure shows the time it took to complete each trial, in route A and route B. Overall, route completion time are significantly reduced throughout the trials across all participants.  The figure also shows the error and recall rates of describing POIs and navigation instructions after performing each trial."
images/15e11b0e326f7122d819cb95c0ad84d2a8d581c8_Image_002.jpg,"This figure is divided into two parts: (a) and (b). 

Part (a) of the figure shows a stacked bar plot showing percentages of 6-point scale responses for different categories of User Initiative. The title is ""User Initiative"", the y-axis has 5 categories; ""Toggle Suggestions"", ""No Suggestions"", ""Suggestions"", ""Replace All"", and ""Automatic"". The x-axis shows percentage, centered at 0, and going up to 100 percent left and right. The scale responses for 1-3 are on the left side, and 4-6 are on the right side. It can be seen that for “Toggle Suggestions”, “No Suggestions”, and “Suggestions”, the majority of responses are on the right side, while for the “Replace All” and “Automatic” conditions, the majority of responses are on the left side.

For ""Toggle Suggestions"" 8.33% responded 1, 0% for 2, 0% for 3, 33.33% for 4, 33.33% for 5, and 25% for 6.
For ""No Suggestions"" 0% responded 1, 8.33% for 2, 8.33% for 3, 33.33% for 4, 16.67% for 5, and 33.33% for 6.
For ""Suggestions"" 0% responded 1, 8.33% for 2, 16.67% for 3, 16.67% for 4, 41.67% for 5, and 16.67% for 6.
For ""Replace All"" 8.33% responded 1, 33.33% for 2, 16.67% for 3, 16.67% for 4, 25% for 5, and 0% for 6.
For ""Automatic"" 16.67% responded 1, 33.33% for 2, 33.33% for 3, 8.33% for 4, 8.33% for 5, and 0% for 6.

Part (b) of the figure shows a stacked bar plot showing percentages of 6-point scale responses for different categories of Change Visibility. The title is ""Change Visibility"", the y-axis has 4 categories; ""Trace"", ""Pop-up"", ""No Trace"", and ""Sidebar"". The x-axis shows percentage, centered at 0, and going up to 100 percent left and right. The scale responses for 1-3 are on the left side, and 4-6 are on the right side. For “Trace” and “Pop-up”, the majority of responses are on the right side. For “No Trace” and “Sidebar” the majority of responses are on the left side.

For ""Trace"" 0% responded 1, 0% for 2, 16.67% for 3, 16.67% for 4, 25% for 5, and 41.67% for 6. 
For ""Pop-up"" 8.33% responded 1, 25% for 2, 8.33% for 3, 8.33% for 4, 16.67% for 5, and 33.33% for 6. 
For ""No Trace"" 8.33% responded 1, 33.33% for 2, 16.67% for 3, 16.67% for 4, 25% for 5, and 41.67% for 6. 
For ""Sidebar"" 50% responded 1, 10% for 2, 10% for 3, 20% for 4, 10% for 5, and 0% for 6."
images/15e11b0e326f7122d819cb95c0ad84d2a8d581c8_Image_003.jpg,"This figure is divided into two parts: (a) and (b). 

Part (a) of the figure shows a stacked bar plot showing percentages of 6-point scale responses for different categories of User Initiative. The title is ""User Initiative"", the y-axis has 5 categories; ""Toggle Suggestions"", ""No Suggestions"", ""Suggestions"", ""Replace All"", and ""Automatic"". The x-axis shows percentage, centered at 0, and going up to 100 percent left and right. The scale responses for 1-3 are on the left side, and 4-6 are on the right side. It can be seen that for “Toggle Suggestions”, “No Suggestions”, and “Suggestions”, the majority of responses are on the right side, while for the “Replace All” and “Automatic” conditions, the majority of responses are on the left side.

For ""Toggle Suggestions"" 8.33% responded 1, 0% for 2, 0% for 3, 33.33% for 4, 33.33% for 5, and 25% for 6.
For ""No Suggestions"" 0% responded 1, 8.33% for 2, 8.33% for 3, 33.33% for 4, 16.67% for 5, and 33.33% for 6.
For ""Suggestions"" 0% responded 1, 8.33% for 2, 16.67% for 3, 16.67% for 4, 41.67% for 5, and 16.67% for 6.
For ""Replace All"" 8.33% responded 1, 33.33% for 2, 16.67% for 3, 16.67% for 4, 25% for 5, and 0% for 6.
For ""Automatic"" 16.67% responded 1, 33.33% for 2, 33.33% for 3, 8.33% for 4, 8.33% for 5, and 0% for 6.

Part (b) of the figure shows a stacked bar plot showing percentages of 6-point scale responses for different categories of Change Visibility. The title is ""Change Visibility"", the y-axis has 4 categories; ""Trace"", ""Pop-up"", ""No Trace"", and ""Sidebar"". The x-axis shows percentage, centered at 0, and going up to 100 percent left and right. The scale responses for 1-3 are on the left side, and 4-6 are on the right side. For “Trace” and “Pop-up”, the majority of responses are on the right side. For “No Trace” and “Sidebar” the majority of responses are on the left side.

For ""Trace"" 0% responded 1, 0% for 2, 16.67% for 3, 16.67% for 4, 25% for 5, and 41.67% for 6. 
For ""Pop-up"" 8.33% responded 1, 25% for 2, 8.33% for 3, 8.33% for 4, 16.67% for 5, and 33.33% for 6. 
For ""No Trace"" 8.33% responded 1, 33.33% for 2, 16.67% for 3, 16.67% for 4, 25% for 5, and 41.67% for 6. 
For ""Sidebar"" 50% responded 1, 10% for 2, 10% for 3, 20% for 4, 10% for 5, and 0% for 6."
images/15e11b0e326f7122d819cb95c0ad84d2a8d581c8_Image_005.jpg,"This Figure is divided into three parts: a, b, and c.

Part (a) of this figure shows a stacked bar plot showing percentages of 5-point likert-scale responses. The title is “This text was easy to read”, the y-axis has 4 categories; ""Original"", ""Automatic"", ""Pop-up"", and ""Decoration"". The x-axis shows percentage, centered at 0, and going up to 100 percent left and right. The likert-scale responses for “Neutral” is centered, and “Disagree” and “Strongly Disagree” are on the left side, and “Agree” and “Strongly Agree” are on the right side. For all the conditions, the majority of responses are on the right side, and there is very little on the left side.

For ""Original"" 4% responded “Strongly Disagree”, 4% for “Disagree”, 24% for “Neutral”, 56% for “Agree”, and 12% for “Strongly Agree”. 
For ""Automatic"" 0% responded “Strongly Disagree”, 4% for “Disagree”, 8% for “Neutral”, 60% for “Agree”, and 28% for “Strongly Agree”.
For ""Pop-up"" 0% responded “Strongly Disagree”, 8% for “Disagree”, 12% for “Neutral”, 48% for “Agree”, and 32% for “Strongly Agree”. 
For ""Decoration"" 0% responded “Strongly Disagree”, 4% for “Disagree”, 12% for “Neutral”, 52% for “Agree”, and 32% for “Strongly Agree”.


Part (b) of this figure shows a stacked bar plot showing percentages of 5-point Likert-scale responses. The title is “I was able to understand this text well.”, the y-axis has 4 categories; ""Original"", ""Automatic"", ""Pop-up"", and ""Decoration"". The x-axis shows percentage, centered at 0, and going up to 100 percent left and right. There is a bracket indicating p<.05 significance between the “Original” and “Pop-up” plots. There is also a bracket indicating p<.05 significance between the “Original” and “Decoration” plots. The Likert-scale responses for “Neutral” is centered, and “Disagree” and “Strongly Disagree” are on the left side, and “Agree” and “Strongly Agree” are on the right side. For all conditions, the majority of responses are on the right side.

For ""Original"" 0% responded “Strongly Disagree”, 12% for “Disagree”, 20% for “Neutral”, 60% for “Agree”, and 8% for “Strongly Agree”. 
For ""Automatic"" 0% responded “Strongly Disagree”, 4% for “Disagree”, 20% for “Neutral”, 40% for “Agree”, and 36% for “Strongly Agree”.
For ""Pop-up"" 0% responded “Strongly Disagree”, 0% for “Disagree”, 12% for “Neutral”, 48% for “Agree”, and 40% for “Strongly Agree”. 
For ""Decoration"" 0% responded “Strongly Disagree”, 0% for “Disagree”, 12% for “Neutral”, 44% for “Agree”, and 44% for “Strongly Agree”.


Part (c) of this figure shows a boxplot for Comprehension Scores for four different conditions, “Original”, “Automatic”, “Pop-up”, and “Decoration”, which are on the x-axis. The y-axis is the score, and is a percentage from 0 to 100. For “Original” and “Automatic” the boxplots appear to be almost equal and most of the boxplot is between 30% and 70%. For “Pop-up”, it is higher up, with the first quartile starting at around 70%. For “Decoration” there is a wider range, the first quartile is at around 30% and the third quartile is at 100%.

The “Original” boxplot has a minimum of 0%, 1st quartile 33.33%, median 66.67%, mean 62.70%, 3rd quartile 66.67%, and a maximum of 100%.
The “Automatic” boxplot has a minimum of 0%, 1st quartile 33.33%, median 66.7%, mean 58.7%, 3rd quartile 66.67%, and a maximum of 100%.
The “Pop-up” boxplot has a minimum of 33.33%, 1st quartile 66.67%, median 66.7%, mean 76%, 3rd quartile 100%, and a maximum of 100%.
The “Decoration” boxplot has a minimum of 0%, 1st quartile 33.33%, median 66.67%, mean 60%, 3rd quartile 100%, and a maximum of 100%."
images/15e11b0e326f7122d819cb95c0ad84d2a8d581c8_Image_006.jpg,"This Figure is divided into three parts: a, b, and c.

Part (a) of this figure shows a stacked bar plot showing percentages of 5-point likert-scale responses. The title is “This text was easy to read”, the y-axis has 4 categories; ""Original"", ""Automatic"", ""Pop-up"", and ""Decoration"". The x-axis shows percentage, centered at 0, and going up to 100 percent left and right. The likert-scale responses for “Neutral” is centered, and “Disagree” and “Strongly Disagree” are on the left side, and “Agree” and “Strongly Agree” are on the right side. For all the conditions, the majority of responses are on the right side, and there is very little on the left side.

For ""Original"" 4% responded “Strongly Disagree”, 4% for “Disagree”, 24% for “Neutral”, 56% for “Agree”, and 12% for “Strongly Agree”. 
For ""Automatic"" 0% responded “Strongly Disagree”, 4% for “Disagree”, 8% for “Neutral”, 60% for “Agree”, and 28% for “Strongly Agree”.
For ""Pop-up"" 0% responded “Strongly Disagree”, 8% for “Disagree”, 12% for “Neutral”, 48% for “Agree”, and 32% for “Strongly Agree”. 
For ""Decoration"" 0% responded “Strongly Disagree”, 4% for “Disagree”, 12% for “Neutral”, 52% for “Agree”, and 32% for “Strongly Agree”.


Part (b) of this figure shows a stacked bar plot showing percentages of 5-point Likert-scale responses. The title is “I was able to understand this text well.”, the y-axis has 4 categories; ""Original"", ""Automatic"", ""Pop-up"", and ""Decoration"". The x-axis shows percentage, centered at 0, and going up to 100 percent left and right. There is a bracket indicating p<.05 significance between the “Original” and “Pop-up” plots. There is also a bracket indicating p<.05 significance between the “Original” and “Decoration” plots. The Likert-scale responses for “Neutral” is centered, and “Disagree” and “Strongly Disagree” are on the left side, and “Agree” and “Strongly Agree” are on the right side. For all conditions, the majority of responses are on the right side.

For ""Original"" 0% responded “Strongly Disagree”, 12% for “Disagree”, 20% for “Neutral”, 60% for “Agree”, and 8% for “Strongly Agree”. 
For ""Automatic"" 0% responded “Strongly Disagree”, 4% for “Disagree”, 20% for “Neutral”, 40% for “Agree”, and 36% for “Strongly Agree”.
For ""Pop-up"" 0% responded “Strongly Disagree”, 0% for “Disagree”, 12% for “Neutral”, 48% for “Agree”, and 40% for “Strongly Agree”. 
For ""Decoration"" 0% responded “Strongly Disagree”, 0% for “Disagree”, 12% for “Neutral”, 44% for “Agree”, and 44% for “Strongly Agree”.


Part (c) of this figure shows a boxplot for Comprehension Scores for four different conditions, “Original”, “Automatic”, “Pop-up”, and “Decoration”, which are on the x-axis. The y-axis is the score, and is a percentage from 0 to 100. For “Original” and “Automatic” the boxplots appear to be almost equal and most of the boxplot is between 30% and 70%. For “Pop-up”, it is higher up, with the first quartile starting at around 70%. For “Decoration” there is a wider range, the first quartile is at around 30% and the third quartile is at 100%.

The “Original” boxplot has a minimum of 0%, 1st quartile 33.33%, median 66.67%, mean 62.70%, 3rd quartile 66.67%, and a maximum of 100%.
The “Automatic” boxplot has a minimum of 0%, 1st quartile 33.33%, median 66.7%, mean 58.7%, 3rd quartile 66.67%, and a maximum of 100%.
The “Pop-up” boxplot has a minimum of 33.33%, 1st quartile 66.67%, median 66.7%, mean 76%, 3rd quartile 100%, and a maximum of 100%.
The “Decoration” boxplot has a minimum of 0%, 1st quartile 33.33%, median 66.67%, mean 60%, 3rd quartile 100%, and a maximum of 100%."
images/15e11b0e326f7122d819cb95c0ad84d2a8d581c8_Image_007.jpg,"This Figure is divided into three parts: a, b, and c.

Part (a) of this figure shows a stacked bar plot showing percentages of 5-point likert-scale responses. The title is “This text was easy to read”, the y-axis has 4 categories; ""Original"", ""Automatic"", ""Pop-up"", and ""Decoration"". The x-axis shows percentage, centered at 0, and going up to 100 percent left and right. The likert-scale responses for “Neutral” is centered, and “Disagree” and “Strongly Disagree” are on the left side, and “Agree” and “Strongly Agree” are on the right side. For all the conditions, the majority of responses are on the right side, and there is very little on the left side.

For ""Original"" 4% responded “Strongly Disagree”, 4% for “Disagree”, 24% for “Neutral”, 56% for “Agree”, and 12% for “Strongly Agree”. 
For ""Automatic"" 0% responded “Strongly Disagree”, 4% for “Disagree”, 8% for “Neutral”, 60% for “Agree”, and 28% for “Strongly Agree”.
For ""Pop-up"" 0% responded “Strongly Disagree”, 8% for “Disagree”, 12% for “Neutral”, 48% for “Agree”, and 32% for “Strongly Agree”. 
For ""Decoration"" 0% responded “Strongly Disagree”, 4% for “Disagree”, 12% for “Neutral”, 52% for “Agree”, and 32% for “Strongly Agree”.


Part (b) of this figure shows a stacked bar plot showing percentages of 5-point Likert-scale responses. The title is “I was able to understand this text well.”, the y-axis has 4 categories; ""Original"", ""Automatic"", ""Pop-up"", and ""Decoration"". The x-axis shows percentage, centered at 0, and going up to 100 percent left and right. There is a bracket indicating p<.05 significance between the “Original” and “Pop-up” plots. There is also a bracket indicating p<.05 significance between the “Original” and “Decoration” plots. The Likert-scale responses for “Neutral” is centered, and “Disagree” and “Strongly Disagree” are on the left side, and “Agree” and “Strongly Agree” are on the right side. For all conditions, the majority of responses are on the right side.

For ""Original"" 0% responded “Strongly Disagree”, 12% for “Disagree”, 20% for “Neutral”, 60% for “Agree”, and 8% for “Strongly Agree”. 
For ""Automatic"" 0% responded “Strongly Disagree”, 4% for “Disagree”, 20% for “Neutral”, 40% for “Agree”, and 36% for “Strongly Agree”.
For ""Pop-up"" 0% responded “Strongly Disagree”, 0% for “Disagree”, 12% for “Neutral”, 48% for “Agree”, and 40% for “Strongly Agree”. 
For ""Decoration"" 0% responded “Strongly Disagree”, 0% for “Disagree”, 12% for “Neutral”, 44% for “Agree”, and 44% for “Strongly Agree”.


Part (c) of this figure shows a boxplot for Comprehension Scores for four different conditions, “Original”, “Automatic”, “Pop-up”, and “Decoration”, which are on the x-axis. The y-axis is the score, and is a percentage from 0 to 100. For “Original” and “Automatic” the boxplots appear to be almost equal and most of the boxplot is between 30% and 70%. For “Pop-up”, it is higher up, with the first quartile starting at around 70%. For “Decoration” there is a wider range, the first quartile is at around 30% and the third quartile is at 100%.

The “Original” boxplot has a minimum of 0%, 1st quartile 33.33%, median 66.67%, mean 62.70%, 3rd quartile 66.67%, and a maximum of 100%.
The “Automatic” boxplot has a minimum of 0%, 1st quartile 33.33%, median 66.7%, mean 58.7%, 3rd quartile 66.67%, and a maximum of 100%.
The “Pop-up” boxplot has a minimum of 33.33%, 1st quartile 66.67%, median 66.7%, mean 76%, 3rd quartile 100%, and a maximum of 100%.
The “Decoration” boxplot has a minimum of 0%, 1st quartile 33.33%, median 66.67%, mean 60%, 3rd quartile 100%, and a maximum of 100%."
images/15e11b0e326f7122d819cb95c0ad84d2a8d581c8_Image_008.jpg,"This figure shows a stacked bar plot showing percentages of 5-point Likert-scale responses. The title is “I would be likely to use:”, and the y-axis has 3 categories; ""Automatic"", ""Pop-up"", and ""Decoration"". The x-axis shows percentage, centered at 0, and going up to 100 percent left and right. There is a bracket indicating p<.01 significance between the “Automatic” and “Pop-up” plots. There is also a bracket indicating p<.001 significance between the “Automatic” and “Decoration” plots. The Likert-scale responses for “Neutral” is centered, and “Disagree” and “Strongly Disagree” are on the left side, and “Agree” and “Strongly Agree” are on the right side. It can be seen that a majority of the responses for “Pop-up” and “Decoration” are either “Agree” or “Strongly Agree”.

For ""Automatic"" 28% responded “Strongly Disagree”, 28% for “Disagree”, 24% for “Neutral”, 12% for “Agree”, and 8% for “Strongly Agree”.
For ""Pop-up"" 4% responded “Strongly Disagree”, 8% for “Disagree”, 8% for “Neutral”, 28% for “Agree”, and 52% for “Strongly Agree”. 
For ""Decoration"" 4% responded “Strongly Disagree”, 8% for “Disagree”, 8% for “Neutral”, 36% for “Agree”, and 44% for “Strongly Agree”."
images/22e30452d31598d12867d84e4357cabe2a444e3e_Image_001.png,"Figure 1 shows the Target Graph visualization of three different clicks. The image shows that the duration of the first click was too long, the second click was too short, and the third click was ok."
images/22e30452d31598d12867d84e4357cabe2a444e3e_Image_002.png,Figure 3 and Figure 4. Figure 3 shows the Bar Graph visualization. Figure 4 shows the Venn Graph visualization
images/23ed58b594d25a29795c70a43b268dd6558d6f39_Image_007.jpg,"Mean NS Motivation to Slow for NNS on a scale of 1 to 7, by presence or absence of Speech Speedometer for Trial 2 and Trial 3 (error bars represent standard errors of the mean)"
images/23ed58b594d25a29795c70a43b268dd6558d6f39_Image_008.jpg,"Figure 4: Mean NS Speech Rate, by presence or absence of Speech Speedometer for Trial 2 and Trial 3 (error bars represent standard error of the mean)."
images/23ed58b594d25a29795c70a43b268dd6558d6f39_Image_010.jpg,"Figure 7: Mean NNS Perceived NS Speech Clarity on a scale of 1 to 7, by presence or absence of Speech Speedometer for Trial 2 and Trial 3 (error bars represent standard errors of the mean)."
images/23ed58b594d25a29795c70a43b268dd6558d6f39_Image_011.jpg,"Figure 8: Mean NNS perceived NS Accommodation on a scale of 1 to 7, by presence or absence of Speech Speedometer for Trial 2 and Trial 3 (error bars represent standard errors of the mean)."
images/ca084360fd522adf8970c75d12cef70a4865d10f_Image_002.jpg,"Bar chart showing mean ratings about usefulness of vocal messages, grouped by mobility aid used and visual condition of participants. Values are explained along subsection 3.3 entitled subjective ratings."
images/ca084360fd522adf8970c75d12cef70a4865d10f_Image_003.jpg,"Bar chart showing mean ratings about usefulness of vocal messages, grouped by previous experience of participants with smartphones and voice navigation apps. Values are explained along subsection 3.3 entitled subjective ratings."
images/acc12add91acb0f81c5bbc7c0ac9343d2d4a8a2c_Image_004.jpg,"Box plot present percent fixation times of native and nonnative. mean fixation times of ""Nonnative"" is higher than ""Native""."
images/acc12add91acb0f81c5bbc7c0ac9343d2d4a8a2c_Image_007.jpg,"Box plot present percent fixation times for videos with vs. without. mean fixation times of ""Without"" is higher than ""With Video""."
images/acc12add91acb0f81c5bbc7c0ac9343d2d4a8a2c_Image_008.jpg,Box plot results of experiment 2. There are two boxes presents the comprehension scores for videos with guidance versus without guidance. Comprehension scores for videos without guidance is higher than comprehension scores for videos with guidance.
images/c798e119140274c1d642488b9681ceb8dae1906b_Image_002.jpg,"Another avatar performing the sentence: ""Do you like my shirt""
ASL glosses: MY SHIRT YOU LIKE
FAP01, FAP02, ..., FAP67: curves of these features applitude changing in time"
images/c798e119140274c1d642488b9681ceb8dae1906b_Image_003.jpg,"Expr(OLD) Scores boxplot
Min value: 1.0
Max value: 10.0
Median: 2.5
Average: 3.3

Non(OLD) Scores boxplot
Min value: 1.0
Max value: 7.0
Median: 1.0
Average: 2.17

Expr(NEW) Scores boxplot
Min value: 1.0
Max value: 10.0
Median: 2.0
Average: 3.56

Non(NEW) Scores boxplot
Min value: 1.0
Max value: 10.0
Median: 1.0
Average: 2.14"
images/c798e119140274c1d642488b9681ceb8dae1906b_Image_004.jpg,"Expr(OLD) Scores boxplot
Min value: 0.0
Max value: 1.0
Median: 0.5
Average: 0.51

Non(OLD) Scores boxplot
Min value: 0.0
Max value: 1.0
Median: 0.5
Average: 0.46

Expr(NEW) Scores boxplot
Min value: 0.0
Max value: 1.0
Median: 0.83
Average: 0.63

Non(NEW) Scores boxplot
Min value: 0.0
Max value: 1.0
Median: 0.33
Average: 0.4"
images/7940222e83f0bea7bea567509fbf9dd90c735230_Image_003.png,"Graphs of results for each task. Each graph has three lines: A middle line that shows time in milliseconds vs angle, and two lines that show the 95% confidence intervals.There are also dotted horizontal lines for preference and error rate."
images/be00f1bcb7d9f911a3ca855e2e7b1bc926be47e8_Image_002.jpg,"This figure is a scatterplot showing the relationship between HIV Estimated Prevalence Rate Per 100,000 Population (CDC, 2011) on the x-axis and Percentage of Ads Containing Sexual Health-Related Language on the y-axis in 95 locations. The relationship is estimated linearly by the equation SHR language = 46.360 + 0.009 * prevalence rate, p = 0.009. Each location is represented by a circle, with the size of the circle representing its population relative to the other locations. Outliers with a low HIV prevalence rate and a high % of SHR language in ads include SF Bay Area and Boise, ID. Outliers with a high HIV prevalence rate and a low % of SHR language in ads include Wichita, KS and Jackson, MS. New York City is close to the linear trend, with a high HIV prevalence rate and a high % of SHR language in ads. In general, locations with a higher population tend to have a greater percentage of ads containing SHR language."
images/b0e8f277b1b96ad4abe82203b553ad78d1765713_Image_004.gif,"A boxplot with IMI Enjoyment Rating on the y-axis and Intervention on the x-axis. The box for the Python Graphics intervention is centered at 5 on the y-axis, the Spatial Exercises box is centered at about 3.6, and the Homeworld Bound box is centered at about 4."
images/50b2e5adc0af45f9e22711267899383dc781c367_Image_020.jpg,"This is a demonstration of text entry speed, mean UER and TER across 4 blocks in the evaluation."
images/dd99f5cb66b6243c24929ad6a5a6edde5d821b1e_Image_005.jpg,"Figure 4. The average self-disclosure level of different groups over time. They show the average levels of self-disclosure for Thoughts & Feelings across the 20 days. In the first week, the self-disclosure levels were similar among the three groups; the difference increased around day 9, with HD being the highest and ND being the lowest to disclose their thoughts."
images/bc2d3dfd2555c7590021db88d60d729dde30be82_Image_006.jpg,"Column graph shows results of Experiment 1: people's blame judgments for each of the four agents, for both action and inaction."
images/bc2d3dfd2555c7590021db88d60d729dde30be82_Image_007.jpg,"Column graph shows results of Experiment 3: people's blame judgments for each of the four agents, for both action and inaction."
images/d7ea0ebf716af351e8c2b23b1c0086048a811856_Image_005.jpg,"Two graphs: 
Left (Notice Scores for Driven and Neutral) and 
Right (Comprehension Scores for Driven and Neutral).

Notice Scores:
Driven Scores boxplot
Min value: 1.0
Max value: 10.0
Lower and Upper Quartile: (1.0, 6.0)
Median: 1.0
Average: 3.41

Neutral Scores boxplot
Min value: 1.0
Max value: 10.0
Lower and Upper Quartile: (1.0, 1.0)
Median: 1.0
Average: 1.92

Comprehension Scores:
Driven Scores boxplot
Min value: 0.0
Max value: 1.0
Lower and Upper Quartile: (0.0, 1.0)
Median: 0.67
Average: 0.56

Neutral Scores boxplot
Min value: 0.0
Max value: 1.0
Lower and Upper Quartile: (0.0, 0.67)
Median: 0.0
Average: 0.31"
images/673e92340023a4eb42572964ac9343eda8798a1e_Image_006.jpg,"An image of two types of visualizations that are provided to the user. The Error Type Graph (top) shows the frequency of different kinds of error types over time. The Website Graph (bottom) shows the most common websites where pointing errors have occurred. When users hover over data points, additional information is shown."
images/5fc3aef74377c8528d6ce115ea04499f30aa306f_Image_009.png,"Three set of graphs: Grammar, Understand, and Natural.

Percentage of Accounted Variance (Adj. R2) for Grammar:
1. Best Performing Single-Metric Model for Each Dependent Variable: 9.95
2. Multiple_Metric Model (corresponds to Figures 1, 2, and 3): 21.67
Significant deifference between 1 and 2: p < 0.01
The best single-metric model for Grammar uses the NormFaceToFromHands eyetracking metric

Percentage of Accounted Variance (Adj. R2) for Understand:
1. Best Performing Single-Metric Model for Each Dependent Variable: 18.32
2. Multiple_Metric Model (corresponds to Figures 1, 2, and 3): 24.03
Significant deifference between 1 and 2: p < 0.05
The best single-metric model for Understand uses the FaceTotalFixTime eyetracking metric

Percentage of Accounted Variance (Adj. R2) for Natural:
1. Best Performing Single-Metric Model for Each Dependent Variable: 19.46
2. Multiple_Metric Model (corresponds to Figures 1, 2, and 3): 35.24
Significant deifference between 1 and 2: p < 0.001
The best single-metric model for Natural uses the PercentFaceFix eyetracking metric"
images/2247b3cb46f3b434c8018fdf71ec8c9f780d7239_Image_001.png,"Figure 1: Text stating ""I'd like to visualize 'Origin', 'Miles_per_Gallon', and 'Displacement'"". Two visualizations are shown. The first, a colored tick plot with 'Miles_per_Gallon' on x, 'Origin' on y, and 'Displacement' on color. Next, a colored scatterplot, with 'Miles_per_Gallon' on x, 'Displacement' on y, and 'Origin' on color. There is a question mark between them."
images/2247b3cb46f3b434c8018fdf71ec8c9f780d7239_Image_002.png,"Figure 1: Text stating ""I'd like to visualize 'Origin', 'Miles_per_Gallon', and 'Displacement'"". Two visualizations are shown. The first, a colored tick plot with 'Miles_per_Gallon' on x, 'Origin' on y, and 'Displacement' on color. Next, a colored scatterplot, with 'Miles_per_Gallon' on x, 'Displacement' on y, and 'Origin' on color. There is a question mark between them."
images/2247b3cb46f3b434c8018fdf71ec8c9f780d7239_Image_004.png,"Figure 2: A series of three visualizations. On the left, a histogram of 'life expectancy' on x and count on y. Next, text stating '+ country' followed by a binned circle plot of the two fields, 'country' on y, 'life expectancy on x, and count on size. Finally, text stating '+ fertility' and a colored tick plot, with 'life expectancy' on x, 'fertility' on y, and 'country' on color."
images/2247b3cb46f3b434c8018fdf71ec8c9f780d7239_Image_005.png,"A bubble chart with ""IMDB Rating"" binned on x, ""Rotten Tomatoes Rating"" on y, and ""US Gross"" on size."
images/2247b3cb46f3b434c8018fdf71ec8c9f780d7239_Image_006.png,"A histogram with ""IMDB Rating"" binned on x, ""US Gross"" on y, and ""Mean of Rotten Tomatoes Rating"" encoded in the bars' color."
images/2247b3cb46f3b434c8018fdf71ec8c9f780d7239_Image_012.png,"Figure 3: Three visualizations. At the top, labeled (a), a bar chart of movie Genres on y and counts on x, along with the Dziban code to generate it (`genre = Chart(movies).field('Major_Genre'`) then new line, `genre`). To the left, labeled (b), a binned circle plot with Genre on x, MPAA Rating on y, and count on size, a cold recommendation (`genre.field('MPAA_Rating')`). To the right, labeled (c) a stacked bar chart with Genre on y, counts on x, and MPAA Rating on color---an anchored recommendation (`genre.anchor().field('MPAA_Rating')`)."
images/b685aec04e942f0b78e729407fd49eb9e0f84fac_Image_005.jpg,"This figure is a bar chart of the average level of  meaningfulness for each of 5 different types of smartphone uses and gratifications. Meaningfulness is shown on the y-axis on a 1-7 point scale. These values are: Productivity (3.6), Information (3.3), Communication (3.3), Entertainment (2.5), and Social Media (2.4)."
images/b685aec04e942f0b78e729407fd49eb9e0f84fac_Image_006.jpg,This figure is a bar chart of the average level of  meaningfulness for 2 motivations of use. Meaningfulness is shown on the y-axis on a 1-7 point scale. These motivations are: Instrumental (3.5) and Habitual (2.5).
images/b685aec04e942f0b78e729407fd49eb9e0f84fac_Image_007.jpg,"This bar graph shows desired frequency on the y-axis (1-5 scale). In order from highest desired frequency to lowest, the 5 U&G types are: productivity, information, communication, entertainment, and social media."
images/b685aec04e942f0b78e729407fd49eb9e0f84fac_Image_008.jpg,"This figure is a stacked bar chart of the motivation behind use at the start, during, and end timing of app use samples. The percentage share of instrumental motivation declined from the start timing (65.6%) to the during timing (51.4%). There was a slight increase in instrumental use from the during timing to the end timing (55.7%)."
images/b685aec04e942f0b78e729407fd49eb9e0f84fac_Image_009.jpg,"This line graph shows the percentage share of instrumental motivation for 5 types of use as timing goes from start, during, to end. The absolute change in instrumental motivation from the start to the end timing was: 0.0% for productivity, -4.0% for information, -6.0% for communication, -7.9% for entertainment, and -9.8% for social media."
images/da5aab6640de0c621ab5a53137722824ed805ebd_Image_008.jpg,7dLYlPu1xm3r-3ujXhUGLXQ79wb8hI2iMXJNQjlHXf-4BQ4tgfJ4m7OuF4TyIyyJinhjYrg0f1H_T62Npz7kyOh0jzJqLtvv_Y1vswFQb9dTXvLlh4IL0PtG
images/1885a9b16ab1afc22fa15f787472018b0ab8ea4c_Image_008.jpg,"Figure 4. Completion time of each UI in the referencing tasks in Study 1. Data labels are mean values, and error bars represent standard deviation."
images/1885a9b16ab1afc22fa15f787472018b0ab8ea4c_Image_009.jpg,"Figure 5. (a) Cumbersomeness and (b) writing effort of each UI in the referencing tasks in Study 1. Data labels are mean values, and error bars represent standard deviation."
images/1885a9b16ab1afc22fa15f787472018b0ab8ea4c_Image_010.jpg,"Participants’ feedback on the design of our interface’s main components were mostly positive. The contextual activity window and on-demand widget were deemed natural and not distracting. P9 in Study 1 felt that the display of different materials in the contextual activity window based on user’s current action is intuitive, while P10 found the on-demand widget useful for checking what she has referred. While some found a slight learning curve with Korero, they all agreed that it was more convenient and efficient once they have learned it, to the extent that they can quickly adapt to the interface in the relatively short time of the user studies. In the post-study interviews, P3 and P12 from Study 1 voiced the need to support and facilitate elaborate references in certain scenarios, such as collaborative discussion in Google Docs and MOOCs."
images/1885a9b16ab1afc22fa15f787472018b0ab8ea4c_Image_011.jpg,"Participants’ feedback on the design of our interface’s main components were mostly positive. The contextual activity window and on-demand widget were deemed natural and not distracting. P9 in Study 1 felt that the display of different materials in the contextual activity window based on user’s current action is intuitive, while P10 found the on-demand widget useful for checking what she has referred. While some found a slight learning curve with Korero, they all agreed that it was more convenient and efficient once they have learned it, to the extent that they can quickly adapt to the interface in the relatively short time of the user studies. In the post-study interviews, P3 and P12 from Study 1 voiced the need to support and facilitate elaborate references in certain scenarios, such as collaborative discussion in Google Docs and MOOCs."
images/ccbb556035dcb992b4b966f03ce8a59b20c064aa_Image_004.png,"Bar chart of RSME results for respective gestures. From highest to lowest: Clap, Double Clap, Snap, Swipe and Wave. Error Bars showing standard error."
images/377c33d7bc0f4b0d3d66b74536be8aadfe5f13b0_Image_004.jpg,"A grouped column graph showing results for means of satisfaction scores in the in-person study for each behavior. Each behavior is listed on the x-axis, with satisfaction scores on the y-axis. The following lists each behavior groups with three means, one for high, medium, and low levels of that behavior. Speech rate had means of 7.1, 7.95, and 6.95 for high, medium, and low, respectively. Voice intensity had means of 6.9, 7.25, and 5.9. Enunciation had means of 6.9, 8.3, and 5.9. Intonation had means of 7.85, 7.95, and 6.4. Eye contact had means of 7.95, 7.8, and 7. Gesturing had means of 8.65, 7.95, and 7.60. Intermittent pausing had means of 6.3, 7.3, and 7.45. A double asterisk is shown next to the behaviors Enunciation and Intonation as they had significant omnibus Friedman test results. A double asterisk, denoting pairwise significant differences are shown between the pairs medium and low enunciation as well as high and low intonation."
images/377c33d7bc0f4b0d3d66b74536be8aadfe5f13b0_Image_005.jpg,"A grouped column graph showing results for means of satisfaction scores in the remote study for each behavior. Each behavior is listed on the x-axis, with satisfaction scores on the y-axis. The following lists each behavior groups with three means, one for high, medium, and low levels of that behavior. Speech rate had means of 3.61, 5.74, and 3.75 for high, medium, and low, respectively. Voice intensity had means of 6.91, 6.57, and 4.61. Enunciation had means of 5.96, 6.48, and 4.04. Intonation had means of 7, 6.48, and 5.74. Eye contact had means of 6.43, 5.83, and 3.65. Gesturing had means of 7, 6.74, and 5.65. Intermittent pausing had means of 5.52, 6.48, 5.39. A double asterisk is shown next to the behaviors Speech Rate, Voice Intensity, Enunciation, Intonation, and Eye Contact as they had significant omnibus Friedman test results. A double asterisk, denoting pairwise significant differences are shown between the pairs High and Medium speech rate, medium and low speech rate, high and low intensity, medium and low intensity, medium and low enunciation, high and low eye contact, and medium and low eye contact."
images/b61e1747b1fef3eedde7aa87f26338f61d52ce93_Image_004.jpg,"This figure shows a stacked bar plot of percentages of a time-spent scale with 6 points. The y-axis shows the percentage of participants. The x-axis has X categories ""On-screen"" and ""Paper"".  The following scale responses are shown from bottom to top: ""> 60 minutes"", ""30-60 minutes"", ""15-29 minutes"", ""10-15 minutes"", ""5-9 minutes"", ""1-4 minutes"", ""None at all"".  For ""On-screen"",  47% responded ""> 60 minutes"", 31 % responded ""30-60 minutes"",  6% responded ""15-29 minutes"",  6% responded ""10-15 minutes"",  6% responded ""5-9 minutes"", 3% responded ""1-4 minutes"".  For ""Paper"",  31% responded ""> 60 minutes"",  16% responded ""30-60 minutes"",  12.5% responded ""15-29 minutes"",  31% responded ""10-15 minutes"",  12.5% responded ""5-9 minutes"",  3% responded ""1-4 minutes"",  22% responded ""None at all""."
images/b61e1747b1fef3eedde7aa87f26338f61d52ce93_Image_008.jpg,"This figure shows a stacked bar plot of percentages of 5-point frequency scale responses. The y-axis shows the percentage of participants. The x-axis has X categories ""Reading"" and ""Video"".  The following scale responses are shown from bottom to top: ""Daily"", ""Often"", ""Weekly"", ""Monthly"",  and ""Rarely""  For ""Reading"",  28% responded ""Daily"", 28% responded ""Often"", 15.5% responded ""Weekly"", 15.5% responded ""Monthly, and 12.5% responded ""Rarely.""  For ""Video"",  10% responded ""Daily"", 29% responded ""Often"", 19% responded ""Weekly"", 29% responded ""Monthly, and 13% responded ""Rarely."""
images/b61e1747b1fef3eedde7aa87f26338f61d52ce93_Image_009.jpg,"Figure 7 shows a stacked bar plot of percentages of 5-point frequency scale responses. The y-axis shows the percentage of participants. The x-axis, labeled as ""Purpose,"" has 9 categories: ""Academic"", ""Medical"", ""Legal"",  ""Work"", ""Personal Reading"", ""News"", ""Visual media"", ""Personal com."",  ""Recreation"". These scale responses are shown from bottom to top: ""Daily"", ""Often"", ""Weekly"", ""Monthly"",  and ""Rarely"". These scalre responses are shown from bottom to top:  ""Extremely Interested"", ""Very Interested"", ""Somewhat Interested"", ""Slightly Interested"", ""Not Interested"". For ""Academic"", 37.5% selected ""Extremely Interested"", 22% ""Very Interested"", 21%  ""Somewhat Interested"", 12.5%  ""Slightly Interested"", 6%  ""Not Interested"". For ""Medical"", 37.5% selected ""Extremely Interested"", 19%  ""Very Interested"", 25%  ""Somewhat Interested"", 6%  ""Slightly Interested"", 12.5%  ""Not Interested"". For ""Legal"", 47% selected ""Extremely Interested"", 6%  ""Very Interested"", 28%  ""Somewhat Interested"", 9%  ""Slightly Interested"", 9%  ""Not Interested"". For ""Work"", 31% selected ""Extremely Interested"", 19%  ""Very Interested"", 25%  ""Somewhat Interested"", 12.5%  ""Slightly Interested"", 12.5%  ""Not Interested"". For ""Personal reading"", 22% selected ""Extremely Interested"", 25%  ""Very Interested"", 6%  ""Somewhat Interested"", 25%  ""Slightly Interested"", 22%  ""Not Interested"". For ""News"", 9% selected ""Extremely Interested"", 3%  ""Very Interested"", 16%  ""Somewhat Interested"", 22%  ""Slightly Interondedested"", 22%  ""Not Interested"". For ""Visual media"", 9% selected ""Extremely Interested"", 25%  ""Very Interested"", 19%  ""Somewhat Interested"", 12.5%  ""Slightly Interested"", 34.5%  ""Not Interested"". For ""Personal comm."", 19% selected ""Extremely Interested"", 12.5%  ""Very Interested"", 15.5%  ""Somewhat Interested"", 25%  ""Slightly Interested"", 28%  ""Not Interested"". For ""Recreation"", 3% selected ""Extremely Interested"", 12.5%  ""Very Interested"", 25%  ""Somewhat Interested"", 22%  ""Slightly Interested"", 37.5% ""Not interested"""
images/8dfa5d035b93b2987ac0997f10851a11f6f90865_Image_010.jpg,"A distribution of experiment design scores showing that 33 experiments scores more than 11 on a scale of 13, 20 scored between 8.8 and 10.9, 7 scored between6.7 and 8.8, and 3 scored between 4.6 and 6.7, and 3 between 2.5 and 4.6. Another distribution shows topics across all experiments that include 61% experiments about diet, 11% about technology use, 9% about alternate treatments, and 20% others"
images/8dfa5d035b93b2987ac0997f10851a11f6f90865_Image_011.jpg,"A distribution shows how review comments were distributed across different sections: 12% Overall, 9% Criteria, 21% Conditions, 35% Measures, and 23% Hypothesis. Comment distribution highlights 75 comments between 0 and 80 chars length and few beyond character length 311 chars. A long descriptive comment on an experiment."
images/8dfa5d035b93b2987ac0997f10851a11f6f90865_Image_012.jpg,Experiment results from 3 experiments. A boxplot comparison of people's stool consistency when they drank kombucha vs those who did not. No kombucha's stool consistency mean is 4.2 while yes kombucha's is 3.9. Two more graphs showing regression line and bar plots.
images/8dfa5d035b93b2987ac0997f10851a11f6f90865_Image_013.jpg,"Three bar plots showing how three communities -- kombucha, open humans, beer -- signed up, participated, and adhered to the instructions"
images/eec67f6d85f017c4b5c349b0ce85398b85c3919b_Image_004.jpg,Figure 3: This figure shows the results of Study 1. Sub-figure (a) shows that the average time to select targets under the condition of appended upper limb is significantly shorter than that under the condition of no reference. Sub-figure (b) shows that the average rating on target position estimation under the condition of appended upper limb is significantly better than that under the condition of no reference.
images/1e7672d17103be22a238cadd435f9385b70e86c7_Image_010.jpg,"Bar chart displaying that ShoulderCam measurements took less time than (in seconds) than goniomter measurements. P4 and P8 were omitted due to being measured by a member of the research team. The data below:

 Gon ShoulderCam
P1 252 69
P2 342 95
P3 330 127
P5 478 124
P6 158 77
P7 124 65
P9 395 269
P10 208 117
P11 218 106"
images/cd857ed14546749328da5ddbc173e34a31ddb499_Image_006.jpg,Reanalysis of data from Roy et al. and Liu et al.: reaction time as a function of stimulus uncertainty.
images/32ae01c420064cbc5dffe553fc458c8604567f8b_Image_007.jpg,"Figure 6: ""Boxplots showing the sadness (left) and happiness (right) changes of wearers and non-wearers. The changes are calculated by subtracting the ratings in the control condition from the ratings in other conditions (emotion ratings in the glasses-without/with-tears condition - emotion ratings in the control condition)."""
images/32ae01c420064cbc5dffe553fc458c8604567f8b_Image_008.jpg,"Figure 6: ""Boxplots showing the sadness (left) and happiness (right) changes of wearers and non-wearers. The changes are calculated by subtracting the ratings in the control condition from the ratings in other conditions (emotion ratings in the glasses-without/with-tears condition - emotion ratings in the control condition)."""
images/32ae01c420064cbc5dffe553fc458c8604567f8b_Image_009.jpg,"Figure 7: ""Average positive-negative scores estimated from the participans' texts written after each condition. Error bars denote standard errors."""
images/a402b43d934bad20577e0c56fc5e5373bb97db15_Image_006.jpg,"Figure 4: ``Heat maps presented and referred to in the paper are assembled as part of an overall comparison. Along the x-axis, its notes the different conditions (all, competitive, and cooperative) and the y-axis denotes fixed and floating (as alternating rows), and the nature of the recorded data (digital space enemies targeted, physical space finger touch points, and physical floor space).''"
images/3db37ace99a8714b85ea5773fefd1e29ddc51da3_Image_006.jpg,"The Baseline Environment showing the Default Chrome Search Interface, augmented with Suggestions Bar at the top of the search interface with query autocompletion suggestions (a). The standard query assistance features remain on the Search Engine Results Page: People Also ask (b), People Also Ask (c), Related Searches (d). Picture cropped to remove search results"
images/8faf8db60e05a356f94fff2cf55954ccfd896f05_Image_004.png,"3 timelines stacked on top of each other. The first shows segments based on transcript sentences, the second shows navigational and editing command events, and the third shows all candidate boundary points created by combining the above two timelines together."
images/c34bb7e20d633c0f49746c367090a6f0b8172e0e_Image_002.jpg,Figure 1. Distribution of deviations for each of the panels for the 80 responses that contained a ground truth. Panels from User 1 to the right all had statistically significant higher deviations from ground truth than the Omnibus panel.
images/680984459a2ab9dcaed587a6e5775a25ce140804_Image_004.jpg,"Figure 3: A diagram of a Field Theory of Managing Diabetes. It is represented as a two-dimension graph that shows glucose levels in the y-axis, and temporal milestones (hospital, diagnosis, treatment, tools, education, practice) in the x-axis. The glucose curve ascends and descends regularly, also representing the ups and downs of the journey of self-managing diabetes, leading to a more stable curve after the use of tools, education and practice. The curve leads to identifying opportunities for design using Internet of Things."
images/0677defc03e335e85f83f6027d0b3bad8d802ae4_Image_006.jpg,Radar plot displaying means and standarddeviations of the four IPQ subscales for both conditions of the user study.
images/b58b35da221a853d5b99bbfaa3ea40252d70016b_Image_006.jpg,"The figure consists of two columns of 3 pictures each.  Picture a (top left) - The two electrodes of a multimeter are connected to each side of a stretch-sensitive yarn. A ruler is situated next to the yarn to show its length which seems to be approximately 10 centimeters. The user does not seem to stretch the yarn and the multimeter shows a value of 0.12MOhm.  Picture b (center left) - It is the same setup as Picture a, but this time the yarn is stretched to reach a length of approximately 20 centimeters. The multimeter shows a value of 1.18MOhm.  Picture c (bottom left) - A plot with two axes shows the evolution of the yarn resistance depending on its extension. It shows linear progression from approximately 0 to 5MOhm (y-axis) going from an extension of 0% to 100% by steps of 20% (x-axis).  Picture d (top right) - This is a close-up on a pressure sensing yarn held within fingertips. The yarn consists of a copper conductive core and a polymerized outer layer.  Picture e (center right) - The two electrodes of a multimeter are connected to two independent pressure-sensitive yarns that stack up on each other. The user is pressing the yarns at their intersection. The value on the multimeter shows a value of 1.93MOhm.  Picture f (bottom right) - A plot shows how the resistances of the yarns evolve depending on the weight applied on top of them. It shows a linear progression from 6MOhm to 2MOhm (y-axis) for weights going from 0.1g to 1000g increasing the weight ten times at each step (x-axis, logarithmic scale)."
images/fa7c681ffd0ea94a482755623a107fce48740b0d_Image_003.jpg,"Stacked bar chart showing how likely reasons for deleting messages. This graph is detailed in section 4.1. Sent by mistake, and sent to wrong recipient are the most likely reasons reported for deletion, while increase storage capacity is the least likely reason reported."
images/fa7c681ffd0ea94a482755623a107fce48740b0d_Image_006.jpg,"The left bar chart is showing reasons participants reported for why delete indicators might stop them from using the delete function. The chart is detailed in section 4.3 and shows most reported reason was to avoid negative assumptions, whilst fewest reported the reason was to avoid showing vulnerability.  The right bar chart is showing reasons participants reported for why delete indicators would not stop them from using the delete function. The chart is detailed in section 4.3.2 and shows most reported reason was the cost of it being read."
images/fa7c681ffd0ea94a482755623a107fce48740b0d_Image_007.png,"The left bar chart is showing reasons participants reported for why delete indicators might stop them from using the delete function. The chart is detailed in section 4.3 and shows most reported reason was to avoid negative assumptions, whilst fewest reported the reason was to avoid showing vulnerability.  The right bar chart is showing reasons participants reported for why delete indicators would not stop them from using the delete function. The chart is detailed in section 4.3.2 and shows most reported reason was the cost of it being read."
images/fa7c681ffd0ea94a482755623a107fce48740b0d_Image_008.png,"Stacked bar chart showing participants assumed reasons for the message being deleted, separated by group and pairwise chats. The chart is detailed in section 5.1.3 and shows most reported assumption was that it was sent to the wrong recipient."
images/fa7c681ffd0ea94a482755623a107fce48740b0d_Image_009.png,"Stacked bar chart showing participants (senders) reasons for the message being deleted, separated by group and pairwise chats. The chart is detailed in section 5.1 and shows most reported reason was that the content was incorrect."
images/544916d82b610b1721d7b9c271f9ef9016937635_Image_002.jpg,"This figure illustrates 3 dampening materials (cork, sorbothane, and spring) and their vibration properties. Also, there is a picture of the prototype's components: Arduino nano, FET shield, battery, charger, and micro USB connection."
images/6da504c2201d0795a9dc76732ba6f20494fd2dda_Image_003.jpg,In the screenshot of light graphs is a plateau in the value of the sensor in the hall from 8pm to 10pm clearly visible.
images/1bd67672e9376feaac80770695717b13ece2c47b_Image_007.png,"Box plot of the time for the participants to learn 26 letters(in seconds). The median value for each letter varies. Letter o has the lowest median(20.095), and letter f has the largest median(81.526), and most(19 letters) are below 50 seconds. The ranges from upper quartile to lower quartile also varies for each letter. Letter a, c, o has small quartile ranges but a few outliers, and letter f, n, q, s has large quartile ranges."
images/1bd67672e9376feaac80770695717b13ece2c47b_Image_010.png,"For the box plot, the median for three stages are 1, 7 and 22 respectively. The range between the lower and the upper quartile is the smallest for stage 0, and is the largest for stage 1. The line plot for each participants' performance for three stages indicate that all participants improved from stage 0 to stage 2."
images/d6b3f3fd502be27b698065d14dc97a1bc56b5792_Image_006.jpg,The boxplots show the difference between the actual and the falsified profiles in percent. The highest mean difference was achieved for agreeableness on average.
images/d5fb83ada0dc1ac5b566d0694e9ea3aa5bc02ed4_Image_005.jpg,https://lh4.googleusercontent.com/J1vq9XOOFja_9zmGaqSLIm-MfEgSOiF0dv2l6NZOkoSCd26Q4nq7KCUBug5JxIJWzc7yqOCW3VR0_BARU2RdTyENYcMwJ1GL9LxrwpX_g_yOQbXc1YeFPpI6na3wFKD-8A
images/666ee9fe09ce777ab9e9940ee465c8349d7ac43e_Image_012.jpg,"Figure 6: This Figure contains a 2D stacked column chart showing the results of the post-study survey (which was conducted after the field study).  In the x-axis, there are 4 questions/sentences which were given to the participants using a 1-5 Likert scale. The y-axis is the average of the rating per each question/sentence. Furthermore, each bar per question/sentence shows the distribution of the ratings. The ratio of each rating (from 1 to 5) is colored differently.  The first sentence is ""1) Sig helped me feel more comfortable when deciding whether to interact with strangers on Twitter"". Participants overall gave an average rating of 3.9/5 for this sentence. 4 people gave a 3, 4 people gave a 4, and 3 people gave a 5.  Next, for ""2) How would you rate your overall experience of using Sig?"" the average rating was 4 out of 5. 2 people gave a 3, 7 people gave a 4, and 2 people gave a 5.  For ""3) Was Sig's visualization of various social signals easy to understand?"" the average score was 4.7 out of 5. 3 people gave a 4 and 8 people gave a 5. Finally, for ""4) Would you be interested in using a refined version of Sig in the future?"", the average rating was 4.7 out of 5. 1 person gave a 2, 2 people gave a 3, 2 people gave a 4, and 6 people gave a 5."
images/233dd54bcbf3e6a151dce13a4d01a531a0648b04_Image_018.jpg,"Figure 8: ""A double bar graph showing the average survey responses for both the Treatment and Control condition. The vertical axis is labelled with the metric measured by the survey questions. 'Perceived Efficiency' and 'Perceived Effectiveness' were both higher in the Treatment condition when compared to the Control condition, and 'Aggregated NASA-TLX' was lower in the Treatment condition when compared to the Control condition."""
images/af1aae9b76b4edd2da0b86e3efe98cf3b11b36b5_Image_003.jpg,The association between planned (estimated) work duration and actual workday duration for each participant. The blue line shows a perfect relationship with no bias. Data points below the line indicate that the planned duration was longer than the actual one.
images/7cc25eed41bc78c0af8b1e3b57437da39d1e220c_Image_004.jpg,"The average value with the standard deviation of the presence and intensity of seventeen action units are shown in histograms. The values for correct responses, wrong responses, consistently detected responses are labeled with the color of black, orange and yellow respectively."
images/7cc25eed41bc78c0af8b1e3b57437da39d1e220c_Image_007.png,The left part shows the histogram of the averaged interruption times of four techniques in four colors. The right part shows the histogram of subjective scores for four dimensions. Four colors represent the scores of four different interruption techniques.
images/7cc25eed41bc78c0af8b1e3b57437da39d1e220c_Image_008.png,This figure shows the histogram of subjective scores for four dimensions. The scores from 1 to 7 are marked by 7 different colors.
images/b93cf632919c3ddf2a7efcd161bf03fe288761de_Image_005.jpg,"Figure 5: ""Distribution of participants' behavior in rooms 1, 2, and 3 according to avatar anthropomorphism and visibility."""
images/b93cf632919c3ddf2a7efcd161bf03fe288761de_Image_007.png,"Figure 7: ""Letter-value box plot of the time until the participants first walked through the wall in room 3, room 4, and across rooms according to avatar anthropomorphism and visibility. """
images/851f09fb796711c334599647d45759535163d36d_Image_012.jpg,Figure 9: Bar graph showing the rating of users' subjective feelings from 1 to 7 on the Y axis against the six evaluation metrics on the X axis.
images/91bc2ec316eb38527582f1cf9fc35ec4df4f9f0f_Image_009.jpg,"Figure 9A shows the results of device position accuracy evaluation. It is a spatial plot showing 8 targets equally spaced in a circle. Measured data points of device final position are overlaid, showing a small average error of 3.5 mm. Figure 9B shows average measured device speed versus target direction relative to the EHD. For a desired speed of 20 cm/s, the average measured speed was 19.4 cm/s. For 25 cm/s, the measured average was 26.6 cm/s. For 30 cm/s, it was 31.5 cm/s. For 35 cm/s, it was 35.6 cm/s."
images/91bc2ec316eb38527582f1cf9fc35ec4df4f9f0f_Image_013.jpg,"Figure 14A shows a plot of visuo-haptic latency in seconds versus device speed in cm/s. The mean latency for no redirection, limited REACH+, and REACH+ conditions are shown for each speed. The data is as follows. For 20 cm/s device speed: No Redirection = 0.22 s, Limited REACH+ = 0.13 s, REACH+ = 0.07 s. For 25 cm/s device speed: No Redirection = 0.06 s, Limited REACH+ = 0.04 s, REACH+ = 0.075 s. For 30 cm/s device speed: No Redirection = 0.02 s, Limited REACH+ = 0.03 s, REACH+ = 0.05 s. For 35 cm/s device speed: No Redirection = 0.04 s, Limited REACH+ = 0.03 s, REACH+ = 0.035 s. For 20 cm/s device speed, significant differences were found between no redirection and Limited REACH+ (p<0.001) and no redirection and REACH+ (p<0.001). Figure 14B shows a plot of on time arrival rate versus device speed in cm/s. The on time arrival rate of the EHD for no redirection, limited REACH+, and REACH+ conditions are shown for each speed. The data is as follows. For 20 cm/s device speed: No Redirection = 0.43, Limited REACH+ = 0.60, REACH+ = 0.71. For 25 cm/s device speed: No Redirection = 0.79, Limited REACH+ = 0.87, REACH+ = 0.77. For 30 cm/s device speed: No Redirection = 0.87, Limited REACH+ = 0.90, REACH+ = 0.80. For 35 cm/s device speed: No Redirection = 0.85, Limited REACH+ = 0.86, REACH+ = 0.85. For 20 cm/s device speed, significant differences were found between no redirection and Limited REACH+ (p<0.01) and no redirection and REACH+ (p<0.001)."
images/c0d867d3d13cbd748d77e960b554f8ea2eb0860d_Image_010.jpg,"This figure shows 2 plots for dominance (a and b). Subfigure a shows an interaction plot. On the x-axis, there are the two levels for the theme ""information content"" (high and low). On the y-axis, there is the dominance score from 4.45 to 4.80. A red line (red standing for two vehicles communicating) is starting left at approximately 4.65 and goes down to 4.45 five in the low content condition. A blue line (indicating one vehicle communicating) is also starting at approximately 4.65 but goes up to 4.80 for the low content condition.  Subfigure b shows for the x-axis the two levels of sight: seeing on the left and VIP on the right. For the y-axis, dominance is depicted from 4.3 to 4.9. The red line (indicating low information content) starts at 4.7 for the seeing going down to 4.3 for the VIP). The blue line indicating high information content, starts at 4.5 and goes up to 4.9 for the VIP."
images/60edc823de283d0b39d6269be3c18877eb489d93_Image_001.jpg,"Shows Gini indices for each combination of task, transform, and machine learning model."
images/60edc823de283d0b39d6269be3c18877eb489d93_Image_002.jpg,"Shows that the Shift transform maintains a relatively equal distribution of dividends while the Absolute Value and Clipping transforms create very unequal, long-tail distributions with ""superstars"" who earn 25-50x larger dividends."
images/664b42914e065121362a835185aaa07e08ea0075_Image_026.png,Error rates decrease over the 8-week period. Substitutions are clearly the most common error type.
images/664b42914e065121362a835185aaa07e08ea0075_Image_035.jpg,"Participants slowly improve performance from week to week as in laboratory settings; however, everyday typing performance is consistently higher than lab performance (average 1.5 times)."
images/664b42914e065121362a835185aaa07e08ea0075_Image_036.jpg,Uncorrected error rate is slightly higher in everyday typing tasks compared with laboratory performance. This results holds true for all participants.
images/7fa3a268386650d6940c6450eb41de2f28ff0a6a_Image_006.jpg,"A combination plot of a bar chart for mean error rate and a point chart using cross circle, coloured orange, for mean offset distance (in cm). The left y-axis indicates mean error rate and the right y-axis indicates the mean offset distance. The x-axis indicates the pointing condition. The first bar is VC, coloured grey. The 2nd, 3rd, and 4th bars, coloured yellow, represent pointing techniques with VB, and 5th, 6th, 7th bars, coloured blue, represent pointing techniques with WD. The error bar of each pointing conditions and the significant difference between each other are also visualised."
images/7fa3a268386650d6940c6450eb41de2f28ff0a6a_Image_007.jpg,"Bar chart of median completion time in milliseconds for the 7 pointing conditions in the smartphone study. The y-axis indicates median completion time and the x-axis indicates the pointing condition. The first bar is VC, coloured grey, which is faster than other pointing conditions. The 2nd, 3rd, and 4th bars, coloured yellow, represent pointing techniques with VB, which are faster than pointing techniques with WD (5th, 6th, 7th bar), coloured blue.  The significant difference between each other is also visualised."
images/7fa3a268386650d6940c6450eb41de2f28ff0a6a_Image_008.jpg,"Bar chart of mean score on each NASA TLX attribute for 7 pointing conditions in smartphone study. The y-axis indicates mean score and the x-axis indicates TLX attributes. For each attribute, each bar represents each pointing condition in the following sequence: VC, VBP2TR, VBP2TA, VBP1RR, WDP2TR, WDP2TA and WDP1RR. The error bar of each pointing conditions and the significant difference between each other are also visualised."
images/dda64d3fadc0eba6ce009dc5902f0eba451afcbf_Image_004.jpg,"Plot comparing frequency of coded gestures (lateral, enclosure, counting, contour, two hands, one hand) between the construction and consumption conditions for two questions."
images/1480dab32d9676b8a3db7946eccd7c8fc172273d_Image_006.jpg,"Comparison of touch / no touch for varying overlay thicknesses of PLA.  A graph shows the asymptotic dependency between increasing overlay thicknesses (from 0 to 20 mm) and the Signal-to-noise ratio. For thicknesses up to 10 mm the Signal-to-noise ratio drastically decreases with increasing thickness (resulting in a high gradient), but lies above a minimal value of 5, indicating robust measurements. For higher thicknesses the gradient asymptotically decreases.  Furthermore, a table lists the measured average capacitance readings when touched and not touched by a finger (including standard deviations), and the respective Signal-to-noise ratio for varying overlay thicknesses of 0.25, 0.5, 1, 2, 10, and 15 mm."
images/41cbffad975874060d643c36c8bdb5c72637564e_Image_004.jpg,"Plot of Effect of Surfaced Hits on ML-1M. Shows boycotts and data strikes. As size of boycotts/data strikes increases, Surfaced Hits are reduced."
images/41cbffad975874060d643c36c8bdb5c72637564e_Image_005.jpg,"Plot of Effect of Surfaced Hits on ML-1M. Shows boycotts and data strikes. As size of boycotts/data strikes increases, Surfaced Hits are reduced."
images/41cbffad975874060d643c36c8bdb5c72637564e_Image_006.jpg,"Plot of Effect of Surfaced Hits on ML-1M. Shows boycotts and data strikes. As size of boycotts/data strikes increases, Surfaced Hits are reduced. Zoomed in on effects between 0.71 and 0.78."
images/41cbffad975874060d643c36c8bdb5c72637564e_Image_007.jpg,"Plot of Effect of Surfaced Hits on ML-20M. Shows boycotts and data strikes. As size of boycotts/data strikes increases, Surfaced Hits are reduced. Zoomed in on effects between 0.71 and 0.78."
images/41cbffad975874060d643c36c8bdb5c72637564e_Image_008.jpg,"Scatterplot shows that the uniqueness of a group, measured by implicit rating cosine distance from centroid, correlates with the Similar User Effect Ratio."
images/9f6637a115774d3c04a3ae8e9dbef0d74e0b3d37_Image_002.jpg,"Figure 2: ""The distribution of moderation message counts per support type. Moderators mainly provided pedagogical and managerial support to discussants during chat-based discussion."""
images/9f6637a115774d3c04a3ae8e9dbef0d74e0b3d37_Image_004.jpg,"Figure 4: ""A distribution of moderation message counts per support type. Moderators mainly provided pedagogical and managerial support to discussants during chat-based discussion."""
images/9683f0243631f6b8ecaa8bece24ea0fb848f2dde_Image_003.jpg,"Column chart of amount of posts (ranging from 0 to about 300) over the time span 2015 until 2020, where bars show increasing numbers of posts over time. Stacked bars differentiate still image posts from video posts. In all cases the amount of video posts is lower than the amount of still image posts."
images/9683f0243631f6b8ecaa8bece24ea0fb848f2dde_Image_006.jpg,"Stacked area chart of word count cluster amounts over time (2020) where amounts of Nurse word cluster is the highest throughout time. COVID-19 word cluster amounts increase strongly around March, April and May and decrease afterwards."
images/e79cd418e238686f30e4b8f2660ab7e729fbec17_Image_009.png,Figure 3 is a bar graph that shows the number of participants who used a specific math e-learning tool. The data is sorted in descending order. 4 people used IXL Learning; 4 people used Khan Academy; 3 people used CMP3; 2 people used Flocabulary; 2 people used Kahoot!; 2 people used ST Math; 1 person used BrainPOP; 1 person used Prodigy; 1 person used DareDash; 1 person used Jungle Math; and 1 person used Slice Fractions.
images/abdf4590d986efc1465e3d2df1d13ec0af57110c_Image_008.jpg,The chart displays the relationship between force and pressure for all 8 configurations.
images/abdf4590d986efc1465e3d2df1d13ec0af57110c_Image_009.jpg,"The chart shows that noise depends on force and the use of nozzles, not tubing size and tubing length."
images/abdf4590d986efc1465e3d2df1d13ec0af57110c_Image_010.png,The bar charts show the maximum frequencies under different tubing configurations and different force magnitude.
images/4f2a57fd4fc6fac14d15cf73711d867f58277500_Image_007.jpg,There are two boxplots per participants. Green one is for the TV viewing condition and the orange one is for the Wall viewing condition.     P1. green boxplot is from 2.17 seconds to 4.51 seconds and the center position is 3.08 seconds. Orange boxplot is from 2.30 seconds to 4.81 seconds and the center position is 3.40 seconds.  P2. green boxplot is from 1.62 seconds to 2.69 seconds and the center position is 2.24 seconds. Orange boxplot is from 1.95 seconds to 4.13 seconds and the center position is 2.50 seconds.  P3. green boxplot is from 1.84 seconds to 2.77 seconds and the center position is 2.34 seconds. Orange boxplot is from 1.74 seconds to 2.40 seconds and the center position is 2.00 seconds.  P4. green boxplot is from 1.73 seconds to 3.35 seconds and the center position is 2.20 seconds. Orange boxplot is from 1.62 seconds to 2.86 seconds and the center position is 2.37 seconds.  P5. green boxplot is from 1.59 seconds to 2.36 seconds and the center position is 2.04 seconds. Orange boxplot is from 1.62 seconds to 2.20 seconds and the center position is 1.88 seconds.  P6. green boxplot is from 1.65 seconds to 2.10 seconds and the center position is 1.84seconds. Orange boxplot is from 1.76 seconds to 2.63 seconds and the center position is 2.16 seconds.  P7. green boxplot is from 2.04 seconds to 3.80 seconds and the center position is 2.56 seconds. Orange boxplot is from 2.58 seconds to 4.55 seconds and the center position is 3.50 seconds.
images/4f2a57fd4fc6fac14d15cf73711d867f58277500_Image_008.jpg,Y axis means participant (numbered with 'P') and X axis means score. There are two bars per participants in horizontal direction. The length of the bar represent the SUS survey scores.   P1. TV condition score is 47.5 and Wall condition score is 35.  P2. TV condition score is 80 and Wall condition score is 75.  P3. TV condition score is 87.5 and Wall condition score is 85.  P4. TV condition score is 82.5 and Wall condition score is 80.  P5. TV condition score is 65 and Wall condition score is 62.5.  P6. TV condition score is 97.5 and Wall condition score is 100.  P7. TV condition score is 87.5 and Wall condition score is 82.5.
images/4f2a57fd4fc6fac14d15cf73711d867f58277500_Image_009.jpg,"(a) There are two bar graph and two line graph. X-axis labeled as Phase and it is from 0 to 2 pi. Both barr graphs has similar heights across the x-axis and both line graph has peak at the 3/4 pi position and 15/8 pi position, and the peak at the 3/4 pi position is more higher than the peak at the 15/8 pi position  (b) cosine x graph and minus cosine x graph are ploated across the x-axis. from 0 to 2 pi"
images/eac27bcb03414777025ff11b23c5dade8f5f2bca_Image_006.jpg,"Likert Scale for 1 = Extremely Inappropriate or Extremely Uncomfortable and 9 = Extremely Appropriate or Extremely Comfort- able. Orange for the olfactory necklace, grey for the glasses, and blue for the nose prototype. Error bars correspond to ±1 S.D. On the top, so- cial acceptance for the necklace (M = 7.25, S.D = 2.75), glasses (M = 6.5, S.D = 1.56), nose (M = 4.7, S.D = 2.01). Comfort while wearing the nose prototype (M = 4.29, S.D = 1.88), necklace (M = 7.7, S.D=1.9), glasses (M = 6.37, S.D = 1.78). ***P-value <0.001, **P-value < 0.01."
images/eac27bcb03414777025ff11b23c5dade8f5f2bca_Image_007.jpg,"""Moist"" - humidity felt on the face, ""Smell"" - intensity of the smell, ""Burst"" - visual spray, ""Sound"" - emitted when a burst is released. Error bars correspond to ±1 S.D. The wearers smelled the fragrance significantly more than the observers for all the prototypes (***P-value < 0.001). The bursts were significantly more visible for the nose prototype than for the necklace (***P-value < 0.001) and for the glasses *P < 0.05 (both the wearer and reviewer)"
images/bf5a5fdd71822c36f869deacb4e45db1713a9b13_Image_013.png,Average distance of gaze (blue; the bottom curve) and cursor (green; the top curve) from target over time
images/bf5a5fdd71822c36f869deacb4e45db1713a9b13_Image_014.png,Average distance of cursor from target over time for conditions: mid-air (blue; denoted as superscript M; the top curve) and passive haptic feedback (green; denoted as superscript H; the bottom curve)
images/827573a74c097a0f83e79454e750d094d415b436_Image_011.png,16 heat maps display all 16 gestures performed by one of the participants. Each entry is an average heat map of 10 trials of a gesture. The sensor reading patterns are significantly different across 16 gestures.
images/f06a381ef1ff7d02a6a1876548e83db20e71442f_Image_005.jpg,"Figure 3. Plots with feature vectors for the different gestures and participants. The plot shows data from one repetition (out of 9) for the 12 participants (horizontal axis) for the 8 gestures (vertical axis). Each sub-image shows a plot of 16 overlaid feature vectors, which has been interpolated to 80 observations over time. Participants performed gestures without feedback and in their own style, which required user-dependent classification. Some potential issues can be seen in the time series:"
images/f06a381ef1ff7d02a6a1876548e83db20e71442f_Image_009.jpg,"Figure 7a. Time on task Boxplot with task completion times for the three input devices. I/O Braid was faster than Buttons (statistical significance).   Figure 7b. Excess motion: Total trial vs last 1 second while locking on target. I/O Braid had more excess motion compared to Buttons and Scroll. The boxplots show median values with quartiles and min/max extent.   Figure 7c. Weighted average subjective feedback.  We mapped the 7-point Likert scale to a score in the range [-3, 3] for Ease of Use, Perceived Accuracy and Tactile Feel. We multiplied the score by the number of times the technique received that rating and computed an average for all the scores. The chart show favorable scores for I/O Braid and Scroll, whereas Buttons was the least popular."
images/f06a381ef1ff7d02a6a1876548e83db20e71442f_Image_010.jpg,"Figure 7a. Time on task Boxplot with task completion times for the three input devices. I/O Braid was faster than Buttons (statistical significance).   Figure 7b. Excess motion: Total trial vs last 1 second while locking on target. I/O Braid had more excess motion compared to Buttons and Scroll. The boxplots show median values with quartiles and min/max extent.   Figure 7c. Weighted average subjective feedback.  We mapped the 7-point Likert scale to a score in the range [-3, 3] for Ease of Use, Perceived Accuracy and Tactile Feel. We multiplied the score by the number of times the technique received that rating and computed an average for all the scores. The chart show favorable scores for I/O Braid and Scroll, whereas Buttons was the least popular."
images/f06a381ef1ff7d02a6a1876548e83db20e71442f_Image_011.jpg,"Figure 7a. Time on task Boxplot with task completion times for the three input devices. I/O Braid was faster than Buttons (statistical significance).   Figure 7b. Excess motion: Total trial vs last 1 second while locking on target. I/O Braid had more excess motion compared to Buttons and Scroll. The boxplots show median values with quartiles and min/max extent.   Figure 7c. Weighted average subjective feedback.  We mapped the 7-point Likert scale to a score in the range [-3, 3] for Ease of Use, Perceived Accuracy and Tactile Feel. We multiplied the score by the number of times the technique received that rating and computed an average for all the scores. The chart show favorable scores for I/O Braid and Scroll, whereas Buttons was the least popular."
images/5894fd4581a79a7067102891bc3db5738195941f_Image_005.jpg,"Bar chart with error bars presents the correction time for four VR text revision techniques when dealing with different types of revision targets. Overall, revising targets that far from the end of the sentence takes more time than those targets near the end of the sentence."
images/5894fd4581a79a7067102891bc3db5738195941f_Image_007.jpg,"Bar chart with error bars presents the caret control time for four VR text revision techniques when dealing with different types of revision targets. Overall, using the discrete caret control requires more time to navigate the caret than the continuous caret control."
images/5894fd4581a79a7067102891bc3db5738195941f_Image_008.jpg,"Bar chart with error bars presents the backspace time for four VR text revision techniques when dealing with different types of revision targets. Overall, using the character-level bacskapce requires more time to delete characters than the word-level backspace."
images/232ed7c309cddf2c3a007fa2880174a3b9d4c891_Image_014.jpg,https://lh3.googleusercontent.com/3J7sySSc7knFIKZbydofGg41fjNLMdKOaY3C06DD0rEQolAIgvuzJiATSWLdTaSzkEEmV0cNTmFOKQRl0EVHOtCspHjiIjrqqHTOdLwiO0ZULru9MR_qlMIFQg
images/341ee80cdaeb3403beae340824f7127cb9d77622_Image_014.jpg,"The first line graph showing that the discrete output from a Speed Detector almost fit the ground truth.  The second line graph showing that the longitudinal acceleration output from an Inertia Detector has a similar trend with ground truth, but with a smaller magnitude.  The third line graph showing that the lateral acceleration output from an Inertia Detector has a similar trend with the ground truth, but cramped to -20 to 20."
images/09ad32856da3e455b58e637c4d0f4efe34573ca3_Image_002.jpg,"Bar chart of number of participants that considered to stop using their tracker, shows that 40% of the participants somewhat to strongly agree to having considered to stop using their tracker."
images/09ad32856da3e455b58e637c4d0f4efe34573ca3_Image_006.jpg,"Bar chart of the regularity of which participants check their tracker data, 63% of the participants check their data at least once a day."
images/09ad32856da3e455b58e637c4d0f4efe34573ca3_Image_008.jpg,"Bar chart of number of participants that reflect on their data spontaneously, shows that 85% of the participants somewhat to strongly agree that reflection happens spontaneously."
images/09ad32856da3e455b58e637c4d0f4efe34573ca3_Image_010.jpg,"Bar chart of number of participants are satisfied about how the tracker data reflects their daily activities, shows that 95% of the participants somewhat to strongly agree to this."
images/3aa4cfaadcfc1172d3439ca6cfd55177420589ae_Image_028.png,Error rates decrease over the 8-week period. Substitutions are clearly the most common error type.
images/3aa4cfaadcfc1172d3439ca6cfd55177420589ae_Image_037.jpg,"Participants slowly improve performance from week to week as in laboratory settings; however, everyday typing performance is consistently higher than lab performance (average 1.5 times)."
images/3aa4cfaadcfc1172d3439ca6cfd55177420589ae_Image_038.jpg,Uncorrected error rate is slightly higher in everyday typing tasks compared with laboratory performance. This results holds true for all participants.
images/6c91ce2625e85d690e8ad2131cc9e759d18ed51b_Image_005.png,"Four plots are shown, corresponding to the four experimental conditions. The y-axis on each plot shows the percent of participants who correctly identified that the dot was an OSI. The x-axis has 5 marks to correspond to the 5 images shown to participants. All four graphs show a monotonically increasing number of participants getting the correct response. The plot for the green condition shows a significantly greater area under the curve that connects the 5 data points, because more participants answered correctly for earlier images in the sequence."
images/6c91ce2625e85d690e8ad2131cc9e759d18ed51b_Image_006.jpg,"A stacked bar chart showing how many participants guessed that an app does or does not have OSIs and how many participants were not sure. Each bar is the same height, so that the bars show the percent of people answering about this app that gave each answer choice, and the total number of participants giving each answer is overlaid on top of the bars. The top 15 most popular apps, used by at least 10% of participants, are shown, with responses ranging from mostly correctly stating that the app had OSIs to mostly expressing uncertainty about whether the app had OSIs."" Table 4: ""A table conveying the mean difference, SE, DF, t value, p value, and 95% CI between the green dot experimental condition and each other color (blue, gray, orange)."
images/0bc157f953ea87ab91323fd70ff95af28332e818_Image_011.jpg,"Box-plots of Area Ratio (script/Latin), which ranges on the y-axis from 0.0-2.0. The scripts plotted are Matilda, Tricolor Braille, Version 2, and Version 1. For each, low-vision and sighted groups are plotted separately. The medians are approximately: Matilda (low-vision: 1.0, sighted: 1.2); Tricolor Braille (low-vision: 0.9, sighted: 0.6); Version 2 (low-vision: 0.7, sighted: 0.6); Version 1 (low-vision: 0.5, sighted: 0.55)."
images/0bc157f953ea87ab91323fd70ff95af28332e818_Image_012.jpg,"Box-plot of Time Ration (script/Latin). Scripts plotted, in order: Matilda, Version 1, Version 2, Tricolor Braille, Armenian, Hebrew, Arabic, Devangari, Chinese. Low-vision and sighted groups are plotted separately for each. Medians range from about 1 for Matilda to about 3 for Chinese. The spread for Chinese is the largest by far."
images/c9c4eef7b43440cb866cdd74715e01dfa995f075_Image_019.jpg,"A bubble chart shows a matrix of bubbles, where the rows are countries (U.S., China, Taiwan) and the columns are behavior categories. Each bubble has a number label corresponding to its area, which reflects the average number of a times a parent from the sample (row) performed the specific behavior (column) during the instructional game session.  Taiwan: Intervention: 17.75 Instruction: 16.25 Open-Ended: 12.83 Augmentation: 8.58 Warmth: 12.83  China: Intervention: 7.3 Instruction: 8.2 Open-Ended: 8.0 Augmentation: 7.4 Warmth: 3.8  U.S. Intervention: 2.4 Instruction: 6.26 Open-Ended: 7.6 Augmentation: 9.6 Warmth: 22.8"
images/c9c4eef7b43440cb866cdd74715e01dfa995f075_Image_020.jpg,"A bubble chart shows a matrix of bubbles, where the rows are countries (U.S., China, Taiwan) and the columns are behavior categories. Each bubble has a number label corresponding to its area, which reflects the average number of a times a parent from the sample (row) performed the specific behavior (column) during the instructional game session.  Taiwan: Intervention: 4.17 Instruction: 7.7 Open-Ended: 6 Augmentation: 8.83 Warmth: 4.83  China: Intervention: 2.4 Instruction: 5.0 Open-Ended: 7.4 Augmentation: 7.4 Warmth: 1.6  U.S. Intervention: 0.5 Instruction: 4.5 Open-Ended: 8.1 Augmentation: 20.9 Warmth: 9.9"
images/ac5ed73b8241b1de45a45ca6aad1e34726dc236b_Image_008.jpg,"Average rating of enjoyment, realism, and intuitiveness on a 7-point Likert scale for the football experience, showing that Miniature Haptics significantly improved enjoyment and realism compared. to controller with vibration feedback and finger walking. There are significant difference between following pairs: enjoyment, MiniatureHaptics vs finger walking and controller; realism, all 3 pairs."
images/ac5ed73b8241b1de45a45ca6aad1e34726dc236b_Image_009.jpg,A pie chart showing distribution of the most preferred interaction method for the football experience. It shows that Miniature Haptics was the most preferred interaction method at 58%. The controller and finger walking are 25% and 17% respectively.
images/e06c93b3b1e062ebaae9f3b570eab2398b284785_Image_010.jpg,"Figure 9. The mean time participants spent on each model, broken down by the different sections in Markit."
images/beec9b27e310c14ccf0235582c11ce4aa9e4214c_Image_006.jpg,"Line graph comparing the standardized MEFS scores between children who played CMC and children who played DT from baseline to the short-term post-test. From baseline to short-term post-test, the CMC line goes up from about 0.4 to 0.5. From baseline to short-term post-test, the DT line goes slightly down from 0.2 to about -0.5."
images/89e2fdadc30740d5621ee09d5e2a05762e7df2d4_Image_004.png,The bar charts show the maximum frequencies under different tubing configurations and different force magnitude.
images/3b7a594a4bde4a45ded0293c0b2699ccb41e4dc3_Image_011.png,On the far left is a bar graph of the number of perceivable pins for each participant. All participants were able to perceive more pins in the lower area of the palm. On the center left is a diagram of the pin display showing the locations of pins that participants could recognize. The perceivable pins produce a shape similar to the left palm. Pins on the edges of the shape could only be perceived by participants with large hands while pins in the inside could be recognized by most (more than seven) participants. On the center right is a bar graph of the distance errors for each participant. P5 had the highest error of approximately 19~mm while P3 had the lowest error of approximately 10~mm. On the far right is a diagram of the pin display showing the average error for each perceivable pin. The error is lower towards the fingertips while it is highest at the bottom of the palm.
images/3b7a594a4bde4a45ded0293c0b2699ccb41e4dc3_Image_013.png,"On the left is a bar graph of the average selection times for each participant. The maximum value is about 1150~ms (P2) while the minimum value is about 700~ms (P9). On the right is a histogram of the selection times of all participants. Most selections occurred between 500~ms and 800~ms. However, there were about 30 selections that took over 1500~ms."
images/3b7a594a4bde4a45ded0293c0b2699ccb41e4dc3_Image_014.png,"On the left is a bar graph of the average selection times for each participant. The maximum value is about 1150~ms (P2) while the minimum value is about 700~ms (P9). On the right is a histogram of the selection times of all participants. Most selections occurred between 500~ms and 800~ms. However, there were about 30 selections that took over 1500~ms."
images/3b7a594a4bde4a45ded0293c0b2699ccb41e4dc3_Image_015.png,Time error graph of the moving target selection task. Most participants produced shorter time errors for faster target speeds while P2 produced a constant error of approximately 200~ms regardless of the target speed.
images/3b7a594a4bde4a45ded0293c0b2699ccb41e4dc3_Image_016.png,"On the far left is a bar graph of the Whack-A-Mole scores for each participant. The highest score was about 90 points (P10) while the lowest was about 60 points (P7). On the center left is a bar graph of the number of planes destroyed and number of collisions in Shoot 'em Up. All participants destroyed more than 13 enemy planes. On the center is a bar graph of the number of rallies in Multi-player Pong for each participant. P7 and P8 performed around 9 rallies on average, while P9 performed less than 2 rallies on average. On the center right is a bar graph of the Rhythm game scores for each participant. On the far right is a scatter plot of Rhythm game score against moving target selection error. The Rhythm game scores (excluding that of P1) were analyzed to show that participants with lower time error in the moving target selection task (study 2) scored higher in Rhythm game."
images/3dad3a747463969ccf7aa054e005afa71bb3d2a9_Image_003.jpg,"This violin plot shows a similar side-by-side distribution of the response rate to messages between the ""human coach"" and ""wizard-of-oz"" groups as in Figure 3. On the left, the density for the ""human coach"" group centered on a higher point, the mean of 71%. On the right, the plot for the ""woz"" group is relatively unchanged from how it appeared in Figure 3, with the mass of the distribution centered on the mean response rate of 54%."
images/0f06c57940475cfc741de29099847b6aa66c8bc0_Image_004.jpg,"Plot of how mean discrimination ellipsoid volume (dependent) varies across eight different lighting ratios (independent). As lighting ratio increases (i.e., the room gets brighter or the screen gets darker), ellipsoid volume increases (i.e., participant color differentiation abilities decrease)."
images/0f06c57940475cfc741de29099847b6aa66c8bc0_Image_007.jpg,"Histogram plot of mean discrimination volumes (bin size = 250) for our participants. Rises sharply from 0-250 (over 500 participants) to a peak at 500-750 (over 3000 participants). Histogram then falls off with a very long tail. Minimum volume is 21.68, 25th quartile is at volume 804.62, 50th quartile (median) is at volume 1558.38, 75th quartile is at volume 3223.60, maximum volume is 1058397.75. Histogram is cut off above volumes of 12000."
images/0f06c57940475cfc741de29099847b6aa66c8bc0_Image_009.jpg,"Plots of lower and upper estimates of the number of unique differentiable colors (independent) versus discrimination ellipsoid volume (dependent). Plots start very high (above 20000 unique colors), fall quickly as ellipsoid volume increases, and then level out into a long-tail. At volume=1000, upper estimate is about 10000 colors and the lower estimate is about 5000 colors; at volume=2000, upper=5000 and lower=2000; at volume 4000, upper=3000 and lower=1000."
images/0f06c57940475cfc741de29099847b6aa66c8bc0_Image_014.jpg,"Plot of mean proportion of image pixels differentiable (independent) for 0% - 100% of the population (dependent) for websites and infographics. Increasing from 0% of the population, both plots start at 100% differentiable and gradually fall to 80% differentiable at 75% of the population. Plots begin to diverge here as they both fall off more quickly until a discontinuity plateau is reached at 88% of the population (websites = 60% differentiable, infographics = 50% differentiable). Plateau gradually declines to 99% of population (websites = 55% differentiable, infographics = 45% differentiable), and then both plots fall to 0% differentiable for 100% of the population."
images/1ac54dd26a3dfd9af0a0d9276a8f4af4a710004d_Image_004.png,"Two graphs, showing average error for a point versus its horizontal position and vertical position. As horizontal position changes, error stays relatively constant. As vertical position gets higher than the calibration marker, error increases."
images/1ac54dd26a3dfd9af0a0d9276a8f4af4a710004d_Image_005.png,A box and whisker plot showing NASA Task Load Index score in each of six categories and the average.
images/4f932661157e43e2df1eaa16e0cfeaa7443ac338_Image_006.jpg,Number of trials and success rates of all 26 participants for all basic emotion they tried to mimic.
images/4f932661157e43e2df1eaa16e0cfeaa7443ac338_Image_007.jpg,Number of trials and success rates of all 26 participants for all basic emotion they tried to mimic.
images/79b8dcb17db71e75b3401e6743e194cf0943b960_Image_003.jpg,"A stacked bar chart illustrating the distributions of categories on how parents with different infant feeding roles make use of digital technology to support their infant feeding practice. The category of technology use includes relating to the feeding experiences of others, assuring infant feeding practice, finding solutions to challenges in infant feeding and logging infant feeding practice. For the category of relating to the feeding experiences of others, 12.8% of breastfeeding parents responded neither agree nor disagree, 38.40% agreed, 36.80% strongly agreed. No bottle-feeding parents responded strongly disagree and disagree. 25.00% responded neither agree nor disagree, 41.67% responded agree, 33.33% responded strongly agree. 23.53% of partners responded responded neither agree nor disagree and 41.18% responded agree. For the assuring infant feeding practice category, 32.54% of breastfeeding parents responded agree while 34.92% responded strongly agree. 50% of bottle-feeding parents responded responded agree and 25.00% responded strongly agree. 23.53% of partners responded disagree, and 41.18% responded agree. For the finding solutions to challenges in infant feeding practice category, 37.7% of breastfeeding parents responded agree and 45.90% responded strongly agree. 33.33% of bottle-feeding parents responded agree and 33.33% responded strongly agree. 37.5% of partners responded agree, 31.25% responded strongly agree. For the logging infant feeding practice category, 34.92% of breastfeeding parents responded strongly disagree, and 25.40% responded strongly agree. 50% of bottle-feeding parents responded strongly agree. 31.25% of partners responded strongly disagree, and 31.25% responded strongly agree."
images/79b8dcb17db71e75b3401e6743e194cf0943b960_Image_004.jpg,"A bar chart illustrating the distribution of the IBM constructs on 5-point Likert scales. For attitude, breastfeeding parents responded strongly agree(59.95%). Bottle-feeding parents responded strongly disagree(30.56%), strongly agree(33.33%). Partners responded strongly agree(35.29%). Parents-to-be responded neither agree nor disagree(33.33%), strongly agree(33.33%). For norm, breastfeeding parents responded strongly disagree(27.32%), disagree(27.32%). Bottle-feeding parents responded strongly disagree(25%) and strongly agree(25%). Partners responded neither agree nor disagree(23.53%), agree(32.94%). Parents-to-be responded neither agree nor disagree(43%). For personal agency, breastfeeding parents responded agree(23.22%), strongly agree(35.95%). Bottle-feeding parents responded strongly disagree(39.58%). Partners responded disagree(25%), agree(25%) and strongly agree(21.32%). Parents-to-be responded neither agree nor disagree(32.14%). For environment, breastfeeding parents responded neither agree nor disagree(25.1%), responded agree(23.28%). Bottle-feeding parents responded neither agree nor disagree(27.08%), strongly agree(27.08%). Partners responded neither agree nor disagree(26.94%), agree(25%). Parents-to-be responded neither agree nor disagree(47.5%). For knowledge, breastfeeding parent responded strongly agree(38.88%). Bottle-feeding parents responded agree(23.33%), strongly agree(36.67%). Partners responded agree(33.05%), strongly agree(46.39%). Parents-to-be responded neither agree nor disagree(28.33%), agree(33.33%). For salience, breastfeeding parents responded strongly agree(59.79%). Bottle-feeding parents responded agree(33.33%), strongly agree(33.33%). Partners responded strongly agree(41.18%). Parents-to-be responded strongly agree(40%). For habit, Breastfeeding parents responded agree(30.65%), strongly agree(46.77%). Bottle-feeding parents responded strongly agree(58.33%). Partners responded agree(47.06%)."
images/0127182e5320bcbdcdad87813a58bc78eb2d2e9c_Image_007.jpg,"The bar graph for precision and recall for three different conditions. Total six bars are present. (Precision/Recall for three condition from C1, C2, to C3). The values are as follows: C1 Precision : 86.9%, C1 Recall 62.7%, C2 Precision 94.7%, C2 Recall 66.8%, C3 Precision 99.2%, C3 Recall 90.0%"
images/0127182e5320bcbdcdad87813a58bc78eb2d2e9c_Image_008.jpg,"The bar graph for the completion time of each animation. Total 6 bars are present (1st demo and the 2nd demo per condition (C1, C2, and C3)). The values are as follows: C1- 1st Demo:39.4s, C1-2nd Demo:35.6s, C1-2nd Demo(Green portion):22.5s, C2-1st Demo:78.3s, C2-2nd Demo:19.1s, C2-2nd Demo (Green portion):4.6s, C3-1st Demo:174.5s, C2-2nd Demo:12.4s, C2-2nd Demo (Green portion):1.1s"
images/031c5426862746aeef25ca784afa9191fcdb0eff_Image_008.jpg,"Left: Average STAI-6 scores during five conditions for both treatment and control groups. An interaction effect (circled) was observed between group and post-stressor 1 and post-stressor 2 conditions: the treatment group receiving vibrotactile patterns during post-stressor 2 experienced a drop in anxiety compared to the control group. Solid line indicates treatment group; dotted line indicates control group. Center, Right: Average positive affect (left) and negative affect (center) during five conditions as reported on a scale of 1 to 100 by both treatment and control groups. No interaction effect was observed between group (treatment and control) and condition (post-stressor 1 and post-stressor 2): we did not find that receiving vibrotactile patterns had an influence on either positive or negative affect."
images/031c5426862746aeef25ca784afa9191fcdb0eff_Image_011.jpg,"Left and Right: Average user-technology engagement difficulty at three levels of perception, cognition, and action in the presence and absence of a stressor, with effect sizes displayed. Left: Synchronization with vibrations is more difficult than both noticing and differentiating vibrations. This is true both without a stressor (at V-Breathing Practice) and with a stressor (at Post-stressor 2). Right: When a stressor is introduced, synchronizing becomes significantly more difficult than both noticing and differentiating. Note that there is data for both treatment and control groups in the absent stressor condition (at V-Breathing Practice), but only for the treatment group in the stressor condition (at Post-stressor 2)."
images/031c5426862746aeef25ca784afa9191fcdb0eff_Image_012.jpg,"SHAP feature importance measured as the mean absolute Shapley values. The rating of how much a participant desired to turn PIV vibrations off was the most important feature, changing the predicted anxiety level on average by 1.42 points. Right: SHAP summary plot showing the importance and the effect of features. Low numbers of willingness to turn-off vibrations contribute to anxiety drop, and large numbers to increase in anxiety."
images/031c5426862746aeef25ca784afa9191fcdb0eff_Image_014.jpg,Left: Average STAI-6 scores. An interaction effect (circled) was observed between group and Post-stressor 1 and Post-stressor 2 for Openness score < 33 but not for Openness score > 33. Center: An interaction effect was observed between Pre- and Post-stressor 1 as well as between Post-stressor 1 and 2 which make the results inconclusive. Right: The same as left but for  Reappraisal scores cutoff at 71.
images/89ce35d22b833c4969ec79eb95a573b492b4c3ca_Image_005.jpg,"Mean completion times. Error bars show the standard deviations, and the asterisks indicate significant differences."
images/89ce35d22b833c4969ec79eb95a573b492b4c3ca_Image_006.jpg,"Means of NASA TLX overall score and SUS score. Error bars show the standard deviations, and the asterisks indicate significant differences."
images/89ce35d22b833c4969ec79eb95a573b492b4c3ca_Image_007.jpg,"Means of NASA TLX weighted workload scores. Error bars show the standard deviations, and the asterisks indicate significant differences."
images/0ce127ebea937d1730bdb2a4625d6bd94a3bdef4_Image_002.png,Magnetic field data when touching various locations of the smartwatch's touchscreen. Magnetic field can be similar even if a touching finger is different. Touch location data is necessary for such cases.
images/0ce127ebea937d1730bdb2a4625d6bd94a3bdef4_Image_003.png,Change in the magnitude of magnetometer vector data with the change in the ambient magnetic field. The magnetometer vector data is a vector sum of the magnetic field of the magnet ring and the ambient magnetic field. The reference and 6'o clock directions denotes two opposite directions.
images/0ce127ebea937d1730bdb2a4625d6bd94a3bdef4_Image_010.png,F1 scores of different indexes for the magnetic field distortion by different thresholds. Bold lines indicate mean values for different participants and the colored areas indicate the range of standard deviations.
images/f65de96c15e33484bc85079b354f053fd9fe8ccc_Image_004.jpg,"The graph shows a gradual increase of about 10% of the amount of total errors from large to tiny. On the other hand, the uncorrected error rate remains constant."
images/f65de96c15e33484bc85079b354f053fd9fe8ccc_Image_005.jpg,The graph shows a significant increase of the relative path lenght as size gets smaller. From a relative distance smaller than 10 pixels to a 30 pixel difference on tiny. The same effect it is also noticible on the task axis lengh but the difference between tiny and large is of only about 8 relative pixels.
images/f65de96c15e33484bc85079b354f053fd9fe8ccc_Image_006.jpg,"The bar graph depicts no differences between the number of slips of large, medium and small size but a considerable difference to tiny that above 60% slip errors."
